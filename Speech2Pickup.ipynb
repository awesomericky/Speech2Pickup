{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech2Pickup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq9_Hd85k-ZD",
        "outputId": "d23f2bf7-e1d9-4ee6-b2d0-ca4d8fc0b919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqc46ycl5hR"
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from os import listdir, makedirs\n",
        "from os.path import join, isfile, isdir\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i63ybC0EmKjA"
      },
      "source": [
        "## processed_data_loader.py ##\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "import pickle\n",
        "\n",
        "def load_data(relative_data_directory_path):\n",
        "    total_data = []\n",
        "    data_files = [f for f in listdir(relative_data_directory_path) if isfile(join(relative_data_directory_path, f))]\n",
        "    data_files.sort()\n",
        "    for data_file in data_files:\n",
        "        with open(join(relative_data_directory_path, data_file), 'rb') as f:\n",
        "            data_list = pickle.load(f)\n",
        "            total_data.append(data_list)\n",
        "\n",
        "            # # Logging for 'Data_v1.0'\n",
        "            # print('='*20)\n",
        "            # print(len(data_list))\n",
        "            # print(len(data_list[0])); print(len(data_list[1])); print(len(data_list[2])); print(len(data_list[3])); print(len(data_list[4])); print(len(data_list[5]))\n",
        "            # print(data_list[0][0]); print(data_list[1][0]); print(data_list[2][0]); print(data_list[3][0]); print(data_list[4][0]); print(data_list[5][0])\n",
        "\n",
        "            # # Logging for 'Data_v2.0' and 'Data_v2.1'\n",
        "            # print('='*20)\n",
        "            # print(len(data_list))\n",
        "            # print(len(data_list[0])); print(len(data_list[1])); print(len(data_list[2]))\n",
        "            # print(data_list[0][0]); print(data_list[1][0]); print(data_list[2][0])\n",
        "            # print(len(data_list[0][0])); print(len(data_list[0][10])); print(len(data_list[0][40]))\n",
        "    return total_data\n",
        "\n",
        "def load_single_data(relative_data_directory_path, file_name):\n",
        "    with open(join(relative_data_directory_path, file_name), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0nYmm17mS5O"
      },
      "source": [
        "## utils.py ##\n",
        "\n",
        "def read_script_files(script_dir_path):\n",
        "    script_files = [f for f in listdir(script_dir_path) if isfile(join(script_dir_path, f))]\n",
        "    script_files.sort()\n",
        "    return script_files\n",
        "\n",
        "def read_script_file_data(script_dir_path, script_file):\n",
        "    curr_file = open(join(script_dir_path, script_file), 'r')\n",
        "    curr_file_lines = curr_file.readlines()\n",
        "    for i in range(len(curr_file_lines)):\n",
        "        words = curr_file_lines[i].split()[2: ]\n",
        "        curr_file_lines[i] = ' '.join(words)\n",
        "    return curr_file_lines\n",
        "\n",
        "def read_audio_files(audio_dir_path):\n",
        "    audio_files = [f for f in listdir(audio_dir_path) if isfile(join(audio_dir_path, f))]\n",
        "    audio_files.sort()\n",
        "    return audio_files"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0at6o5olLGW"
      },
      "source": [
        "## process_data.py ##\n",
        "\n",
        "def audio_length_equalize_and_save(relative_data_directory_path, relative_save_data_directory_path):\n",
        "    data_type = relative_data_directory_path.split('/')[-1]\n",
        "    if data_type == 'data_v1.0':\n",
        "        sampled_audios_idx = 3\n",
        "        sample_rates_idx = 4\n",
        "\n",
        "        # Load data\n",
        "        data_files = [f for f in listdir(relative_data_directory_path) if isfile(join(relative_data_directory_path, f))]\n",
        "        data_files.sort()\n",
        "        total_file_num = len(data_files)\n",
        "        print('{} file loaded'.format(total_file_num))\n",
        "\n",
        "        # Find max sampled audio length\n",
        "        max_sampled_audio_len = 0        \n",
        "        for data_file in data_files:\n",
        "            data = load_single_data(relative_data_directory_path, data_file)\n",
        "            sampled_audios = data[sampled_audios_idx]\n",
        "            for sampled_audio in sampled_audios:\n",
        "                curr_sampled_audio_len = len(sampled_audio)\n",
        "                if curr_sampled_audio_len > max_sampled_audio_len:\n",
        "                    max_sampled_audio_len = curr_sampled_audio_len\n",
        "        \n",
        "        # Modify 'sampled_audios'\n",
        "        # of 'data_v1.0' to make audio length same\n",
        "        for i in range(total_file_num):\n",
        "            print('Processing {}/{}'.format(i+1, total_file_num))\n",
        "            data = load_single_data(relative_data_directory_path, data_files[i])\n",
        "            sampled_audios = data[sampled_audios_idx]\n",
        "            sampled_rates = data[sample_rates_idx]\n",
        "\n",
        "            for ii in range(len(sampled_audios)):\n",
        "                # Add zero padding to 'sampled audio'\n",
        "                len_zero_padding = max_sampled_audio_len - len(sampled_audios[ii])\n",
        "                sampled_audios[ii].extend([0]*len_zero_padding)\n",
        "\n",
        "            data[sampled_audios_idx] = sampled_audios\n",
        "            result = save_single_data(relative_save_data_directory_path, data, i+1)\n",
        "\n",
        "    elif data_type == 'data_v2.0':\n",
        "        sampled_audios_idx = 0\n",
        "        sample_rates_idx = 1\n",
        "        word_time_intervals_idx = 2\n",
        "\n",
        "        # Load data\n",
        "        data_files = [f for f in listdir(relative_data_directory_path) if isfile(join(relative_data_directory_path, f))]\n",
        "        data_files.sort()\n",
        "        total_file_num = len(data_files)\n",
        "        print('{} file loaded'.format(total_file_num))\n",
        "        \n",
        "        # Find max sampled audio length\n",
        "        max_sampled_audio_len = 0        \n",
        "        for data_file in data_files:\n",
        "            data = load_single_data(relative_data_directory_path, data_file)\n",
        "            sampled_audios = data[sampled_audios_idx]\n",
        "            for sampled_audio in sampled_audios:\n",
        "                curr_sampled_audio_len = len(sampled_audio)\n",
        "                if curr_sampled_audio_len > max_sampled_audio_len:\n",
        "                    max_sampled_audio_len = curr_sampled_audio_len\n",
        "        \n",
        "        # Modify 'sampled_audios' and 'word_time_intervals'\n",
        "        # of 'data_v2.0' to make audio length same\n",
        "        for i in range(total_file_num):\n",
        "            print('Processing {}/{}'.format(i+1, total_file_num))\n",
        "            data = load_single_data(relative_data_directory_path, data_files[i])\n",
        "            sampled_audios = data[sampled_audios_idx]\n",
        "            sampled_rates = data[sample_rates_idx]\n",
        "            word_time_intervals = data[word_time_intervals_idx]\n",
        "\n",
        "            for ii in range(len(sampled_audios)):\n",
        "                # Add zero padding to 'sampled audio'\n",
        "                len_zero_padding = max_sampled_audio_len - len(sampled_audios[ii])\n",
        "                sampled_audios[ii] = np.append(sampled_audios[ii], [0]*len_zero_padding)\n",
        "\n",
        "                # Add silent part to 'word_time_interval'\n",
        "                added_time = round(len_zero_padding/float(sampled_rates[ii]), 3)\n",
        "                curr_end_time = word_time_intervals[ii][-1][-1]\n",
        "                word_time_intervals[ii].append([\"\", curr_end_time, curr_end_time+added_time])\n",
        "\n",
        "            data[sampled_audios_idx] = sampled_audios\n",
        "            data[word_time_intervals_idx] = word_time_intervals\n",
        "\n",
        "            result = save_single_data(relative_save_data_directory_path, data, i+1)\n",
        "    else:\n",
        "        raise ValueError('Unavailable data directory path for audio zero padding')\n",
        "\n",
        "\n",
        "def save_single_data(relative_save_data_directory_path, data, save_file_num):\n",
        "    # Check directiry to save data\n",
        "    if not isdir(relative_save_data_directory_path):\n",
        "        makedirs(relative_save_data_directory_path)\n",
        "    \n",
        "    # Save\n",
        "    file_name = relative_save_data_directory_path + '/senEM_preprocessed_{}.pkl'.format(save_file_num)\n",
        "    print('Saving {} data'.format(save_file_num))\n",
        "    with open(file_name, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "    return True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-DGP9nlmr2z"
      },
      "source": [
        "## processed_data_saver.py ##\n",
        "\n",
        "def save_data_v2_1(relative_data_directory_path, relative_save_data_directory_path):\n",
        "    audio_length_equalize_and_save(relative_data_directory_path, relative_save_data_directory_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOAY_yQsm22r",
        "outputId": "832b9f67-5e93-4cfc-c670-b689cf1ca184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "relative_data_directory_path = '/content/gdrive/My Drive/Speech2Pickup/data_v2.0'\n",
        "relative_save_data_directory_path = '/content/gdrive/My Drive/Speech2Pickup/data_v2.1'\n",
        "save_data_v2_1(relative_data_directory_path, relative_save_data_directory_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-85f9a3b956be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrelative_data_directory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Speech2Pickup/data_v2.0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrelative_save_data_directory_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Speech2Pickup/data_v2.1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_data_v2_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_data_directory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_save_data_directory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'save_data_v2_1' is not defined"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "10 file loaded\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}