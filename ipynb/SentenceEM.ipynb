{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceEM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d0b7db4cb1349b5b529ff122908bcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d340d95b83bc49a883ff899f0f924880",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_369d24fb359b4d19a136fd8fe345527e",
              "IPY_MODEL_ce0cc942699a43a695d6e25d48382569"
            ]
          }
        },
        "d340d95b83bc49a883ff899f0f924880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "369d24fb359b4d19a136fd8fe345527e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_7a7b0017dbed4c73b1bfa389afcbb843",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.06MB of 0.06MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cb0abfd7bd24738b58a36e348022acc"
          }
        },
        "ce0cc942699a43a695d6e25d48382569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f6e853d4f8f4a078725ac024ef340c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b261cb8854a8429eb0484210091442af"
          }
        },
        "7a7b0017dbed4c73b1bfa389afcbb843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cb0abfd7bd24738b58a36e348022acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f6e853d4f8f4a078725ac024ef340c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b261cb8854a8429eb0484210091442af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjubJvgqoi7O",
        "outputId": "b2a3e457-951c-46b6-ce92-cc2b702b8b4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DtnV8t-aTfD"
      },
      "source": [
        "% pip install wandb -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXUngcu6W42Q"
      },
      "source": [
        "% pip install pdbpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBA26NJTgUsh",
        "outputId": "b5070f5d-7fa8-4fc6-81ff-9d2cf657d361"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrLeuXRKm3vN"
      },
      "source": [
        "# Turning off tensorflow warning message (not recommended)\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ0XNqJJZ-ll"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.backend as kb\n",
        "from tensorflow.keras.models import save_model\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import random\n",
        "import pdb\n",
        "import wandb\n",
        "from os.path import join, isfile\n",
        "from os import listdir"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHYVABrggyHf",
        "outputId": "b5606533-bbb7-4484-c197-64e1a47b4589"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di9QVKhraRmb",
        "outputId": "48a72c51-75b4-4547-d392-7104f3b1859a"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawesomericky\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EySe9_QPR-K",
        "outputId": "dd5e8600-cb6c-40b4-9826-0d6b1cc17c99"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print('Found GPU at {}'.format(device_name))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biS128E0ZXvL"
      },
      "source": [
        "\"\"\"\n",
        "utils.py\n",
        "\"\"\"\n",
        "\n",
        "def read_script_files(script_dir_path):\n",
        "    script_files = [f for f in listdir(script_dir_path) if isfile(join(script_dir_path, f))]\n",
        "    script_files.sort()\n",
        "    return script_files\n",
        "\n",
        "def data_shuffle(relative_data_directory_path):\n",
        "    data_files = read_script_files(relative_data_directory_path)\n",
        "    random.shuffle(data_files)\n",
        "    return data_files"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76bPg01FZg_p"
      },
      "source": [
        "\"\"\"\n",
        "processed_data_loader.py\n",
        "\"\"\"\n",
        "\n",
        "def load_single_npz_data(relative_data_directory_path, file_name):\n",
        "    file_path = join(relative_data_directory_path, file_name)\n",
        "    data = np.load(file=file_path)\n",
        "    return data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDnb_Tk9F2JJ"
      },
      "source": [
        "\"\"\"\n",
        "TCN_and_decoder.py\n",
        "\"\"\"\n",
        "\n",
        "class ResidualBlock(tf.keras.Model):\n",
        "    def __init__(self, dilation_rate, num_filters, kernel_size, padding, \n",
        "                        dropout_rate, seed, training_state):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=seed)\n",
        "        layers = tf.keras.layers\n",
        "        assert padding in ['causal', 'same']\n",
        "\n",
        "        self.training_state = training_state\n",
        "\n",
        "        # Block1\n",
        "        self.conv1 = layers.Conv1D(filters=num_filters, kernel_size=kernel_size, data_format='channels_last',\n",
        "                                    dilation_rate=dilation_rate, padding=padding, kernel_initializer=init)\n",
        "        self.batch1 = layers.BatchNormalization(axis=1, trainable=True)\n",
        "        self.ac1 = layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop1 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block2\n",
        "        self.conv2 = layers.Conv1D(filters=num_filters, kernel_size=kernel_size, data_format='channels_last',\n",
        "                                    dilation_rate=dilation_rate, padding=padding, kernel_initializer=init)\n",
        "        self.batch2 = layers.BatchNormalization(axis=1, trainable=True)\n",
        "        self.ac2 = layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop2 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        self.downsample = layers.Conv1D(filters=num_filters, kernel_size=1,\n",
        "                                        padding='same', kernel_initializer=init)\n",
        "        self.ac3 = layers.LeakyReLU(alpha=0.2)\n",
        "    \n",
        "    def call(self, x):\n",
        "        # Block1\n",
        "        prev_x = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch1(x)\n",
        "        x = self.ac1(x)\n",
        "        x = self.drop1(x) if self.training_state else x\n",
        "\n",
        "        # Block2\n",
        "        x = self.conv2(x)\n",
        "        x = self.batch2(x)\n",
        "        x = self.ac2(x)\n",
        "        x = self.drop2(x) if self.training_state else x\n",
        "\n",
        "        # Match dimention\n",
        "        if prev_x.shape[-1] != x.shape[-1]:\n",
        "            prev_x = self.downsample(prev_x)\n",
        "        assert prev_x.shape[1:] == x.shape[1:]\n",
        "\n",
        "        # skip connection\n",
        "        return self.ac3(prev_x + x)\n",
        "\n",
        "class TemporalBlock(tf.keras.Model):\n",
        "    def __init__(self, num_channels, kernel_size, dropout_rate, seed, training_state):\n",
        "        # num_channels is a list contains hidden channel numbers of Conv1D\n",
        "        # len(num_channels) is number of convolutional layers in one Temporal Block\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        assert isinstance(num_channels, list)\n",
        "\n",
        "        self.num_levels = len(num_channels)\n",
        "        self.resi_blocks = [0]*self.num_levels\n",
        "        for i in range(self.num_levels):\n",
        "            dilation_rate = 2**i\n",
        "            self.resi_blocks[i] = ResidualBlock(dilation_rate, num_channels[i], kernel_size, padding='causal',\n",
        "                            dropout_rate=dropout_rate, seed=seed, training_state=training_state)\n",
        "    \n",
        "    def call(self, x):\n",
        "        for i in range(self.num_levels):\n",
        "            x = self.resi_blocks[i](x)\n",
        "        return x\n",
        "\n",
        "class TempConvnet(tf.keras.Model):\n",
        "    def __init__(self, num_stacks, num_channels, kernel_size, dropout_rate, return_type, seed, training_state):\n",
        "        # num_stacks number of Temporal Blocks in Temporal convolutional network\n",
        "        super(TempConvnet, self).__init__()\n",
        "        assert isinstance(num_stacks, int)\n",
        "        assert isinstance(num_channels, list)\n",
        "        assert return_type in ['whole', 'end']\n",
        "\n",
        "        self.num_stacks = num_stacks\n",
        "        self.temp_blocks = [0]*self.num_stacks\n",
        "        self.return_type = return_type\n",
        "        for i in range(num_stacks):\n",
        "            self.temp_blocks[i] = TemporalBlock(num_channels, kernel_size=kernel_size, dropout_rate=dropout_rate, seed=seed, training_state=training_state)\n",
        "    \n",
        "    def call(self, x):\n",
        "        for i in range(self.num_stacks):\n",
        "            x = self.temp_blocks[i](x)\n",
        "        \n",
        "        if self.return_type == 'whole':\n",
        "            return x\n",
        "        elif self.return_type == 'end':\n",
        "            return x[:, -1, :]\n",
        "\n",
        "class TempConvnet_Decoder(tf.keras.Model):\n",
        "    def __init__(self, decoder_type, num_channels, kernel_size, padding, dropout_rate, seed, training_state):\n",
        "        super(TempConvnet_Decoder, self).__init__()\n",
        "        assert isinstance(num_channels, int)\n",
        "        assert isinstance(kernel_size, list)\n",
        "        assert padding in ['causal', 'same']\n",
        "        assert decoder_type in ['linguistic', 'acoustic']\n",
        "\n",
        "        init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=seed)\n",
        "        layers = tf.keras.layers\n",
        "\n",
        "        self.training_state = training_state\n",
        "\n",
        "        # Block1\n",
        "        self.upsample_block1 = layers.UpSampling1D(size=3)\n",
        "        self.conv_block1 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block1 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block1 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block1 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block2\n",
        "        self.upsample_block2 = layers.UpSampling1D(size=3)\n",
        "        self.conv_block2 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block2 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block2 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block2 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block3\n",
        "        self.upsample_block3 = layers.UpSampling1D(size=2)\n",
        "        self.conv_block3 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block3 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block3 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block3 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block4\n",
        "        self.conv_block4 = layers.Conv1D(filters=num_channels, kernel_size=2, data_format='channels_last',\n",
        "                                            padding='valid', kernel_initializer=init)\n",
        "        self.batchnorm_block4 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block4 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block4 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block5\n",
        "        self.upsample_block5 = layers.UpSampling1D(size=2)\n",
        "        self.conv_block5 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block5 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block5 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block5 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block6\n",
        "        self.upsample_block6 = layers.UpSampling1D(size=3)\n",
        "        self.conv_block6 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block6 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block6 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block6 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block7\n",
        "        self.conv_block7 = layers.Conv1D(filters=num_channels, kernel_size=2, data_format='channels_last',\n",
        "                                            padding='valid', kernel_initializer=init)\n",
        "        self.batchnorm_block7 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block7 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block7 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block8\n",
        "        self.upsample_block8 = layers.UpSampling1D(size=3)\n",
        "        self.conv_block8 = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "                                            padding=padding, kernel_initializer=init)\n",
        "        self.batchnorm_block8 = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "        self.ac_block8 = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.drop_block8 = layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "        # Block9 (final block)\n",
        "        self.final_conv_block = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[1], data_format='channels_last',\n",
        "                                                    padding=padding, kernel_initializer=init)\n",
        "        self.final_ac_block = layers.Softmax(axis=-1) if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "        self.final_reshape_block = layers.Permute((2, 1))\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.upsample_block1(x)\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.batchnorm_block1(x)\n",
        "        x = self.ac_block1(x)\n",
        "        x = self.drop_block1(x) if self.training_state else x\n",
        "        x = self.upsample_block2(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.batchnorm_block2(x)\n",
        "        x = self.ac_block2(x)\n",
        "        x = self.drop_block2(x) if self.training_state else x\n",
        "        x = self.upsample_block3(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.batchnorm_block3(x)\n",
        "        x = self.ac_block3(x)\n",
        "        x = self.drop_block3(x) if self.training_state else x\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.batchnorm_block4(x)\n",
        "        x = self.ac_block4(x)\n",
        "        x = self.drop_block4(x) if self.training_state else x\n",
        "        x = self.upsample_block5(x)\n",
        "        x = self.conv_block5(x)\n",
        "        x = self.batchnorm_block5(x)\n",
        "        x = self.ac_block5(x)\n",
        "        x = self.drop_block5(x) if self.training_state else x\n",
        "        x = self.upsample_block6(x)\n",
        "        x = self.conv_block6(x)\n",
        "        x = self.batchnorm_block6(x)\n",
        "        x = self.ac_block6(x)\n",
        "        x = self.drop_block6(x) if self.training_state else x\n",
        "        x = self.conv_block7(x)\n",
        "        x = self.batchnorm_block7(x)\n",
        "        x = self.ac_block7(x)\n",
        "        x = self.drop_block7(x) if self.training_state else x\n",
        "        x = self.upsample_block8(x)\n",
        "        x = self.conv_block8(x)\n",
        "        x = self.batchnorm_block8(x)\n",
        "        x = self.ac_block8(x)\n",
        "        x = self.drop_block8(x) if self.training_state else x\n",
        "        x = self.final_conv_block(x)\n",
        "        x = self.final_ac_block(x)\n",
        "        y = self.final_reshape_block(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "########################\n",
        "### Previous version ###\n",
        "########################\n",
        "\n",
        "# class TempConvnet_Decoder(tf.keras.Model):\n",
        "#     def __init__(self, decoder_type, num_levels, num_channels, kernel_size, padding, upsample_size, dropout_rate, output_shape, seed, training_state):\n",
        "#         super(TempConvnet_Decoder, self).__init__()\n",
        "#         assert isinstance(num_channels, int)\n",
        "#         assert isinstance(kernel_size, list)\n",
        "#         assert isinstance(upsample_size, dict)\n",
        "#         assert padding in ['causal', 'same']\n",
        "#         assert decoder_type in ['linguistic', 'acoustic']\n",
        "#         assert num_levels == upsample_size[2] + upsample_size[3] + upsample_size[0]\n",
        "\n",
        "#         init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1, seed=seed)\n",
        "#         layers = tf.keras.layers\n",
        "\n",
        "#         self.training_state = training_state\n",
        "\n",
        "#         self.size2_upsample_num = upsample_size[2]\n",
        "#         self.size3_upsample_num = upsample_size[3]\n",
        "#         self.reshape_conv_num = 1\n",
        "#         self.num_levels = num_levels\n",
        "#         self.final_kernel_size = kernel_size[1]\n",
        "#         self.output_len = output_shape[-1]  ## ex) (num_batch, num_time_steps, dictionary_length)\n",
        "\n",
        "#         self.upsample_blocks = [0]*(num_levels-1)\n",
        "#         self.conv_blocks = [0]*(num_levels-1)\n",
        "#         self.batchnorm_blocks = [0]*(num_levels-1)\n",
        "#         self.ac_blocks = [0]*(num_levels-1)\n",
        "#         self.drop_blocks = [0]*(num_levels-1)\n",
        "\n",
        "#         for i in range(num_levels-self.size3_upsample_num-self.reshape_conv_num):\n",
        "#             self.upsample_blocks[i] = layers.UpSampling1D(size=2)\n",
        "#             self.conv_blocks[i] = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "#                                                     padding=padding, kernel_initializer=init)\n",
        "#             self.batchnorm_blocks[i] = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "#             self.ac_blocks[i] = layers.ReLU() if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "#             self.drop_blocks[i] = layers.Dropout(rate=dropout_rate)\n",
        "#         for i in range(num_levels-self.size3_upsample_num-self.reshape_conv_num, num_levels-self.reshape_conv_num):\n",
        "#             self.upsample_blocks[i] = layers.UpSampling1D(size=3)\n",
        "#             self.conv_blocks[i] = layers.Conv1D(filters=num_channels, kernel_size=kernel_size[0], data_format='channels_last',\n",
        "#                                                     padding=padding, kernel_initializer=init)\n",
        "#             self.batchnorm_blocks[i] = layers.BatchNormalization(axis=-1, trainable=True)\n",
        "#             self.ac_blocks[i] = layers.Activation('tanh') if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "#             self.drop_blocks[i] = layers.Dropout(rate=dropout_rate)\n",
        "#         self.final_conv_block = layers.Conv1D(filters=num_channels, kernel_size=self.final_kernel_size, data_format='channels_last',\n",
        "#                                                     padding='valid', kernel_initializer=init)\n",
        "#         self.final_ac_block = layers.Softmax(axis=-1) if decoder_type == 'linguistic' else layers.LeakyReLU(alpha=0.2)\n",
        "#         self.final_reshape_block = layers.Permute((2, 1))\n",
        "    \n",
        "#     def call(self, x):\n",
        "#         import pdb\n",
        "#         for i in range(self.num_levels-1):\n",
        "#             x = self.upsample_blocks[i](x)\n",
        "#             x = self.conv_blocks[i](x)\n",
        "#             x = self.batchnorm_blocks[i](x)\n",
        "#             x = self.ac_blocks[i](x)\n",
        "#             x = self.drop_blocks[i](x) if self.training_state else x\n",
        "#         pdb.set_trace()\n",
        "#         len_padding = (self.output_len - (x.shape[1] - self.final_kernel_size) - 1)//2\n",
        "#         x = tf.keras.layers.ZeroPadding1D(padding=(len_padding*2, 0))(x)\n",
        "#         x = self.final_conv_block(x)\n",
        "#         x = self.final_ac_block(x)\n",
        "#         y = self.final_reshape_block(x)\n",
        "#         return y"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_tBigUbFqaT"
      },
      "source": [
        "\"\"\"\n",
        "sentenceEM.py\n",
        "\"\"\"\n",
        "\n",
        "class sentenceEM(tf.keras.Model):\n",
        "    def __init__(self, encoder_args, linguistic_decoder_args, acoustic_decoder_args, input_shapes, seed, training_state):\n",
        "        \"\"\"\n",
        "        1) encoder_args: \n",
        "        num_stacks, num_channels, kernel_size, dropout_rate, return_type, seed\n",
        "        2) linguistic_decoder_args:\n",
        "        decoder_type, num_channels, kernel_size, padding, dropout_rate, seed, training_state\n",
        "        3) acoustic_decoder_args:\n",
        "        decoder_type, num_channels, kernel_size, padding, dropout_rate, seed, training_state\n",
        "        \"\"\"\n",
        "        super(sentenceEM, self).__init__()\n",
        "        self.input_shapes = input_shapes\n",
        "        self.input_reshape_block = layers.Permute((2, 1))\n",
        "        self.encoder = TempConvnet(num_stacks=encoder_args['num_stacks'], num_channels=encoder_args['num_channels'],\n",
        "                                        kernel_size=encoder_args['kernel_size'], dropout_rate=encoder_args['dropout_rate'],\n",
        "                                        return_type=encoder_args['return_type'], seed=seed, training_state=training_state)\n",
        "        self.linguistic_decoder = TempConvnet_Decoder(decoder_type=linguistic_decoder_args['decoder_type'], num_channels=linguistic_decoder_args['num_channels'], \n",
        "                                                      kernel_size=linguistic_decoder_args['kernel_size'], padding=linguistic_decoder_args['padding'],\n",
        "                                                      dropout_rate=linguistic_decoder_args['dropout_rate'], seed=seed, training_state=training_state)\n",
        "        self.acoustic_decoder = TempConvnet_Decoder(decoder_type=acoustic_decoder_args['decoder_type'], num_channels=acoustic_decoder_args['num_channels'], \n",
        "                                                    kernel_size=acoustic_decoder_args['kernel_size'], padding=acoustic_decoder_args['padding'],\n",
        "                                                    dropout_rate=acoustic_decoder_args['dropout_rate'], seed=seed, training_state=training_state)\n",
        "    \n",
        "    def call(self, x):\n",
        "        embedded_outputs = self.input_reshape_block(x)\n",
        "        embedded_outputs = self.encoder(embedded_outputs)\n",
        "        embedded_outputs = kb.expand_dims(embedded_outputs, axis=1)\n",
        "        linguistic_outputs = self.linguistic_decoder(embedded_outputs)\n",
        "        acoustic_outputs = self.acoustic_decoder(embedded_outputs)\n",
        "        return linguistic_outputs, acoustic_outputs\n",
        "    \n",
        "    def encoder_call(self, x):\n",
        "        embedded_outputs = self.input_reshape_block(x)\n",
        "        embedded_outputs = self.encoder(embedded_outputs)\n",
        "        return embedded_outputs\n",
        "    \n",
        "    def decoder_call(self, x):\n",
        "        embedded_outputs = kb.expand_dims(x, axis=1)\n",
        "        linguistic_outputs = self.linguistic_decoder(embedded_outputs)\n",
        "        acoustic_outputs = self.acoustic_decoder(embedded_outputs)\n",
        "        return linguistic_outputs, acoustic_outputs\n",
        "    \n",
        "    def build_seperate_graph(self):\n",
        "        # Encoder graph\n",
        "        x = tf.keras.Input(batch_shape=self.input_shapes)\n",
        "        embedded_outputs = self.encoder_call(x)\n",
        "        self.embedded_outputs_shape = embedded_outputs.shape\n",
        "        self.encoder_model = tf.keras.Model(inputs=x, outputs=embedded_outputs)\n",
        "\n",
        "        # Decoder graph\n",
        "        embeddings = tf.keras.Input(batch_shape=self.embedded_outputs_shape)\n",
        "        linguistic_outputs, acoustic_outputs = self.decoder_call(embeddings)\n",
        "        self.decoder_model = tf.keras.Model(inputs=embeddings, outputs=[linguistic_outputs, acoustic_outputs])\n",
        "    \n",
        "    def build_total_graph(self):\n",
        "        x = tf.keras.Input(batch_input_shape=self.input_shapes)\n",
        "        y = self.encoder_model(x)\n",
        "        l_y, a_y = self.decoder_model(y)\n",
        "        self.model = tf.keras.Model(inputs=x, outputs=[l_y, a_y])\n",
        "\n",
        "    # def model_visualize(self):\n",
        "    #     self.model.summary()\n",
        "    #     plot_model(self.model, to_file='/home/awesomericky/Lab_intern/Prof_Oh/Code/Speech2Pickup/image/sentenceEM.png')\n",
        "    \n",
        "    def encoder_model_compile(self, lr):\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        self.encoder_model.compile(optimizer=optimizer)\n",
        "\n",
        "    def model_compile(self, lr, loss_weights):\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        self.model.compile(optimizer=optimizer, loss=[self.linguistic_loss_function, self.acoustic_loss_function],\n",
        "                           loss_weights=[loss_weights['linguistic'], loss_weights['acoustic']],\n",
        "                           metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "    def model_train(self, X_train, Y_linguistic_train, Y_acoustic_train, batch_size, epochs, total_model_file_path, encoder_model_file_path):\n",
        "        custom_callback = CustomCallback(total_model_file_path, encoder_model_file_path, self.model, self.encoder_model)\n",
        "        self.model.fit(x=X_train, y=[Y_linguistic_train, Y_acoustic_train], batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[custom_callback])\n",
        "    \n",
        "    def linguistic_loss_function(self, y_actual, y_predicted):\n",
        "        epsil = 1e-5\n",
        "        y_predicted = -kb.log(y_predicted + epsil)\n",
        "        loss = layers.multiply([y_actual, y_predicted])\n",
        "        loss = kb.sum(loss, axis=1)\n",
        "        loss = kb.mean(loss, keepdims=False)\n",
        "        return loss\n",
        "    \n",
        "    def acoustic_loss_function(self, y_actual, y_predicted):\n",
        "        loss = layers.subtract([y_actual, y_predicted])\n",
        "        loss = layers.multiply([loss, loss])\n",
        "        loss = kb.mean(loss, keepdims=False)\n",
        "        return loss\n",
        "\n",
        "class CustomCallback(Callback):\n",
        "    def __init__(self, total_model_file_path, encoder_model_file_path, total_model, encoder_model):\n",
        "        self.total_model_file_path = total_model_file_path\n",
        "        self.encoder_model_file_path = encoder_model_file_path\n",
        "        self.total_model = total_model\n",
        "        self.encoder_model = encoder_model\n",
        "        self.monitor = 'model_1_categorical_accuracy'\n",
        "        self.monitor_op = np.greater\n",
        "        self.best = 0\n",
        "        self.temp_loss = []\n",
        "        self.temp_linguistic_loss = []\n",
        "        self.temp_acoustic_loss = []\n",
        "        self.temp_linguistic_accuracy = []\n",
        "    \n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.temp_loss.append(logs.get('loss'))\n",
        "        self.temp_linguistic_loss.append(logs.get('model_1_loss'))\n",
        "        self.temp_acoustic_loss.append(logs.get('model_1_1_loss'))\n",
        "        self.temp_linguistic_accuracy.append(logs.get('model_1_categorical_accuracy'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.temp_loss.append(logs.get('loss'))\n",
        "        self.temp_linguistic_loss.append(logs.get('model_1_loss'))\n",
        "        self.temp_acoustic_loss.append(logs.get('model_1_1_loss'))\n",
        "        self.temp_linguistic_accuracy.append(logs.get('model_1_categorical_accuracy'))\n",
        "        # temp_val_loss = logs.get('val_loss')\n",
        "        # temp_val_linguistic_accuracy = logs.get('val_model_1_categorical_accuracy')\n",
        "        # temp_val_acoustic_loss = logs.get('val_model_1_1_mean_squared_error')\n",
        "\n",
        "        # Logging data\n",
        "        for iii in range(len(self.temp_loss)):\n",
        "            wandb.log({'temp_loss': self.temp_loss[iii]})\n",
        "            wandb.log({'temp_linguistic_loss': self.temp_linguistic_loss[iii]})\n",
        "            wandb.log({'temp_acoustic_loss': self.temp_acoustic_loss[iii]})\n",
        "            wandb.log({'temp_linguistic_accuracy': self.temp_linguistic_accuracy[iii]})\n",
        "        # wandb.log({'temp_val_loss': temp_val_loss})\n",
        "        # wandb.log({'temp_val_linguistic_accuracy': temp_val_linguistic_accuracy})\n",
        "        # wandb.log({'temp_val_acoustic_loss': temp_val_acoustic_loss})\n",
        "        self.temp_loss = []\n",
        "        self.temp_linguistic_loss = []\n",
        "        self.temp_acoustic_loss = []\n",
        "        self.temp_linguistic_accuracy = []\n",
        "        \n",
        "        # Save model\n",
        "        current = logs.get(self.monitor)\n",
        "        if self.monitor_op(current, self.best):\n",
        "            self.best = current\n",
        "            self.total_model.save_weights(filepath=self.total_model_file_path, overwrite=True)\n",
        "            self.encoder_model.save_weights(filepath=self.encoder_model_file_path, overwrite=True)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRSZUTxv6OyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c2e14b-9036-4a6f-e780-debfe97c84c9"
      },
      "source": [
        "# Configure model\n",
        "\n",
        "train_model_number = 10\n",
        "batch_size = 1024; seed = 1; lr = 0.0001; epochs = 50; loss_weights={'linguistic': 100, 'acoustic': 0.005}\n",
        "n_mels = 40\n",
        "time_steps = 303\n",
        "word_dic_size = 43\n",
        "dropout_rate = 0.1\n",
        "training_state = True\n",
        "input_shapes = (None, n_mels, time_steps)\n",
        "encoder_args = {'num_stacks': 3, 'num_channels':[n_mels for i in range(6)], 'kernel_size':3, 'dropout_rate': dropout_rate, 'return_type': 'end'}\n",
        "linguistic_decoder_args = {'decoder_type': 'linguistic', 'num_channels': word_dic_size,\n",
        "                           'kernel_size': [2, 2], 'padding': 'causal', 'dropout_rate': dropout_rate}\n",
        "acoustic_decoder_args = {'decoder_type': 'acoustic', 'num_channels': n_mels,\n",
        "                         'kernel_size': [2, 2], 'padding': 'causal', 'dropout_rate': dropout_rate}\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    sen_em_model = sentenceEM(encoder_args=encoder_args, linguistic_decoder_args=linguistic_decoder_args, acoustic_decoder_args=acoustic_decoder_args,\n",
        "                                input_shapes=input_shapes, seed=seed, training_state=training_state)\n",
        "    sen_em_model.build_seperate_graph()\n",
        "    sen_em_model.build_total_graph()\n",
        "    sen_em_model.model_compile(lr=lr, loss_weights=loss_weights)\n",
        "# sen_em_model.model_visualize()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method TempConvnet.call of <__main__.TempConvnet object at 0x7fe337521eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TempConvnet.call of <__main__.TempConvnet object at 0x7fe337521eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe437cd25c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe437cd25c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437cd26d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437cd26d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe337233a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe337233a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3373a55f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3373a55f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437b46828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437b46828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3375a8198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3375a8198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe33745ecf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe33745ecf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe33745eb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe33745eb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4375333c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4375333c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436ce9400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436ce9400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388c8a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388c8a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd7cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd7cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388af860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388af860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe3376c3978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe3376c3978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3376c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3376c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379fbf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379fbf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379d2b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379d2b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e66d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e66d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e32b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e32b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379b8e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379b8e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe4379b0a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe4379b0a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe437cb70f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe437cb70f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet.call of <__main__.TempConvnet object at 0x7fe337521eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TempConvnet.call of <__main__.TempConvnet object at 0x7fe337521eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe437cd25c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe437cd25c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437cd26d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437cd26d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe337233a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe337233a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3373a55f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3373a55f8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437b46828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe437b46828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3375a8198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3375a8198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe33745ecf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe33745ecf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe33745eb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe33745eb70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4375333c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4375333c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436ce9400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436ce9400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388c8a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388c8a20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd7cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe436cd7cf8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388af860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4388af860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe3376c3978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <__main__.TemporalBlock object at 0x7fe3376c3978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3376c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe3376c3eb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379fbf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379fbf28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379d2b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379d2b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e66d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e66d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e32b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379e32b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379b8e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <__main__.ResidualBlock object at 0x7fe4379b8e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe437cb70f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe437cb70f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe4379b0a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TempConvnet_Decoder.call of <__main__.TempConvnet_Decoder object at 0x7fe4379b0a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZrallcaXJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5898ad3f-a688-403e-e6d7-d986c070b9ef"
      },
      "source": [
        "# Train model\n",
        "\n",
        "wandb_config = {'batch_size':batch_size,\n",
        "                'learning_rate': lr,\n",
        "                'loss_weight (linguistic, acoustic)': (loss_weights['linguistic'], loss_weights['acoustic']),\n",
        "                'channel_type': 'single',\n",
        "                'n_mels': n_mels,\n",
        "                'seed': seed,\n",
        "                'date': '2020-12-05',\n",
        "                'train_model_number': train_model_number,\n",
        "                'memo': 'init std=0.1, Dropout_rate: 0.1'}\n",
        "wandb_run = wandb.init(project='Speech2Pickup', name='sentenceEM', config=wandb_config)\n",
        "total_model_file_path = '/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/' + str(train_model_number) + '/total_model/sentenceEM_total_model'\n",
        "encoder_model_file_path = '/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/' + str(train_model_number) + '/encoder_model/sentenceEM_encoder_model'\n",
        "model_configuration_file = '/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/' + str(train_model_number) + '/model_config.txt'\n",
        "relative_data_directory_path = '/content/drive/MyDrive/Speech2Pickup/data_v2.2_single_channel'\n",
        "\n",
        "# Write model configuration in .txt file\n",
        "with open(model_configuration_file, 'w') as f:\n",
        "    f.write(str(wandb_config))\n",
        "\n",
        "# # Load data\n",
        "# print('Loading data...')\n",
        "# data_file = listdir(relative_data_directory_path)[0]\n",
        "# data = load_single_npz_data(relative_data_directory_path=relative_data_directory_path, file_name=data_file)\n",
        "# acoustic_data = data['acoustic']\n",
        "# linguistic_data = data['linguistic']\n",
        "\n",
        "# Train model and save\n",
        "print('Start training')\n",
        "try:\n",
        "    # Train\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        sen_em_model.model_train(X_train=acoustic_data, Y_linguistic_train=linguistic_data, Y_acoustic_train=acoustic_data, batch_size=batch_size, epochs=epochs,\n",
        "                                 total_model_file_path=total_model_file_path, encoder_model_file_path=encoder_model_file_path)\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">sentenceEM</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/awesomericky/Speech2Pickup\" target=\"_blank\">https://wandb.ai/awesomericky/Speech2Pickup</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/awesomericky/Speech2Pickup/runs/1vzffck9\" target=\"_blank\">https://wandb.ai/awesomericky/Speech2Pickup/runs/1vzffck9</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201204_174853-1vzffck9</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Start training\n",
            "Train on 40698 samples\n",
            "Epoch 1/50\n",
            "40698/40698 [==============================] - 48s 1ms/sample - loss: 390.3807 - model_1_loss: 3.7743 - model_1_1_loss: 2565.9370 - model_1_categorical_accuracy: 0.0074 - model_1_mean_squared_error: 0.0228 - model_1_1_categorical_accuracy: 0.0056 - model_1_1_mean_squared_error: 2565.8904\n",
            "Epoch 2/50\n",
            "40698/40698 [==============================] - 34s 841us/sample - loss: 350.9025 - model_1_loss: 3.3796 - model_1_1_loss: 2559.6655 - model_1_categorical_accuracy: 0.0053 - model_1_mean_squared_error: 0.0222 - model_1_1_categorical_accuracy: 0.0074 - model_1_1_mean_squared_error: 2559.5754\n",
            "Epoch 3/50\n",
            "15360/40698 [==========>...................] - ETA: 21s - loss: 319.3015 - model_1_loss: 3.0653 - model_1_1_loss: 2555.2476 - model_1_categorical_accuracy: 0.0062 - model_1_mean_squared_error: 0.0214 - model_1_1_categorical_accuracy: 0.0076 - model_1_1_mean_squared_error: 2555.2478"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibBz0FwpzLPw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583,
          "referenced_widgets": [
            "0d0b7db4cb1349b5b529ff122908bcbe",
            "d340d95b83bc49a883ff899f0f924880",
            "369d24fb359b4d19a136fd8fe345527e",
            "ce0cc942699a43a695d6e25d48382569",
            "7a7b0017dbed4c73b1bfa389afcbb843",
            "8cb0abfd7bd24738b58a36e348022acc",
            "4f6e853d4f8f4a078725ac024ef340c9",
            "b261cb8854a8429eb0484210091442af"
          ]
        },
        "outputId": "455168bd-bef9-4005-fa0b-4de4236b917b"
      },
      "source": [
        "# Erase model from memory\n",
        "# Finish wandb process\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "del sen_em_model\n",
        "wandb_run.finish()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1481<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d0b7db4cb1349b5b529ff122908bcbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20201204_174853-1vzffck9/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20201204_174853-1vzffck9/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>temp_loss</td><td>350.90249</td></tr><tr><td>_step</td><td>327</td></tr><tr><td>_runtime</td><td>101</td></tr><tr><td>_timestamp</td><td>1607104234</td></tr><tr><td>temp_linguistic_loss</td><td>3.37956</td></tr><tr><td>temp_acoustic_loss</td><td>2559.66553</td></tr><tr><td>temp_linguistic_accuracy</td><td>0.0053</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>temp_loss</td><td>â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒ</td></tr><tr><td>_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_runtime</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>temp_linguistic_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>temp_acoustic_loss</td><td>â–ˆâ–„â–…â–„â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–</td></tr><tr><td>temp_linguistic_accuracy</td><td>â–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">sentenceEM</strong>: <a href=\"https://wandb.ai/awesomericky/Speech2Pickup/runs/1vzffck9\" target=\"_blank\">https://wandb.ai/awesomericky/Speech2Pickup/runs/1vzffck9</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JyMoCwrTa00"
      },
      "source": [
        "x = tf.convert_to_tensor(np.random.random((batch_size, 40, 303)), dtype=np.float32)   # batch, dim, seq_len\n",
        "l_y, a_y = sen_em_model.model(x)\n",
        "embed = sen_em_model.encoder_model(x)\n",
        "print(kb.eval(embed).shape)\n",
        "\n",
        "print('='*20)\n",
        "print(kb.eval(l_y).shape)\n",
        "print(kb.eval(a_y).shape)\n",
        "# print(len(kb.eval(l_y)[0,:,0]))\n",
        "print('='*20)\n",
        "print(np.sum(kb.eval(l_y)[0,:,0]))\n",
        "print(np.sum(kb.eval(l_y)[0,:,100]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHrguM7QsINY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6ef199-fe53-482a-aeb4-75b306bb523c"
      },
      "source": [
        "# Load model (model compiling should be done first)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/' + str(train_model_number) + '/total_model/sentenceEM_total_model'\n",
        "sen_em_model.model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff682534908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4vZBkDHrPfm"
      },
      "source": [
        "\"\"\"\n",
        "utils.py\n",
        "\"\"\"\n",
        "\n",
        "def read_script_files(script_dir_path):\n",
        "    script_files = [f for f in listdir(script_dir_path) if isfile(join(script_dir_path, f))]\n",
        "    script_files.sort()\n",
        "    return script_files\n",
        "\n",
        "def read_script_file_data(script_dir_path, script_file):\n",
        "    curr_file = open(join(script_dir_path, script_file), 'r')\n",
        "    curr_file_lines = curr_file.readlines()\n",
        "    for i in range(len(curr_file_lines)):\n",
        "        words = curr_file_lines[i].split()[2: ]\n",
        "        curr_file_lines[i] = ' '.join(words)\n",
        "    return curr_file_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrgYrsZzrIcn"
      },
      "source": [
        "\"\"\"\n",
        "process_data.py\n",
        "\"\"\"\n",
        "\n",
        "def make_word_dictionary(relative_script_directory_path):\n",
        "    # Check whole word candidates\n",
        "    script_files = read_script_files(relative_script_directory_path)\n",
        "    total_words = set()\n",
        "    num = 0\n",
        "    for script_file in script_files:\n",
        "        num += 1\n",
        "        print('Processing {}/{}'.format(num, len(script_files)))\n",
        "        curr_file_lines = read_script_file_data(relative_script_directory_path, script_file)\n",
        "        for curr_file_line in curr_file_lines:\n",
        "            total_words.update(set(curr_file_line.split()))\n",
        "    total_words = list(total_words)\n",
        "    total_words.append(\"\")  # blank\n",
        "    total_words.append(\"OOV\")  # Out of vocabulary\n",
        "    total_words.sort()\n",
        "\n",
        "    # One-hot encoding\n",
        "    word_dictionary = dict()\n",
        "    word_dictionary_size = len(total_words)\n",
        "    for i in range(word_dictionary_size):\n",
        "        one_hot = np.zeros(word_dictionary_size)\n",
        "        one_hot[i] = 1\n",
        "        word_dictionary[total_words[i]] = one_hot\n",
        "    # print(word_dictionary)\n",
        "    return word_dictionary, word_dictionary_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6eppcGFq-hc"
      },
      "source": [
        "# Set word dictionary to check output of model later\n",
        "\n",
        "relative_script_directory_path = './drive/MyDrive/Speech2Pickup/train_script'\n",
        "word_dic, word_dic_size = make_word_dictionary(relative_script_directory_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_0fxHfmL-2D"
      },
      "source": [
        "# Check output of loaded model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "relative_data_directory_path = '/content/drive/MyDrive/Speech2Pickup/data_v2.2_single_channel'\n",
        "file_name = 'senEM_preprocessed.npz'\n",
        "n = 40123\n",
        "# data = load_single_npz_data(relative_data_directory_path=relative_data_directory_path, file_name=file_name)\n",
        "acoustic_train_batch = [data['acoustic'][n]]\n",
        "linguistic_train_batch = [data['linguistic'][n]]\n",
        "acoustic_train_batch = np.array(acoustic_train_batch, dtype=np.float32)\n",
        "linguistic_train_batch = np.array(linguistic_train_batch, dtype=np.float32)\n",
        "l_out, a_out = sen_em_model.model(acoustic_train_batch)\n",
        "\n",
        "l_out = np.squeeze(kb.eval(l_out))\n",
        "a_out = np.squeeze(kb.eval(a_out))\n",
        "l_true = np.squeeze(linguistic_train_batch)\n",
        "a_true = np.squeeze(acoustic_train_batch)\n",
        "\n",
        "l_out = np.argmax(l_out, axis=0)\n",
        "l_true = np.argmax(l_true, axis=0)\n",
        "\n",
        "true_sentence = []\n",
        "predicted_sentence = []\n",
        "word_dic_keys = list(word_dic.keys())\n",
        "n = 0\n",
        "for i in l_true:\n",
        "  if n==0:\n",
        "    true_sentence.append(word_dic_keys[i])\n",
        "  elif true_sentence[-1] != word_dic_keys[i]:\n",
        "    true_sentence.append(word_dic_keys[i])\n",
        "  n += 1\n",
        "n = 0\n",
        "for i in l_out:\n",
        "  if n==0:\n",
        "    predicted_sentence.append(word_dic_keys[i])\n",
        "  elif predicted_sentence[-1] != word_dic_keys[i]:\n",
        "    predicted_sentence.append(word_dic_keys[i])\n",
        "  n += 1\n",
        "true_sentence = ' '.join(true_sentence)\n",
        "predicted_sentence = ' '.join(predicted_sentence)\n",
        "print('True: {}'.format(true_sentence))\n",
        "print('Predict: {}'.format(predicted_sentence))\n",
        "\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.plot(l_out, label='prediction')\n",
        "ax.plot(l_true, label='ground truth')\n",
        "ax.set_title('Linguistic feature')\n",
        "ax.set_xlabel('Time step')\n",
        "ax.set_ylabel('Freq')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(25,15))\n",
        "img = librosa.display.specshow(data=a_true, sr=8000, hop_length=256,  x_axis='time',\n",
        "                            y_axis='mel', cmap='viridis', fmax=4000, ax=ax[0])\n",
        "ax[0].set(title='Mel specrogram - ground truth')\n",
        "ax[0].label_outer()\n",
        "\n",
        "img = librosa.display.specshow(data=a_out, sr=8000, hop_length=256,  x_axis='time',\n",
        "                            y_axis='mel', cmap='viridis', fmax=4000, ax=ax[1])\n",
        "ax[1].set(title='Mel specrogram - prediction')\n",
        "ax[1].label_outer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8hGflXHkJl4",
        "outputId": "1053e65d-0b21-4d8b-863f-c68970543d04"
      },
      "source": [
        "# Test and save for jointly training 'Speech2Pickup' (Debugging)\n",
        "\n",
        "sen_em_model.model.save_weights(filepath='/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/total_model/sentenceEM_total_model', overwrite=True)\n",
        "sen_em_model.encoder_model.save_weights(filepath='/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/encoder_model/sentenceEM_encoder_model', overwrite=True)\n",
        "print('Model saving complete!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model saving complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JihOgux0mKCk"
      },
      "source": [
        "# Compare sorting time\n",
        "\n",
        "import time\n",
        "ts = time.time()\n",
        "random.shuffle(data_files)\n",
        "te = time.time()\n",
        "print('String sort: {}'.format(te-ts))\n",
        "print(data_files)\n",
        "# ts = time.time()\n",
        "# random.shuffle(indexs)\n",
        "# te = time.time()\n",
        "# print('Int sort: {}'.format(te-ts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPa0THO1Umyn"
      },
      "source": [
        "# Test (Debugging)\n",
        "\n",
        "data = load_single_npz_data(relative_data_directory_path='/content/drive/MyDrive/Speech2Pickup/data_v2.2', file_name='senEM_preprocessed_100.npz')\n",
        "data1 = data['arr_0']\n",
        "data1 = np.float32(data1)\n",
        "data1 = kb.expand_dims(data1, axis=0)\n",
        "with tf.device('/device:GPU:0'):\n",
        "  l_y, a_y = sen_em_model(data1)\n",
        "print(kb.eval(a_y)[0,:,180])\n",
        "print('='*20)\n",
        "print(kb.eval(l_y)[0,:,180])\n",
        "print(len(kb.eval(l_y)[0,:,180]))\n",
        "print('='*20)\n",
        "print(np.sum(kb.eval(l_y)[0,:,180]))\n",
        "print(np.sum(kb.eval(l_y)[0,:,300]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jhil34yX5Ne"
      },
      "source": [
        "pdb.enable()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JciAh_P4Is6"
      },
      "source": [
        "# Test (Debugging)\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "x = tf.convert_to_tensor(np.ones((1, 40, 303)), dtype=np.float32)   # batch, dim, seq_len\n",
        "l_y, a_y = sen_em_model.model(x)\n",
        "print(kb.eval(l_y).shape)\n",
        "print(kb.eval(a_y).shape)\n",
        "# mid = sen_em_model.encoder_model(x)\n",
        "# print('='*20)\n",
        "# print(kb.eval(l_y)[0,:,200])\n",
        "# out = np.squeeze(kb.eval(l_y))\n",
        "# subtract = out[:, :10] - np.fliplr(out[:, 293:])\n",
        "# print(subtract)\n",
        "# print(out[:, :10])\n",
        "# print('='*20)\n",
        "# print(out[:, 293:])\n",
        "# plt.imshow(out[:, :10], aspect='auto')\n",
        "# plt.show()\n",
        "# plt.imshow(out[:, 293:], aspect='auto')\n",
        "# print(len(kb.eval(l_y)[0,:,:]))\n",
        "# print(np.sum(kb.eval(l_y)[0,:,0]))\n",
        "# print(np.sum(kb.eval(l_y)[0,:,100]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOYD86EfeZoj"
      },
      "source": [
        "# print(kb.eval(l_y)[0,:,234:238])\n",
        "# print(kb.eval(l_y)[0,:,298:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "013hJm5c0SWq"
      },
      "source": [
        "x = tf.convert_to_tensor(np.ones((1, 40, 303)), dtype=np.float32)   # batch, dim, seq_len\n",
        "embedding = sen_em_model.encoder_model(x)\n",
        "print(kb.eval(embedding))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuoHjdx1NRCq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}