{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "run_HGN_senEM_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw3YiVt838Tn"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFqZe5eq7wrP",
        "outputId": "9089520a-6a6e-4eb1-819a-d17490af4673"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrwDjFKOu4Jg",
        "outputId": "7d730990-eea2-4793-f66c-35625822be5d"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e83VV0wby26c"
      },
      "source": [
        "% pip install wandb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8op54dlA38Tn"
      },
      "source": [
        "# Import dependencies\n",
        "\n",
        "from os import listdir, remove, makedirs\n",
        "from os.path import join, isdir, isfile\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import variable_scope as vs\n",
        "import tensorflow.keras.layers as layers\n",
        "import wandb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR5nqGf3SfJf",
        "outputId": "99516d14-1f4a-4848-d32c-b7dfbab79c93"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mawesomericky\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3CHnzG4yaXB"
      },
      "source": [
        "# Import python files\n",
        "\n",
        "from utils import HGN_organize_data, HGN_divide_train_test\n",
        "from code_HGN_senEM_train import train"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OGQHCK_38Tn"
      },
      "source": [
        "## Load Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqqjCosb38Tn",
        "outputId": "6b35842d-ace8-42db-de97-9fa33d61dabe"
      },
      "source": [
        "relative_data_directory_path = '/content/drive/MyDrive/Speech2Pickup/data_v1.2_single_channel/preprocessed4HGN_speech2pickup.npz'\n",
        "    \n",
        "data = np.load(relative_data_directory_path)\n",
        "\n",
        "img_idx = data['img_idx']\n",
        "sen_len = data['seq_len']\n",
        "speech_inputs = data['inputs']\n",
        "pos_outputs = data['outputs']\n",
        "sentence = data['sentence']\n",
        "\n",
        "print('End loading MetaData')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End loading MetaData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_dqmGhN38Tn"
      },
      "source": [
        "## Load data and divide training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlqqLiDe38To",
        "outputId": "f465e0b5-2962-49ab-d3ba-89d31fe00618"
      },
      "source": [
        "num_data = img_idx.shape[0]\n",
        "\n",
        "img_path = '/content/drive/MyDrive/Speech2Pickup/train_img'\n",
        "script_path = '/content/drive/MyDrive/Speech2Pickup/train_heatmap'\n",
        "\n",
        "total_images, total_heatmaps = HGN_organize_data(img_path, script_path, model_type='speech2pickup');\n",
        "\n",
        "args = dict()\n",
        "args['img_idx'] = img_idx\n",
        "args['speech_inputs'] = speech_inputs\n",
        "args['pos_outputs'] = pos_outputs\n",
        "args['num_data'] = num_data\n",
        "\n",
        "idx_train, idx_test, num_train, num_test, \\\n",
        "train_img_idx, train_speech_inputs, train_pos_outputs, \\\n",
        "test_img_idx, test_speech_inputs, test_pos_outputs = \\\n",
        "HGN_divide_train_test(args, model_type='speech2pickup')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading image..\n",
            "Loading 1/478\n",
            "Loading 2/478\n",
            "Loading 3/478\n",
            "Loading 4/478\n",
            "Loading 5/478\n",
            "Loading 6/478\n",
            "Loading 7/478\n",
            "Loading 8/478\n",
            "Loading 9/478\n",
            "Loading 10/478\n",
            "Loading 11/478\n",
            "Loading 12/478\n",
            "Loading 13/478\n",
            "Loading 14/478\n",
            "Loading 15/478\n",
            "Loading 16/478\n",
            "Loading 17/478\n",
            "Loading 18/478\n",
            "Loading 19/478\n",
            "Loading 20/478\n",
            "Loading 21/478\n",
            "Loading 22/478\n",
            "Loading 23/478\n",
            "Loading 24/478\n",
            "Loading 25/478\n",
            "Loading 26/478\n",
            "Loading 27/478\n",
            "Loading 28/478\n",
            "Loading 29/478\n",
            "Loading 30/478\n",
            "Loading 31/478\n",
            "Loading 32/478\n",
            "Loading 33/478\n",
            "Loading 34/478\n",
            "Loading 35/478\n",
            "Loading 36/478\n",
            "Loading 37/478\n",
            "Loading 38/478\n",
            "Loading 39/478\n",
            "Loading 40/478\n",
            "Loading 41/478\n",
            "Loading 42/478\n",
            "Loading 43/478\n",
            "Loading 44/478\n",
            "Loading 45/478\n",
            "Loading 46/478\n",
            "Loading 47/478\n",
            "Loading 48/478\n",
            "Loading 49/478\n",
            "Loading 50/478\n",
            "Loading 51/478\n",
            "Loading 52/478\n",
            "Loading 53/478\n",
            "Loading 54/478\n",
            "Loading 55/478\n",
            "Loading 56/478\n",
            "Loading 57/478\n",
            "Loading 58/478\n",
            "Loading 59/478\n",
            "Loading 60/478\n",
            "Loading 61/478\n",
            "Loading 62/478\n",
            "Loading 63/478\n",
            "Loading 64/478\n",
            "Loading 65/478\n",
            "Loading 66/478\n",
            "Loading 67/478\n",
            "Loading 68/478\n",
            "Loading 69/478\n",
            "Loading 70/478\n",
            "Loading 71/478\n",
            "Loading 72/478\n",
            "Loading 73/478\n",
            "Loading 74/478\n",
            "Loading 75/478\n",
            "Loading 76/478\n",
            "Loading 77/478\n",
            "Loading 78/478\n",
            "Loading 79/478\n",
            "Loading 80/478\n",
            "Loading 81/478\n",
            "Loading 82/478\n",
            "Loading 83/478\n",
            "Loading 84/478\n",
            "Loading 85/478\n",
            "Loading 86/478\n",
            "Loading 87/478\n",
            "Loading 88/478\n",
            "Loading 89/478\n",
            "Loading 90/478\n",
            "Loading 91/478\n",
            "Loading 92/478\n",
            "Loading 93/478\n",
            "Loading 94/478\n",
            "Loading 95/478\n",
            "Loading 96/478\n",
            "Loading 97/478\n",
            "Loading 98/478\n",
            "Loading 99/478\n",
            "Loading 100/478\n",
            "Loading 101/478\n",
            "Loading 102/478\n",
            "Loading 103/478\n",
            "Loading 104/478\n",
            "Loading 105/478\n",
            "Loading 106/478\n",
            "Loading 107/478\n",
            "Loading 108/478\n",
            "Loading 109/478\n",
            "Loading 110/478\n",
            "Loading 111/478\n",
            "Loading 112/478\n",
            "Loading 113/478\n",
            "Loading 114/478\n",
            "Loading 115/478\n",
            "Loading 116/478\n",
            "Loading 117/478\n",
            "Loading 118/478\n",
            "Loading 119/478\n",
            "Loading 120/478\n",
            "Loading 121/478\n",
            "Loading 122/478\n",
            "Loading 123/478\n",
            "Loading 124/478\n",
            "Loading 125/478\n",
            "Loading 126/478\n",
            "Loading 127/478\n",
            "Loading 128/478\n",
            "Loading 129/478\n",
            "Loading 130/478\n",
            "Loading 131/478\n",
            "Loading 132/478\n",
            "Loading 133/478\n",
            "Loading 134/478\n",
            "Loading 135/478\n",
            "Loading 136/478\n",
            "Loading 137/478\n",
            "Loading 138/478\n",
            "Loading 139/478\n",
            "Loading 140/478\n",
            "Loading 141/478\n",
            "Loading 142/478\n",
            "Loading 143/478\n",
            "Loading 144/478\n",
            "Loading 145/478\n",
            "Loading 146/478\n",
            "Loading 147/478\n",
            "Loading 148/478\n",
            "Loading 149/478\n",
            "Loading 150/478\n",
            "Loading 151/478\n",
            "Loading 152/478\n",
            "Loading 153/478\n",
            "Loading 154/478\n",
            "Loading 155/478\n",
            "Loading 156/478\n",
            "Loading 157/478\n",
            "Loading 158/478\n",
            "Loading 159/478\n",
            "Loading 160/478\n",
            "Loading 161/478\n",
            "Loading 162/478\n",
            "Loading 163/478\n",
            "Loading 164/478\n",
            "Loading 165/478\n",
            "Loading 166/478\n",
            "Loading 167/478\n",
            "Loading 168/478\n",
            "Loading 169/478\n",
            "Loading 170/478\n",
            "Loading 171/478\n",
            "Loading 172/478\n",
            "Loading 173/478\n",
            "Loading 174/478\n",
            "Loading 175/478\n",
            "Loading 176/478\n",
            "Loading 177/478\n",
            "Loading 178/478\n",
            "Loading 179/478\n",
            "Loading 180/478\n",
            "Loading 181/478\n",
            "Loading 182/478\n",
            "Loading 183/478\n",
            "Loading 184/478\n",
            "Loading 185/478\n",
            "Loading 186/478\n",
            "Loading 187/478\n",
            "Loading 188/478\n",
            "Loading 189/478\n",
            "Loading 190/478\n",
            "Loading 191/478\n",
            "Loading 192/478\n",
            "Loading 193/478\n",
            "Loading 194/478\n",
            "Loading 195/478\n",
            "Loading 196/478\n",
            "Loading 197/478\n",
            "Loading 198/478\n",
            "Loading 199/478\n",
            "Loading 200/478\n",
            "Loading 201/478\n",
            "Loading 202/478\n",
            "Loading 203/478\n",
            "Loading 204/478\n",
            "Loading 205/478\n",
            "Loading 206/478\n",
            "Loading 207/478\n",
            "Loading 208/478\n",
            "Loading 209/478\n",
            "Loading 210/478\n",
            "Loading 211/478\n",
            "Loading 212/478\n",
            "Loading 213/478\n",
            "Loading 214/478\n",
            "Loading 215/478\n",
            "Loading 216/478\n",
            "Loading 217/478\n",
            "Loading 218/478\n",
            "Loading 219/478\n",
            "Loading 220/478\n",
            "Loading 221/478\n",
            "Loading 222/478\n",
            "Loading 223/478\n",
            "Loading 224/478\n",
            "Loading 225/478\n",
            "Loading 226/478\n",
            "Loading 227/478\n",
            "Loading 228/478\n",
            "Loading 229/478\n",
            "Loading 230/478\n",
            "Loading 231/478\n",
            "Loading 232/478\n",
            "Loading 233/478\n",
            "Loading 234/478\n",
            "Loading 235/478\n",
            "Loading 236/478\n",
            "Loading 237/478\n",
            "Loading 238/478\n",
            "Loading 239/478\n",
            "Loading 240/478\n",
            "Loading 241/478\n",
            "Loading 242/478\n",
            "Loading 243/478\n",
            "Loading 244/478\n",
            "Loading 245/478\n",
            "Loading 246/478\n",
            "Loading 247/478\n",
            "Loading 248/478\n",
            "Loading 249/478\n",
            "Loading 250/478\n",
            "Loading 251/478\n",
            "Loading 252/478\n",
            "Loading 253/478\n",
            "Loading 254/478\n",
            "Loading 255/478\n",
            "Loading 256/478\n",
            "Loading 257/478\n",
            "Loading 258/478\n",
            "Loading 259/478\n",
            "Loading 260/478\n",
            "Loading 261/478\n",
            "Loading 262/478\n",
            "Loading 263/478\n",
            "Loading 264/478\n",
            "Loading 265/478\n",
            "Loading 266/478\n",
            "Loading 267/478\n",
            "Loading 268/478\n",
            "Loading 269/478\n",
            "Loading 270/478\n",
            "Loading 271/478\n",
            "Loading 272/478\n",
            "Loading 273/478\n",
            "Loading 274/478\n",
            "Loading 275/478\n",
            "Loading 276/478\n",
            "Loading 277/478\n",
            "Loading 278/478\n",
            "Loading 279/478\n",
            "Loading 280/478\n",
            "Loading 281/478\n",
            "Loading 282/478\n",
            "Loading 283/478\n",
            "Loading 284/478\n",
            "Loading 285/478\n",
            "Loading 286/478\n",
            "Loading 287/478\n",
            "Loading 288/478\n",
            "Loading 289/478\n",
            "Loading 290/478\n",
            "Loading 291/478\n",
            "Loading 292/478\n",
            "Loading 293/478\n",
            "Loading 294/478\n",
            "Loading 295/478\n",
            "Loading 296/478\n",
            "Loading 297/478\n",
            "Loading 298/478\n",
            "Loading 299/478\n",
            "Loading 300/478\n",
            "Loading 301/478\n",
            "Loading 302/478\n",
            "Loading 303/478\n",
            "Loading 304/478\n",
            "Loading 305/478\n",
            "Loading 306/478\n",
            "Loading 307/478\n",
            "Loading 308/478\n",
            "Loading 309/478\n",
            "Loading 310/478\n",
            "Loading 311/478\n",
            "Loading 312/478\n",
            "Loading 313/478\n",
            "Loading 314/478\n",
            "Loading 315/478\n",
            "Loading 316/478\n",
            "Loading 317/478\n",
            "Loading 318/478\n",
            "Loading 319/478\n",
            "Loading 320/478\n",
            "Loading 321/478\n",
            "Loading 322/478\n",
            "Loading 323/478\n",
            "Loading 324/478\n",
            "Loading 325/478\n",
            "Loading 326/478\n",
            "Loading 327/478\n",
            "Loading 328/478\n",
            "Loading 329/478\n",
            "Loading 330/478\n",
            "Loading 331/478\n",
            "Loading 332/478\n",
            "Loading 333/478\n",
            "Loading 334/478\n",
            "Loading 335/478\n",
            "Loading 336/478\n",
            "Loading 337/478\n",
            "Loading 338/478\n",
            "Loading 339/478\n",
            "Loading 340/478\n",
            "Loading 341/478\n",
            "Loading 342/478\n",
            "Loading 343/478\n",
            "Loading 344/478\n",
            "Loading 345/478\n",
            "Loading 346/478\n",
            "Loading 347/478\n",
            "Loading 348/478\n",
            "Loading 349/478\n",
            "Loading 350/478\n",
            "Loading 351/478\n",
            "Loading 352/478\n",
            "Loading 353/478\n",
            "Loading 354/478\n",
            "Loading 355/478\n",
            "Loading 356/478\n",
            "Loading 357/478\n",
            "Loading 358/478\n",
            "Loading 359/478\n",
            "Loading 360/478\n",
            "Loading 361/478\n",
            "Loading 362/478\n",
            "Loading 363/478\n",
            "Loading 364/478\n",
            "Loading 365/478\n",
            "Loading 366/478\n",
            "Loading 367/478\n",
            "Loading 368/478\n",
            "Loading 369/478\n",
            "Loading 370/478\n",
            "Loading 371/478\n",
            "Loading 372/478\n",
            "Loading 373/478\n",
            "Loading 374/478\n",
            "Loading 375/478\n",
            "Loading 376/478\n",
            "Loading 377/478\n",
            "Loading 378/478\n",
            "Loading 379/478\n",
            "Loading 380/478\n",
            "Loading 381/478\n",
            "Loading 382/478\n",
            "Loading 383/478\n",
            "Loading 384/478\n",
            "Loading 385/478\n",
            "Loading 386/478\n",
            "Loading 387/478\n",
            "Loading 388/478\n",
            "Loading 389/478\n",
            "Loading 390/478\n",
            "Loading 391/478\n",
            "Loading 392/478\n",
            "Loading 393/478\n",
            "Loading 394/478\n",
            "Loading 395/478\n",
            "Loading 396/478\n",
            "Loading 397/478\n",
            "Loading 398/478\n",
            "Loading 399/478\n",
            "Loading 400/478\n",
            "Loading 401/478\n",
            "Loading 402/478\n",
            "Loading 403/478\n",
            "Loading 404/478\n",
            "Loading 405/478\n",
            "Loading 406/478\n",
            "Loading 407/478\n",
            "Loading 408/478\n",
            "Loading 409/478\n",
            "Loading 410/478\n",
            "Loading 411/478\n",
            "Loading 412/478\n",
            "Loading 413/478\n",
            "Loading 414/478\n",
            "Loading 415/478\n",
            "Loading 416/478\n",
            "Loading 417/478\n",
            "Loading 418/478\n",
            "Loading 419/478\n",
            "Loading 420/478\n",
            "Loading 421/478\n",
            "Loading 422/478\n",
            "Loading 423/478\n",
            "Loading 424/478\n",
            "Loading 425/478\n",
            "Loading 426/478\n",
            "Loading 427/478\n",
            "Loading 428/478\n",
            "Loading 429/478\n",
            "Loading 430/478\n",
            "Loading 431/478\n",
            "Loading 432/478\n",
            "Loading 433/478\n",
            "Loading 434/478\n",
            "Loading 435/478\n",
            "Loading 436/478\n",
            "Loading 437/478\n",
            "Loading 438/478\n",
            "Loading 439/478\n",
            "Loading 440/478\n",
            "Loading 441/478\n",
            "Loading 442/478\n",
            "Loading 443/478\n",
            "Loading 444/478\n",
            "Loading 445/478\n",
            "Loading 446/478\n",
            "Loading 447/478\n",
            "Loading 448/478\n",
            "Loading 449/478\n",
            "Loading 450/478\n",
            "Loading 451/478\n",
            "Loading 452/478\n",
            "Loading 453/478\n",
            "Loading 454/478\n",
            "Loading 455/478\n",
            "Loading 456/478\n",
            "Loading 457/478\n",
            "Loading 458/478\n",
            "Loading 459/478\n",
            "Loading 460/478\n",
            "Loading 461/478\n",
            "Loading 462/478\n",
            "Loading 463/478\n",
            "Loading 464/478\n",
            "Loading 465/478\n",
            "Loading 466/478\n",
            "Loading 467/478\n",
            "Loading 468/478\n",
            "Loading 469/478\n",
            "Loading 470/478\n",
            "Loading 471/478\n",
            "Loading 472/478\n",
            "Loading 473/478\n",
            "Loading 474/478\n",
            "Loading 475/478\n",
            "Loading 476/478\n",
            "Loading 477/478\n",
            "Loading 478/478\n",
            "Loading heatmap..\n",
            "Loading 1/2134\n",
            "Loading 2/2134\n",
            "Loading 3/2134\n",
            "Loading 4/2134\n",
            "Loading 5/2134\n",
            "Loading 6/2134\n",
            "Loading 7/2134\n",
            "Loading 8/2134\n",
            "Loading 9/2134\n",
            "Loading 10/2134\n",
            "Loading 11/2134\n",
            "Loading 12/2134\n",
            "Loading 13/2134\n",
            "Loading 14/2134\n",
            "Loading 15/2134\n",
            "Loading 16/2134\n",
            "Loading 17/2134\n",
            "Loading 18/2134\n",
            "Loading 19/2134\n",
            "Loading 20/2134\n",
            "Loading 21/2134\n",
            "Loading 22/2134\n",
            "Loading 23/2134\n",
            "Loading 24/2134\n",
            "Loading 25/2134\n",
            "Loading 26/2134\n",
            "Loading 27/2134\n",
            "Loading 28/2134\n",
            "Loading 29/2134\n",
            "Loading 30/2134\n",
            "Loading 31/2134\n",
            "Loading 32/2134\n",
            "Loading 33/2134\n",
            "Loading 34/2134\n",
            "Loading 35/2134\n",
            "Loading 36/2134\n",
            "Loading 37/2134\n",
            "Loading 38/2134\n",
            "Loading 39/2134\n",
            "Loading 40/2134\n",
            "Loading 41/2134\n",
            "Loading 42/2134\n",
            "Loading 43/2134\n",
            "Loading 44/2134\n",
            "Loading 45/2134\n",
            "Loading 46/2134\n",
            "Loading 47/2134\n",
            "Loading 48/2134\n",
            "Loading 49/2134\n",
            "Loading 50/2134\n",
            "Loading 51/2134\n",
            "Loading 52/2134\n",
            "Loading 53/2134\n",
            "Loading 54/2134\n",
            "Loading 55/2134\n",
            "Loading 56/2134\n",
            "Loading 57/2134\n",
            "Loading 58/2134\n",
            "Loading 59/2134\n",
            "Loading 60/2134\n",
            "Loading 61/2134\n",
            "Loading 62/2134\n",
            "Loading 63/2134\n",
            "Loading 64/2134\n",
            "Loading 65/2134\n",
            "Loading 66/2134\n",
            "Loading 67/2134\n",
            "Loading 68/2134\n",
            "Loading 69/2134\n",
            "Loading 70/2134\n",
            "Loading 71/2134\n",
            "Loading 72/2134\n",
            "Loading 73/2134\n",
            "Loading 74/2134\n",
            "Loading 75/2134\n",
            "Loading 76/2134\n",
            "Loading 77/2134\n",
            "Loading 78/2134\n",
            "Loading 79/2134\n",
            "Loading 80/2134\n",
            "Loading 81/2134\n",
            "Loading 82/2134\n",
            "Loading 83/2134\n",
            "Loading 84/2134\n",
            "Loading 85/2134\n",
            "Loading 86/2134\n",
            "Loading 87/2134\n",
            "Loading 88/2134\n",
            "Loading 89/2134\n",
            "Loading 90/2134\n",
            "Loading 91/2134\n",
            "Loading 92/2134\n",
            "Loading 93/2134\n",
            "Loading 94/2134\n",
            "Loading 95/2134\n",
            "Loading 96/2134\n",
            "Loading 97/2134\n",
            "Loading 98/2134\n",
            "Loading 99/2134\n",
            "Loading 100/2134\n",
            "Loading 101/2134\n",
            "Loading 102/2134\n",
            "Loading 103/2134\n",
            "Loading 104/2134\n",
            "Loading 105/2134\n",
            "Loading 106/2134\n",
            "Loading 107/2134\n",
            "Loading 108/2134\n",
            "Loading 109/2134\n",
            "Loading 110/2134\n",
            "Loading 111/2134\n",
            "Loading 112/2134\n",
            "Loading 113/2134\n",
            "Loading 114/2134\n",
            "Loading 115/2134\n",
            "Loading 116/2134\n",
            "Loading 117/2134\n",
            "Loading 118/2134\n",
            "Loading 119/2134\n",
            "Loading 120/2134\n",
            "Loading 121/2134\n",
            "Loading 122/2134\n",
            "Loading 123/2134\n",
            "Loading 124/2134\n",
            "Loading 125/2134\n",
            "Loading 126/2134\n",
            "Loading 127/2134\n",
            "Loading 128/2134\n",
            "Loading 129/2134\n",
            "Loading 130/2134\n",
            "Loading 131/2134\n",
            "Loading 132/2134\n",
            "Loading 133/2134\n",
            "Loading 134/2134\n",
            "Loading 135/2134\n",
            "Loading 136/2134\n",
            "Loading 137/2134\n",
            "Loading 138/2134\n",
            "Loading 139/2134\n",
            "Loading 140/2134\n",
            "Loading 141/2134\n",
            "Loading 142/2134\n",
            "Loading 143/2134\n",
            "Loading 144/2134\n",
            "Loading 145/2134\n",
            "Loading 146/2134\n",
            "Loading 147/2134\n",
            "Loading 148/2134\n",
            "Loading 149/2134\n",
            "Loading 150/2134\n",
            "Loading 151/2134\n",
            "Loading 152/2134\n",
            "Loading 153/2134\n",
            "Loading 154/2134\n",
            "Loading 155/2134\n",
            "Loading 156/2134\n",
            "Loading 157/2134\n",
            "Loading 158/2134\n",
            "Loading 159/2134\n",
            "Loading 160/2134\n",
            "Loading 161/2134\n",
            "Loading 162/2134\n",
            "Loading 163/2134\n",
            "Loading 164/2134\n",
            "Loading 165/2134\n",
            "Loading 166/2134\n",
            "Loading 167/2134\n",
            "Loading 168/2134\n",
            "Loading 169/2134\n",
            "Loading 170/2134\n",
            "Loading 171/2134\n",
            "Loading 172/2134\n",
            "Loading 173/2134\n",
            "Loading 174/2134\n",
            "Loading 175/2134\n",
            "Loading 176/2134\n",
            "Loading 177/2134\n",
            "Loading 178/2134\n",
            "Loading 179/2134\n",
            "Loading 180/2134\n",
            "Loading 181/2134\n",
            "Loading 182/2134\n",
            "Loading 183/2134\n",
            "Loading 184/2134\n",
            "Loading 185/2134\n",
            "Loading 186/2134\n",
            "Loading 187/2134\n",
            "Loading 188/2134\n",
            "Loading 189/2134\n",
            "Loading 190/2134\n",
            "Loading 191/2134\n",
            "Loading 192/2134\n",
            "Loading 193/2134\n",
            "Loading 194/2134\n",
            "Loading 195/2134\n",
            "Loading 196/2134\n",
            "Loading 197/2134\n",
            "Loading 198/2134\n",
            "Loading 199/2134\n",
            "Loading 200/2134\n",
            "Loading 201/2134\n",
            "Loading 202/2134\n",
            "Loading 203/2134\n",
            "Loading 204/2134\n",
            "Loading 205/2134\n",
            "Loading 206/2134\n",
            "Loading 207/2134\n",
            "Loading 208/2134\n",
            "Loading 209/2134\n",
            "Loading 210/2134\n",
            "Loading 211/2134\n",
            "Loading 212/2134\n",
            "Loading 213/2134\n",
            "Loading 214/2134\n",
            "Loading 215/2134\n",
            "Loading 216/2134\n",
            "Loading 217/2134\n",
            "Loading 218/2134\n",
            "Loading 219/2134\n",
            "Loading 220/2134\n",
            "Loading 221/2134\n",
            "Loading 222/2134\n",
            "Loading 223/2134\n",
            "Loading 224/2134\n",
            "Loading 225/2134\n",
            "Loading 226/2134\n",
            "Loading 227/2134\n",
            "Loading 228/2134\n",
            "Loading 229/2134\n",
            "Loading 230/2134\n",
            "Loading 231/2134\n",
            "Loading 232/2134\n",
            "Loading 233/2134\n",
            "Loading 234/2134\n",
            "Loading 235/2134\n",
            "Loading 236/2134\n",
            "Loading 237/2134\n",
            "Loading 238/2134\n",
            "Loading 239/2134\n",
            "Loading 240/2134\n",
            "Loading 241/2134\n",
            "Loading 242/2134\n",
            "Loading 243/2134\n",
            "Loading 244/2134\n",
            "Loading 245/2134\n",
            "Loading 246/2134\n",
            "Loading 247/2134\n",
            "Loading 248/2134\n",
            "Loading 249/2134\n",
            "Loading 250/2134\n",
            "Loading 251/2134\n",
            "Loading 252/2134\n",
            "Loading 253/2134\n",
            "Loading 254/2134\n",
            "Loading 255/2134\n",
            "Loading 256/2134\n",
            "Loading 257/2134\n",
            "Loading 258/2134\n",
            "Loading 259/2134\n",
            "Loading 260/2134\n",
            "Loading 261/2134\n",
            "Loading 262/2134\n",
            "Loading 263/2134\n",
            "Loading 264/2134\n",
            "Loading 265/2134\n",
            "Loading 266/2134\n",
            "Loading 267/2134\n",
            "Loading 268/2134\n",
            "Loading 269/2134\n",
            "Loading 270/2134\n",
            "Loading 271/2134\n",
            "Loading 272/2134\n",
            "Loading 273/2134\n",
            "Loading 274/2134\n",
            "Loading 275/2134\n",
            "Loading 276/2134\n",
            "Loading 277/2134\n",
            "Loading 278/2134\n",
            "Loading 279/2134\n",
            "Loading 280/2134\n",
            "Loading 281/2134\n",
            "Loading 282/2134\n",
            "Loading 283/2134\n",
            "Loading 284/2134\n",
            "Loading 285/2134\n",
            "Loading 286/2134\n",
            "Loading 287/2134\n",
            "Loading 288/2134\n",
            "Loading 289/2134\n",
            "Loading 290/2134\n",
            "Loading 291/2134\n",
            "Loading 292/2134\n",
            "Loading 293/2134\n",
            "Loading 294/2134\n",
            "Loading 295/2134\n",
            "Loading 296/2134\n",
            "Loading 297/2134\n",
            "Loading 298/2134\n",
            "Loading 299/2134\n",
            "Loading 300/2134\n",
            "Loading 301/2134\n",
            "Loading 302/2134\n",
            "Loading 303/2134\n",
            "Loading 304/2134\n",
            "Loading 305/2134\n",
            "Loading 306/2134\n",
            "Loading 307/2134\n",
            "Loading 308/2134\n",
            "Loading 309/2134\n",
            "Loading 310/2134\n",
            "Loading 311/2134\n",
            "Loading 312/2134\n",
            "Loading 313/2134\n",
            "Loading 314/2134\n",
            "Loading 315/2134\n",
            "Loading 316/2134\n",
            "Loading 317/2134\n",
            "Loading 318/2134\n",
            "Loading 319/2134\n",
            "Loading 320/2134\n",
            "Loading 321/2134\n",
            "Loading 322/2134\n",
            "Loading 323/2134\n",
            "Loading 324/2134\n",
            "Loading 325/2134\n",
            "Loading 326/2134\n",
            "Loading 327/2134\n",
            "Loading 328/2134\n",
            "Loading 329/2134\n",
            "Loading 330/2134\n",
            "Loading 331/2134\n",
            "Loading 332/2134\n",
            "Loading 333/2134\n",
            "Loading 334/2134\n",
            "Loading 335/2134\n",
            "Loading 336/2134\n",
            "Loading 337/2134\n",
            "Loading 338/2134\n",
            "Loading 339/2134\n",
            "Loading 340/2134\n",
            "Loading 341/2134\n",
            "Loading 342/2134\n",
            "Loading 343/2134\n",
            "Loading 344/2134\n",
            "Loading 345/2134\n",
            "Loading 346/2134\n",
            "Loading 347/2134\n",
            "Loading 348/2134\n",
            "Loading 349/2134\n",
            "Loading 350/2134\n",
            "Loading 351/2134\n",
            "Loading 352/2134\n",
            "Loading 353/2134\n",
            "Loading 354/2134\n",
            "Loading 355/2134\n",
            "Loading 356/2134\n",
            "Loading 357/2134\n",
            "Loading 358/2134\n",
            "Loading 359/2134\n",
            "Loading 360/2134\n",
            "Loading 361/2134\n",
            "Loading 362/2134\n",
            "Loading 363/2134\n",
            "Loading 364/2134\n",
            "Loading 365/2134\n",
            "Loading 366/2134\n",
            "Loading 367/2134\n",
            "Loading 368/2134\n",
            "Loading 369/2134\n",
            "Loading 370/2134\n",
            "Loading 371/2134\n",
            "Loading 372/2134\n",
            "Loading 373/2134\n",
            "Loading 374/2134\n",
            "Loading 375/2134\n",
            "Loading 376/2134\n",
            "Loading 377/2134\n",
            "Loading 378/2134\n",
            "Loading 379/2134\n",
            "Loading 380/2134\n",
            "Loading 381/2134\n",
            "Loading 382/2134\n",
            "Loading 383/2134\n",
            "Loading 384/2134\n",
            "Loading 385/2134\n",
            "Loading 386/2134\n",
            "Loading 387/2134\n",
            "Loading 388/2134\n",
            "Loading 389/2134\n",
            "Loading 390/2134\n",
            "Loading 391/2134\n",
            "Loading 392/2134\n",
            "Loading 393/2134\n",
            "Loading 394/2134\n",
            "Loading 395/2134\n",
            "Loading 396/2134\n",
            "Loading 397/2134\n",
            "Loading 398/2134\n",
            "Loading 399/2134\n",
            "Loading 400/2134\n",
            "Loading 401/2134\n",
            "Loading 402/2134\n",
            "Loading 403/2134\n",
            "Loading 404/2134\n",
            "Loading 405/2134\n",
            "Loading 406/2134\n",
            "Loading 407/2134\n",
            "Loading 408/2134\n",
            "Loading 409/2134\n",
            "Loading 410/2134\n",
            "Loading 411/2134\n",
            "Loading 412/2134\n",
            "Loading 413/2134\n",
            "Loading 414/2134\n",
            "Loading 415/2134\n",
            "Loading 416/2134\n",
            "Loading 417/2134\n",
            "Loading 418/2134\n",
            "Loading 419/2134\n",
            "Loading 420/2134\n",
            "Loading 421/2134\n",
            "Loading 422/2134\n",
            "Loading 423/2134\n",
            "Loading 424/2134\n",
            "Loading 425/2134\n",
            "Loading 426/2134\n",
            "Loading 427/2134\n",
            "Loading 428/2134\n",
            "Loading 429/2134\n",
            "Loading 430/2134\n",
            "Loading 431/2134\n",
            "Loading 432/2134\n",
            "Loading 433/2134\n",
            "Loading 434/2134\n",
            "Loading 435/2134\n",
            "Loading 436/2134\n",
            "Loading 437/2134\n",
            "Loading 438/2134\n",
            "Loading 439/2134\n",
            "Loading 440/2134\n",
            "Loading 441/2134\n",
            "Loading 442/2134\n",
            "Loading 443/2134\n",
            "Loading 444/2134\n",
            "Loading 445/2134\n",
            "Loading 446/2134\n",
            "Loading 447/2134\n",
            "Loading 448/2134\n",
            "Loading 449/2134\n",
            "Loading 450/2134\n",
            "Loading 451/2134\n",
            "Loading 452/2134\n",
            "Loading 453/2134\n",
            "Loading 454/2134\n",
            "Loading 455/2134\n",
            "Loading 456/2134\n",
            "Loading 457/2134\n",
            "Loading 458/2134\n",
            "Loading 459/2134\n",
            "Loading 460/2134\n",
            "Loading 461/2134\n",
            "Loading 462/2134\n",
            "Loading 463/2134\n",
            "Loading 464/2134\n",
            "Loading 465/2134\n",
            "Loading 466/2134\n",
            "Loading 467/2134\n",
            "Loading 468/2134\n",
            "Loading 469/2134\n",
            "Loading 470/2134\n",
            "Loading 471/2134\n",
            "Loading 472/2134\n",
            "Loading 473/2134\n",
            "Loading 474/2134\n",
            "Loading 475/2134\n",
            "Loading 476/2134\n",
            "Loading 477/2134\n",
            "Loading 478/2134\n",
            "Loading 479/2134\n",
            "Loading 480/2134\n",
            "Loading 481/2134\n",
            "Loading 482/2134\n",
            "Loading 483/2134\n",
            "Loading 484/2134\n",
            "Loading 485/2134\n",
            "Loading 486/2134\n",
            "Loading 487/2134\n",
            "Loading 488/2134\n",
            "Loading 489/2134\n",
            "Loading 490/2134\n",
            "Loading 491/2134\n",
            "Loading 492/2134\n",
            "Loading 493/2134\n",
            "Loading 494/2134\n",
            "Loading 495/2134\n",
            "Loading 496/2134\n",
            "Loading 497/2134\n",
            "Loading 498/2134\n",
            "Loading 499/2134\n",
            "Loading 500/2134\n",
            "Loading 501/2134\n",
            "Loading 502/2134\n",
            "Loading 503/2134\n",
            "Loading 504/2134\n",
            "Loading 505/2134\n",
            "Loading 506/2134\n",
            "Loading 507/2134\n",
            "Loading 508/2134\n",
            "Loading 509/2134\n",
            "Loading 510/2134\n",
            "Loading 511/2134\n",
            "Loading 512/2134\n",
            "Loading 513/2134\n",
            "Loading 514/2134\n",
            "Loading 515/2134\n",
            "Loading 516/2134\n",
            "Loading 517/2134\n",
            "Loading 518/2134\n",
            "Loading 519/2134\n",
            "Loading 520/2134\n",
            "Loading 521/2134\n",
            "Loading 522/2134\n",
            "Loading 523/2134\n",
            "Loading 524/2134\n",
            "Loading 525/2134\n",
            "Loading 526/2134\n",
            "Loading 527/2134\n",
            "Loading 528/2134\n",
            "Loading 529/2134\n",
            "Loading 530/2134\n",
            "Loading 531/2134\n",
            "Loading 532/2134\n",
            "Loading 533/2134\n",
            "Loading 534/2134\n",
            "Loading 535/2134\n",
            "Loading 536/2134\n",
            "Loading 537/2134\n",
            "Loading 538/2134\n",
            "Loading 539/2134\n",
            "Loading 540/2134\n",
            "Loading 541/2134\n",
            "Loading 542/2134\n",
            "Loading 543/2134\n",
            "Loading 544/2134\n",
            "Loading 545/2134\n",
            "Loading 546/2134\n",
            "Loading 547/2134\n",
            "Loading 548/2134\n",
            "Loading 549/2134\n",
            "Loading 550/2134\n",
            "Loading 551/2134\n",
            "Loading 552/2134\n",
            "Loading 553/2134\n",
            "Loading 554/2134\n",
            "Loading 555/2134\n",
            "Loading 556/2134\n",
            "Loading 557/2134\n",
            "Loading 558/2134\n",
            "Loading 559/2134\n",
            "Loading 560/2134\n",
            "Loading 561/2134\n",
            "Loading 562/2134\n",
            "Loading 563/2134\n",
            "Loading 564/2134\n",
            "Loading 565/2134\n",
            "Loading 566/2134\n",
            "Loading 567/2134\n",
            "Loading 568/2134\n",
            "Loading 569/2134\n",
            "Loading 570/2134\n",
            "Loading 571/2134\n",
            "Loading 572/2134\n",
            "Loading 573/2134\n",
            "Loading 574/2134\n",
            "Loading 575/2134\n",
            "Loading 576/2134\n",
            "Loading 577/2134\n",
            "Loading 578/2134\n",
            "Loading 579/2134\n",
            "Loading 580/2134\n",
            "Loading 581/2134\n",
            "Loading 582/2134\n",
            "Loading 583/2134\n",
            "Loading 584/2134\n",
            "Loading 585/2134\n",
            "Loading 586/2134\n",
            "Loading 587/2134\n",
            "Loading 588/2134\n",
            "Loading 589/2134\n",
            "Loading 590/2134\n",
            "Loading 591/2134\n",
            "Loading 592/2134\n",
            "Loading 593/2134\n",
            "Loading 594/2134\n",
            "Loading 595/2134\n",
            "Loading 596/2134\n",
            "Loading 597/2134\n",
            "Loading 598/2134\n",
            "Loading 599/2134\n",
            "Loading 600/2134\n",
            "Loading 601/2134\n",
            "Loading 602/2134\n",
            "Loading 603/2134\n",
            "Loading 604/2134\n",
            "Loading 605/2134\n",
            "Loading 606/2134\n",
            "Loading 607/2134\n",
            "Loading 608/2134\n",
            "Loading 609/2134\n",
            "Loading 610/2134\n",
            "Loading 611/2134\n",
            "Loading 612/2134\n",
            "Loading 613/2134\n",
            "Loading 614/2134\n",
            "Loading 615/2134\n",
            "Loading 616/2134\n",
            "Loading 617/2134\n",
            "Loading 618/2134\n",
            "Loading 619/2134\n",
            "Loading 620/2134\n",
            "Loading 621/2134\n",
            "Loading 622/2134\n",
            "Loading 623/2134\n",
            "Loading 624/2134\n",
            "Loading 625/2134\n",
            "Loading 626/2134\n",
            "Loading 627/2134\n",
            "Loading 628/2134\n",
            "Loading 629/2134\n",
            "Loading 630/2134\n",
            "Loading 631/2134\n",
            "Loading 632/2134\n",
            "Loading 633/2134\n",
            "Loading 634/2134\n",
            "Loading 635/2134\n",
            "Loading 636/2134\n",
            "Loading 637/2134\n",
            "Loading 638/2134\n",
            "Loading 639/2134\n",
            "Loading 640/2134\n",
            "Loading 641/2134\n",
            "Loading 642/2134\n",
            "Loading 643/2134\n",
            "Loading 644/2134\n",
            "Loading 645/2134\n",
            "Loading 646/2134\n",
            "Loading 647/2134\n",
            "Loading 648/2134\n",
            "Loading 649/2134\n",
            "Loading 650/2134\n",
            "Loading 651/2134\n",
            "Loading 652/2134\n",
            "Loading 653/2134\n",
            "Loading 654/2134\n",
            "Loading 655/2134\n",
            "Loading 656/2134\n",
            "Loading 657/2134\n",
            "Loading 658/2134\n",
            "Loading 659/2134\n",
            "Loading 660/2134\n",
            "Loading 661/2134\n",
            "Loading 662/2134\n",
            "Loading 663/2134\n",
            "Loading 664/2134\n",
            "Loading 665/2134\n",
            "Loading 666/2134\n",
            "Loading 667/2134\n",
            "Loading 668/2134\n",
            "Loading 669/2134\n",
            "Loading 670/2134\n",
            "Loading 671/2134\n",
            "Loading 672/2134\n",
            "Loading 673/2134\n",
            "Loading 674/2134\n",
            "Loading 675/2134\n",
            "Loading 676/2134\n",
            "Loading 677/2134\n",
            "Loading 678/2134\n",
            "Loading 679/2134\n",
            "Loading 680/2134\n",
            "Loading 681/2134\n",
            "Loading 682/2134\n",
            "Loading 683/2134\n",
            "Loading 684/2134\n",
            "Loading 685/2134\n",
            "Loading 686/2134\n",
            "Loading 687/2134\n",
            "Loading 688/2134\n",
            "Loading 689/2134\n",
            "Loading 690/2134\n",
            "Loading 691/2134\n",
            "Loading 692/2134\n",
            "Loading 693/2134\n",
            "Loading 694/2134\n",
            "Loading 695/2134\n",
            "Loading 696/2134\n",
            "Loading 697/2134\n",
            "Loading 698/2134\n",
            "Loading 699/2134\n",
            "Loading 700/2134\n",
            "Loading 701/2134\n",
            "Loading 702/2134\n",
            "Loading 703/2134\n",
            "Loading 704/2134\n",
            "Loading 705/2134\n",
            "Loading 706/2134\n",
            "Loading 707/2134\n",
            "Loading 708/2134\n",
            "Loading 709/2134\n",
            "Loading 710/2134\n",
            "Loading 711/2134\n",
            "Loading 712/2134\n",
            "Loading 713/2134\n",
            "Loading 714/2134\n",
            "Loading 715/2134\n",
            "Loading 716/2134\n",
            "Loading 717/2134\n",
            "Loading 718/2134\n",
            "Loading 719/2134\n",
            "Loading 720/2134\n",
            "Loading 721/2134\n",
            "Loading 722/2134\n",
            "Loading 723/2134\n",
            "Loading 724/2134\n",
            "Loading 725/2134\n",
            "Loading 726/2134\n",
            "Loading 727/2134\n",
            "Loading 728/2134\n",
            "Loading 729/2134\n",
            "Loading 730/2134\n",
            "Loading 731/2134\n",
            "Loading 732/2134\n",
            "Loading 733/2134\n",
            "Loading 734/2134\n",
            "Loading 735/2134\n",
            "Loading 736/2134\n",
            "Loading 737/2134\n",
            "Loading 738/2134\n",
            "Loading 739/2134\n",
            "Loading 740/2134\n",
            "Loading 741/2134\n",
            "Loading 742/2134\n",
            "Loading 743/2134\n",
            "Loading 744/2134\n",
            "Loading 745/2134\n",
            "Loading 746/2134\n",
            "Loading 747/2134\n",
            "Loading 748/2134\n",
            "Loading 749/2134\n",
            "Loading 750/2134\n",
            "Loading 751/2134\n",
            "Loading 752/2134\n",
            "Loading 753/2134\n",
            "Loading 754/2134\n",
            "Loading 755/2134\n",
            "Loading 756/2134\n",
            "Loading 757/2134\n",
            "Loading 758/2134\n",
            "Loading 759/2134\n",
            "Loading 760/2134\n",
            "Loading 761/2134\n",
            "Loading 762/2134\n",
            "Loading 763/2134\n",
            "Loading 764/2134\n",
            "Loading 765/2134\n",
            "Loading 766/2134\n",
            "Loading 767/2134\n",
            "Loading 768/2134\n",
            "Loading 769/2134\n",
            "Loading 770/2134\n",
            "Loading 771/2134\n",
            "Loading 772/2134\n",
            "Loading 773/2134\n",
            "Loading 774/2134\n",
            "Loading 775/2134\n",
            "Loading 776/2134\n",
            "Loading 777/2134\n",
            "Loading 778/2134\n",
            "Loading 779/2134\n",
            "Loading 780/2134\n",
            "Loading 781/2134\n",
            "Loading 782/2134\n",
            "Loading 783/2134\n",
            "Loading 784/2134\n",
            "Loading 785/2134\n",
            "Loading 786/2134\n",
            "Loading 787/2134\n",
            "Loading 788/2134\n",
            "Loading 789/2134\n",
            "Loading 790/2134\n",
            "Loading 791/2134\n",
            "Loading 792/2134\n",
            "Loading 793/2134\n",
            "Loading 794/2134\n",
            "Loading 795/2134\n",
            "Loading 796/2134\n",
            "Loading 797/2134\n",
            "Loading 798/2134\n",
            "Loading 799/2134\n",
            "Loading 800/2134\n",
            "Loading 801/2134\n",
            "Loading 802/2134\n",
            "Loading 803/2134\n",
            "Loading 804/2134\n",
            "Loading 805/2134\n",
            "Loading 806/2134\n",
            "Loading 807/2134\n",
            "Loading 808/2134\n",
            "Loading 809/2134\n",
            "Loading 810/2134\n",
            "Loading 811/2134\n",
            "Loading 812/2134\n",
            "Loading 813/2134\n",
            "Loading 814/2134\n",
            "Loading 815/2134\n",
            "Loading 816/2134\n",
            "Loading 817/2134\n",
            "Loading 818/2134\n",
            "Loading 819/2134\n",
            "Loading 820/2134\n",
            "Loading 821/2134\n",
            "Loading 822/2134\n",
            "Loading 823/2134\n",
            "Loading 824/2134\n",
            "Loading 825/2134\n",
            "Loading 826/2134\n",
            "Loading 827/2134\n",
            "Loading 828/2134\n",
            "Loading 829/2134\n",
            "Loading 830/2134\n",
            "Loading 831/2134\n",
            "Loading 832/2134\n",
            "Loading 833/2134\n",
            "Loading 834/2134\n",
            "Loading 835/2134\n",
            "Loading 836/2134\n",
            "Loading 837/2134\n",
            "Loading 838/2134\n",
            "Loading 839/2134\n",
            "Loading 840/2134\n",
            "Loading 841/2134\n",
            "Loading 842/2134\n",
            "Loading 843/2134\n",
            "Loading 844/2134\n",
            "Loading 845/2134\n",
            "Loading 846/2134\n",
            "Loading 847/2134\n",
            "Loading 848/2134\n",
            "Loading 849/2134\n",
            "Loading 850/2134\n",
            "Loading 851/2134\n",
            "Loading 852/2134\n",
            "Loading 853/2134\n",
            "Loading 854/2134\n",
            "Loading 855/2134\n",
            "Loading 856/2134\n",
            "Loading 857/2134\n",
            "Loading 858/2134\n",
            "Loading 859/2134\n",
            "Loading 860/2134\n",
            "Loading 861/2134\n",
            "Loading 862/2134\n",
            "Loading 863/2134\n",
            "Loading 864/2134\n",
            "Loading 865/2134\n",
            "Loading 866/2134\n",
            "Loading 867/2134\n",
            "Loading 868/2134\n",
            "Loading 869/2134\n",
            "Loading 870/2134\n",
            "Loading 871/2134\n",
            "Loading 872/2134\n",
            "Loading 873/2134\n",
            "Loading 874/2134\n",
            "Loading 875/2134\n",
            "Loading 876/2134\n",
            "Loading 877/2134\n",
            "Loading 878/2134\n",
            "Loading 879/2134\n",
            "Loading 880/2134\n",
            "Loading 881/2134\n",
            "Loading 882/2134\n",
            "Loading 883/2134\n",
            "Loading 884/2134\n",
            "Loading 885/2134\n",
            "Loading 886/2134\n",
            "Loading 887/2134\n",
            "Loading 888/2134\n",
            "Loading 889/2134\n",
            "Loading 890/2134\n",
            "Loading 891/2134\n",
            "Loading 892/2134\n",
            "Loading 893/2134\n",
            "Loading 894/2134\n",
            "Loading 895/2134\n",
            "Loading 896/2134\n",
            "Loading 897/2134\n",
            "Loading 898/2134\n",
            "Loading 899/2134\n",
            "Loading 900/2134\n",
            "Loading 901/2134\n",
            "Loading 902/2134\n",
            "Loading 903/2134\n",
            "Loading 904/2134\n",
            "Loading 905/2134\n",
            "Loading 906/2134\n",
            "Loading 907/2134\n",
            "Loading 908/2134\n",
            "Loading 909/2134\n",
            "Loading 910/2134\n",
            "Loading 911/2134\n",
            "Loading 912/2134\n",
            "Loading 913/2134\n",
            "Loading 914/2134\n",
            "Loading 915/2134\n",
            "Loading 916/2134\n",
            "Loading 917/2134\n",
            "Loading 918/2134\n",
            "Loading 919/2134\n",
            "Loading 920/2134\n",
            "Loading 921/2134\n",
            "Loading 922/2134\n",
            "Loading 923/2134\n",
            "Loading 924/2134\n",
            "Loading 925/2134\n",
            "Loading 926/2134\n",
            "Loading 927/2134\n",
            "Loading 928/2134\n",
            "Loading 929/2134\n",
            "Loading 930/2134\n",
            "Loading 931/2134\n",
            "Loading 932/2134\n",
            "Loading 933/2134\n",
            "Loading 934/2134\n",
            "Loading 935/2134\n",
            "Loading 936/2134\n",
            "Loading 937/2134\n",
            "Loading 938/2134\n",
            "Loading 939/2134\n",
            "Loading 940/2134\n",
            "Loading 941/2134\n",
            "Loading 942/2134\n",
            "Loading 943/2134\n",
            "Loading 944/2134\n",
            "Loading 945/2134\n",
            "Loading 946/2134\n",
            "Loading 947/2134\n",
            "Loading 948/2134\n",
            "Loading 949/2134\n",
            "Loading 950/2134\n",
            "Loading 951/2134\n",
            "Loading 952/2134\n",
            "Loading 953/2134\n",
            "Loading 954/2134\n",
            "Loading 955/2134\n",
            "Loading 956/2134\n",
            "Loading 957/2134\n",
            "Loading 958/2134\n",
            "Loading 959/2134\n",
            "Loading 960/2134\n",
            "Loading 961/2134\n",
            "Loading 962/2134\n",
            "Loading 963/2134\n",
            "Loading 964/2134\n",
            "Loading 965/2134\n",
            "Loading 966/2134\n",
            "Loading 967/2134\n",
            "Loading 968/2134\n",
            "Loading 969/2134\n",
            "Loading 970/2134\n",
            "Loading 971/2134\n",
            "Loading 972/2134\n",
            "Loading 973/2134\n",
            "Loading 974/2134\n",
            "Loading 975/2134\n",
            "Loading 976/2134\n",
            "Loading 977/2134\n",
            "Loading 978/2134\n",
            "Loading 979/2134\n",
            "Loading 980/2134\n",
            "Loading 981/2134\n",
            "Loading 982/2134\n",
            "Loading 983/2134\n",
            "Loading 984/2134\n",
            "Loading 985/2134\n",
            "Loading 986/2134\n",
            "Loading 987/2134\n",
            "Loading 988/2134\n",
            "Loading 989/2134\n",
            "Loading 990/2134\n",
            "Loading 991/2134\n",
            "Loading 992/2134\n",
            "Loading 993/2134\n",
            "Loading 994/2134\n",
            "Loading 995/2134\n",
            "Loading 996/2134\n",
            "Loading 997/2134\n",
            "Loading 998/2134\n",
            "Loading 999/2134\n",
            "Loading 1000/2134\n",
            "Loading 1001/2134\n",
            "Loading 1002/2134\n",
            "Loading 1003/2134\n",
            "Loading 1004/2134\n",
            "Loading 1005/2134\n",
            "Loading 1006/2134\n",
            "Loading 1007/2134\n",
            "Loading 1008/2134\n",
            "Loading 1009/2134\n",
            "Loading 1010/2134\n",
            "Loading 1011/2134\n",
            "Loading 1012/2134\n",
            "Loading 1013/2134\n",
            "Loading 1014/2134\n",
            "Loading 1015/2134\n",
            "Loading 1016/2134\n",
            "Loading 1017/2134\n",
            "Loading 1018/2134\n",
            "Loading 1019/2134\n",
            "Loading 1020/2134\n",
            "Loading 1021/2134\n",
            "Loading 1022/2134\n",
            "Loading 1023/2134\n",
            "Loading 1024/2134\n",
            "Loading 1025/2134\n",
            "Loading 1026/2134\n",
            "Loading 1027/2134\n",
            "Loading 1028/2134\n",
            "Loading 1029/2134\n",
            "Loading 1030/2134\n",
            "Loading 1031/2134\n",
            "Loading 1032/2134\n",
            "Loading 1033/2134\n",
            "Loading 1034/2134\n",
            "Loading 1035/2134\n",
            "Loading 1036/2134\n",
            "Loading 1037/2134\n",
            "Loading 1038/2134\n",
            "Loading 1039/2134\n",
            "Loading 1040/2134\n",
            "Loading 1041/2134\n",
            "Loading 1042/2134\n",
            "Loading 1043/2134\n",
            "Loading 1044/2134\n",
            "Loading 1045/2134\n",
            "Loading 1046/2134\n",
            "Loading 1047/2134\n",
            "Loading 1048/2134\n",
            "Loading 1049/2134\n",
            "Loading 1050/2134\n",
            "Loading 1051/2134\n",
            "Loading 1052/2134\n",
            "Loading 1053/2134\n",
            "Loading 1054/2134\n",
            "Loading 1055/2134\n",
            "Loading 1056/2134\n",
            "Loading 1057/2134\n",
            "Loading 1058/2134\n",
            "Loading 1059/2134\n",
            "Loading 1060/2134\n",
            "Loading 1061/2134\n",
            "Loading 1062/2134\n",
            "Loading 1063/2134\n",
            "Loading 1064/2134\n",
            "Loading 1065/2134\n",
            "Loading 1066/2134\n",
            "Loading 1067/2134\n",
            "Loading 1068/2134\n",
            "Loading 1069/2134\n",
            "Loading 1070/2134\n",
            "Loading 1071/2134\n",
            "Loading 1072/2134\n",
            "Loading 1073/2134\n",
            "Loading 1074/2134\n",
            "Loading 1075/2134\n",
            "Loading 1076/2134\n",
            "Loading 1077/2134\n",
            "Loading 1078/2134\n",
            "Loading 1079/2134\n",
            "Loading 1080/2134\n",
            "Loading 1081/2134\n",
            "Loading 1082/2134\n",
            "Loading 1083/2134\n",
            "Loading 1084/2134\n",
            "Loading 1085/2134\n",
            "Loading 1086/2134\n",
            "Loading 1087/2134\n",
            "Loading 1088/2134\n",
            "Loading 1089/2134\n",
            "Loading 1090/2134\n",
            "Loading 1091/2134\n",
            "Loading 1092/2134\n",
            "Loading 1093/2134\n",
            "Loading 1094/2134\n",
            "Loading 1095/2134\n",
            "Loading 1096/2134\n",
            "Loading 1097/2134\n",
            "Loading 1098/2134\n",
            "Loading 1099/2134\n",
            "Loading 1100/2134\n",
            "Loading 1101/2134\n",
            "Loading 1102/2134\n",
            "Loading 1103/2134\n",
            "Loading 1104/2134\n",
            "Loading 1105/2134\n",
            "Loading 1106/2134\n",
            "Loading 1107/2134\n",
            "Loading 1108/2134\n",
            "Loading 1109/2134\n",
            "Loading 1110/2134\n",
            "Loading 1111/2134\n",
            "Loading 1112/2134\n",
            "Loading 1113/2134\n",
            "Loading 1114/2134\n",
            "Loading 1115/2134\n",
            "Loading 1116/2134\n",
            "Loading 1117/2134\n",
            "Loading 1118/2134\n",
            "Loading 1119/2134\n",
            "Loading 1120/2134\n",
            "Loading 1121/2134\n",
            "Loading 1122/2134\n",
            "Loading 1123/2134\n",
            "Loading 1124/2134\n",
            "Loading 1125/2134\n",
            "Loading 1126/2134\n",
            "Loading 1127/2134\n",
            "Loading 1128/2134\n",
            "Loading 1129/2134\n",
            "Loading 1130/2134\n",
            "Loading 1131/2134\n",
            "Loading 1132/2134\n",
            "Loading 1133/2134\n",
            "Loading 1134/2134\n",
            "Loading 1135/2134\n",
            "Loading 1136/2134\n",
            "Loading 1137/2134\n",
            "Loading 1138/2134\n",
            "Loading 1139/2134\n",
            "Loading 1140/2134\n",
            "Loading 1141/2134\n",
            "Loading 1142/2134\n",
            "Loading 1143/2134\n",
            "Loading 1144/2134\n",
            "Loading 1145/2134\n",
            "Loading 1146/2134\n",
            "Loading 1147/2134\n",
            "Loading 1148/2134\n",
            "Loading 1149/2134\n",
            "Loading 1150/2134\n",
            "Loading 1151/2134\n",
            "Loading 1152/2134\n",
            "Loading 1153/2134\n",
            "Loading 1154/2134\n",
            "Loading 1155/2134\n",
            "Loading 1156/2134\n",
            "Loading 1157/2134\n",
            "Loading 1158/2134\n",
            "Loading 1159/2134\n",
            "Loading 1160/2134\n",
            "Loading 1161/2134\n",
            "Loading 1162/2134\n",
            "Loading 1163/2134\n",
            "Loading 1164/2134\n",
            "Loading 1165/2134\n",
            "Loading 1166/2134\n",
            "Loading 1167/2134\n",
            "Loading 1168/2134\n",
            "Loading 1169/2134\n",
            "Loading 1170/2134\n",
            "Loading 1171/2134\n",
            "Loading 1172/2134\n",
            "Loading 1173/2134\n",
            "Loading 1174/2134\n",
            "Loading 1175/2134\n",
            "Loading 1176/2134\n",
            "Loading 1177/2134\n",
            "Loading 1178/2134\n",
            "Loading 1179/2134\n",
            "Loading 1180/2134\n",
            "Loading 1181/2134\n",
            "Loading 1182/2134\n",
            "Loading 1183/2134\n",
            "Loading 1184/2134\n",
            "Loading 1185/2134\n",
            "Loading 1186/2134\n",
            "Loading 1187/2134\n",
            "Loading 1188/2134\n",
            "Loading 1189/2134\n",
            "Loading 1190/2134\n",
            "Loading 1191/2134\n",
            "Loading 1192/2134\n",
            "Loading 1193/2134\n",
            "Loading 1194/2134\n",
            "Loading 1195/2134\n",
            "Loading 1196/2134\n",
            "Loading 1197/2134\n",
            "Loading 1198/2134\n",
            "Loading 1199/2134\n",
            "Loading 1200/2134\n",
            "Loading 1201/2134\n",
            "Loading 1202/2134\n",
            "Loading 1203/2134\n",
            "Loading 1204/2134\n",
            "Loading 1205/2134\n",
            "Loading 1206/2134\n",
            "Loading 1207/2134\n",
            "Loading 1208/2134\n",
            "Loading 1209/2134\n",
            "Loading 1210/2134\n",
            "Loading 1211/2134\n",
            "Loading 1212/2134\n",
            "Loading 1213/2134\n",
            "Loading 1214/2134\n",
            "Loading 1215/2134\n",
            "Loading 1216/2134\n",
            "Loading 1217/2134\n",
            "Loading 1218/2134\n",
            "Loading 1219/2134\n",
            "Loading 1220/2134\n",
            "Loading 1221/2134\n",
            "Loading 1222/2134\n",
            "Loading 1223/2134\n",
            "Loading 1224/2134\n",
            "Loading 1225/2134\n",
            "Loading 1226/2134\n",
            "Loading 1227/2134\n",
            "Loading 1228/2134\n",
            "Loading 1229/2134\n",
            "Loading 1230/2134\n",
            "Loading 1231/2134\n",
            "Loading 1232/2134\n",
            "Loading 1233/2134\n",
            "Loading 1234/2134\n",
            "Loading 1235/2134\n",
            "Loading 1236/2134\n",
            "Loading 1237/2134\n",
            "Loading 1238/2134\n",
            "Loading 1239/2134\n",
            "Loading 1240/2134\n",
            "Loading 1241/2134\n",
            "Loading 1242/2134\n",
            "Loading 1243/2134\n",
            "Loading 1244/2134\n",
            "Loading 1245/2134\n",
            "Loading 1246/2134\n",
            "Loading 1247/2134\n",
            "Loading 1248/2134\n",
            "Loading 1249/2134\n",
            "Loading 1250/2134\n",
            "Loading 1251/2134\n",
            "Loading 1252/2134\n",
            "Loading 1253/2134\n",
            "Loading 1254/2134\n",
            "Loading 1255/2134\n",
            "Loading 1256/2134\n",
            "Loading 1257/2134\n",
            "Loading 1258/2134\n",
            "Loading 1259/2134\n",
            "Loading 1260/2134\n",
            "Loading 1261/2134\n",
            "Loading 1262/2134\n",
            "Loading 1263/2134\n",
            "Loading 1264/2134\n",
            "Loading 1265/2134\n",
            "Loading 1266/2134\n",
            "Loading 1267/2134\n",
            "Loading 1268/2134\n",
            "Loading 1269/2134\n",
            "Loading 1270/2134\n",
            "Loading 1271/2134\n",
            "Loading 1272/2134\n",
            "Loading 1273/2134\n",
            "Loading 1274/2134\n",
            "Loading 1275/2134\n",
            "Loading 1276/2134\n",
            "Loading 1277/2134\n",
            "Loading 1278/2134\n",
            "Loading 1279/2134\n",
            "Loading 1280/2134\n",
            "Loading 1281/2134\n",
            "Loading 1282/2134\n",
            "Loading 1283/2134\n",
            "Loading 1284/2134\n",
            "Loading 1285/2134\n",
            "Loading 1286/2134\n",
            "Loading 1287/2134\n",
            "Loading 1288/2134\n",
            "Loading 1289/2134\n",
            "Loading 1290/2134\n",
            "Loading 1291/2134\n",
            "Loading 1292/2134\n",
            "Loading 1293/2134\n",
            "Loading 1294/2134\n",
            "Loading 1295/2134\n",
            "Loading 1296/2134\n",
            "Loading 1297/2134\n",
            "Loading 1298/2134\n",
            "Loading 1299/2134\n",
            "Loading 1300/2134\n",
            "Loading 1301/2134\n",
            "Loading 1302/2134\n",
            "Loading 1303/2134\n",
            "Loading 1304/2134\n",
            "Loading 1305/2134\n",
            "Loading 1306/2134\n",
            "Loading 1307/2134\n",
            "Loading 1308/2134\n",
            "Loading 1309/2134\n",
            "Loading 1310/2134\n",
            "Loading 1311/2134\n",
            "Loading 1312/2134\n",
            "Loading 1313/2134\n",
            "Loading 1314/2134\n",
            "Loading 1315/2134\n",
            "Loading 1316/2134\n",
            "Loading 1317/2134\n",
            "Loading 1318/2134\n",
            "Loading 1319/2134\n",
            "Loading 1320/2134\n",
            "Loading 1321/2134\n",
            "Loading 1322/2134\n",
            "Loading 1323/2134\n",
            "Loading 1324/2134\n",
            "Loading 1325/2134\n",
            "Loading 1326/2134\n",
            "Loading 1327/2134\n",
            "Loading 1328/2134\n",
            "Loading 1329/2134\n",
            "Loading 1330/2134\n",
            "Loading 1331/2134\n",
            "Loading 1332/2134\n",
            "Loading 1333/2134\n",
            "Loading 1334/2134\n",
            "Loading 1335/2134\n",
            "Loading 1336/2134\n",
            "Loading 1337/2134\n",
            "Loading 1338/2134\n",
            "Loading 1339/2134\n",
            "Loading 1340/2134\n",
            "Loading 1341/2134\n",
            "Loading 1342/2134\n",
            "Loading 1343/2134\n",
            "Loading 1344/2134\n",
            "Loading 1345/2134\n",
            "Loading 1346/2134\n",
            "Loading 1347/2134\n",
            "Loading 1348/2134\n",
            "Loading 1349/2134\n",
            "Loading 1350/2134\n",
            "Loading 1351/2134\n",
            "Loading 1352/2134\n",
            "Loading 1353/2134\n",
            "Loading 1354/2134\n",
            "Loading 1355/2134\n",
            "Loading 1356/2134\n",
            "Loading 1357/2134\n",
            "Loading 1358/2134\n",
            "Loading 1359/2134\n",
            "Loading 1360/2134\n",
            "Loading 1361/2134\n",
            "Loading 1362/2134\n",
            "Loading 1363/2134\n",
            "Loading 1364/2134\n",
            "Loading 1365/2134\n",
            "Loading 1366/2134\n",
            "Loading 1367/2134\n",
            "Loading 1368/2134\n",
            "Loading 1369/2134\n",
            "Loading 1370/2134\n",
            "Loading 1371/2134\n",
            "Loading 1372/2134\n",
            "Loading 1373/2134\n",
            "Loading 1374/2134\n",
            "Loading 1375/2134\n",
            "Loading 1376/2134\n",
            "Loading 1377/2134\n",
            "Loading 1378/2134\n",
            "Loading 1379/2134\n",
            "Loading 1380/2134\n",
            "Loading 1381/2134\n",
            "Loading 1382/2134\n",
            "Loading 1383/2134\n",
            "Loading 1384/2134\n",
            "Loading 1385/2134\n",
            "Loading 1386/2134\n",
            "Loading 1387/2134\n",
            "Loading 1388/2134\n",
            "Loading 1389/2134\n",
            "Loading 1390/2134\n",
            "Loading 1391/2134\n",
            "Loading 1392/2134\n",
            "Loading 1393/2134\n",
            "Loading 1394/2134\n",
            "Loading 1395/2134\n",
            "Loading 1396/2134\n",
            "Loading 1397/2134\n",
            "Loading 1398/2134\n",
            "Loading 1399/2134\n",
            "Loading 1400/2134\n",
            "Loading 1401/2134\n",
            "Loading 1402/2134\n",
            "Loading 1403/2134\n",
            "Loading 1404/2134\n",
            "Loading 1405/2134\n",
            "Loading 1406/2134\n",
            "Loading 1407/2134\n",
            "Loading 1408/2134\n",
            "Loading 1409/2134\n",
            "Loading 1410/2134\n",
            "Loading 1411/2134\n",
            "Loading 1412/2134\n",
            "Loading 1413/2134\n",
            "Loading 1414/2134\n",
            "Loading 1415/2134\n",
            "Loading 1416/2134\n",
            "Loading 1417/2134\n",
            "Loading 1418/2134\n",
            "Loading 1419/2134\n",
            "Loading 1420/2134\n",
            "Loading 1421/2134\n",
            "Loading 1422/2134\n",
            "Loading 1423/2134\n",
            "Loading 1424/2134\n",
            "Loading 1425/2134\n",
            "Loading 1426/2134\n",
            "Loading 1427/2134\n",
            "Loading 1428/2134\n",
            "Loading 1429/2134\n",
            "Loading 1430/2134\n",
            "Loading 1431/2134\n",
            "Loading 1432/2134\n",
            "Loading 1433/2134\n",
            "Loading 1434/2134\n",
            "Loading 1435/2134\n",
            "Loading 1436/2134\n",
            "Loading 1437/2134\n",
            "Loading 1438/2134\n",
            "Loading 1439/2134\n",
            "Loading 1440/2134\n",
            "Loading 1441/2134\n",
            "Loading 1442/2134\n",
            "Loading 1443/2134\n",
            "Loading 1444/2134\n",
            "Loading 1445/2134\n",
            "Loading 1446/2134\n",
            "Loading 1447/2134\n",
            "Loading 1448/2134\n",
            "Loading 1449/2134\n",
            "Loading 1450/2134\n",
            "Loading 1451/2134\n",
            "Loading 1452/2134\n",
            "Loading 1453/2134\n",
            "Loading 1454/2134\n",
            "Loading 1455/2134\n",
            "Loading 1456/2134\n",
            "Loading 1457/2134\n",
            "Loading 1458/2134\n",
            "Loading 1459/2134\n",
            "Loading 1460/2134\n",
            "Loading 1461/2134\n",
            "Loading 1462/2134\n",
            "Loading 1463/2134\n",
            "Loading 1464/2134\n",
            "Loading 1465/2134\n",
            "Loading 1466/2134\n",
            "Loading 1467/2134\n",
            "Loading 1468/2134\n",
            "Loading 1469/2134\n",
            "Loading 1470/2134\n",
            "Loading 1471/2134\n",
            "Loading 1472/2134\n",
            "Loading 1473/2134\n",
            "Loading 1474/2134\n",
            "Loading 1475/2134\n",
            "Loading 1476/2134\n",
            "Loading 1477/2134\n",
            "Loading 1478/2134\n",
            "Loading 1479/2134\n",
            "Loading 1480/2134\n",
            "Loading 1481/2134\n",
            "Loading 1482/2134\n",
            "Loading 1483/2134\n",
            "Loading 1484/2134\n",
            "Loading 1485/2134\n",
            "Loading 1486/2134\n",
            "Loading 1487/2134\n",
            "Loading 1488/2134\n",
            "Loading 1489/2134\n",
            "Loading 1490/2134\n",
            "Loading 1491/2134\n",
            "Loading 1492/2134\n",
            "Loading 1493/2134\n",
            "Loading 1494/2134\n",
            "Loading 1495/2134\n",
            "Loading 1496/2134\n",
            "Loading 1497/2134\n",
            "Loading 1498/2134\n",
            "Loading 1499/2134\n",
            "Loading 1500/2134\n",
            "Loading 1501/2134\n",
            "Loading 1502/2134\n",
            "Loading 1503/2134\n",
            "Loading 1504/2134\n",
            "Loading 1505/2134\n",
            "Loading 1506/2134\n",
            "Loading 1507/2134\n",
            "Loading 1508/2134\n",
            "Loading 1509/2134\n",
            "Loading 1510/2134\n",
            "Loading 1511/2134\n",
            "Loading 1512/2134\n",
            "Loading 1513/2134\n",
            "Loading 1514/2134\n",
            "Loading 1515/2134\n",
            "Loading 1516/2134\n",
            "Loading 1517/2134\n",
            "Loading 1518/2134\n",
            "Loading 1519/2134\n",
            "Loading 1520/2134\n",
            "Loading 1521/2134\n",
            "Loading 1522/2134\n",
            "Loading 1523/2134\n",
            "Loading 1524/2134\n",
            "Loading 1525/2134\n",
            "Loading 1526/2134\n",
            "Loading 1527/2134\n",
            "Loading 1528/2134\n",
            "Loading 1529/2134\n",
            "Loading 1530/2134\n",
            "Loading 1531/2134\n",
            "Loading 1532/2134\n",
            "Loading 1533/2134\n",
            "Loading 1534/2134\n",
            "Loading 1535/2134\n",
            "Loading 1536/2134\n",
            "Loading 1537/2134\n",
            "Loading 1538/2134\n",
            "Loading 1539/2134\n",
            "Loading 1540/2134\n",
            "Loading 1541/2134\n",
            "Loading 1542/2134\n",
            "Loading 1543/2134\n",
            "Loading 1544/2134\n",
            "Loading 1545/2134\n",
            "Loading 1546/2134\n",
            "Loading 1547/2134\n",
            "Loading 1548/2134\n",
            "Loading 1549/2134\n",
            "Loading 1550/2134\n",
            "Loading 1551/2134\n",
            "Loading 1552/2134\n",
            "Loading 1553/2134\n",
            "Loading 1554/2134\n",
            "Loading 1555/2134\n",
            "Loading 1556/2134\n",
            "Loading 1557/2134\n",
            "Loading 1558/2134\n",
            "Loading 1559/2134\n",
            "Loading 1560/2134\n",
            "Loading 1561/2134\n",
            "Loading 1562/2134\n",
            "Loading 1563/2134\n",
            "Loading 1564/2134\n",
            "Loading 1565/2134\n",
            "Loading 1566/2134\n",
            "Loading 1567/2134\n",
            "Loading 1568/2134\n",
            "Loading 1569/2134\n",
            "Loading 1570/2134\n",
            "Loading 1571/2134\n",
            "Loading 1572/2134\n",
            "Loading 1573/2134\n",
            "Loading 1574/2134\n",
            "Loading 1575/2134\n",
            "Loading 1576/2134\n",
            "Loading 1577/2134\n",
            "Loading 1578/2134\n",
            "Loading 1579/2134\n",
            "Loading 1580/2134\n",
            "Loading 1581/2134\n",
            "Loading 1582/2134\n",
            "Loading 1583/2134\n",
            "Loading 1584/2134\n",
            "Loading 1585/2134\n",
            "Loading 1586/2134\n",
            "Loading 1587/2134\n",
            "Loading 1588/2134\n",
            "Loading 1589/2134\n",
            "Loading 1590/2134\n",
            "Loading 1591/2134\n",
            "Loading 1592/2134\n",
            "Loading 1593/2134\n",
            "Loading 1594/2134\n",
            "Loading 1595/2134\n",
            "Loading 1596/2134\n",
            "Loading 1597/2134\n",
            "Loading 1598/2134\n",
            "Loading 1599/2134\n",
            "Loading 1600/2134\n",
            "Loading 1601/2134\n",
            "Loading 1602/2134\n",
            "Loading 1603/2134\n",
            "Loading 1604/2134\n",
            "Loading 1605/2134\n",
            "Loading 1606/2134\n",
            "Loading 1607/2134\n",
            "Loading 1608/2134\n",
            "Loading 1609/2134\n",
            "Loading 1610/2134\n",
            "Loading 1611/2134\n",
            "Loading 1612/2134\n",
            "Loading 1613/2134\n",
            "Loading 1614/2134\n",
            "Loading 1615/2134\n",
            "Loading 1616/2134\n",
            "Loading 1617/2134\n",
            "Loading 1618/2134\n",
            "Loading 1619/2134\n",
            "Loading 1620/2134\n",
            "Loading 1621/2134\n",
            "Loading 1622/2134\n",
            "Loading 1623/2134\n",
            "Loading 1624/2134\n",
            "Loading 1625/2134\n",
            "Loading 1626/2134\n",
            "Loading 1627/2134\n",
            "Loading 1628/2134\n",
            "Loading 1629/2134\n",
            "Loading 1630/2134\n",
            "Loading 1631/2134\n",
            "Loading 1632/2134\n",
            "Loading 1633/2134\n",
            "Loading 1634/2134\n",
            "Loading 1635/2134\n",
            "Loading 1636/2134\n",
            "Loading 1637/2134\n",
            "Loading 1638/2134\n",
            "Loading 1639/2134\n",
            "Loading 1640/2134\n",
            "Loading 1641/2134\n",
            "Loading 1642/2134\n",
            "Loading 1643/2134\n",
            "Loading 1644/2134\n",
            "Loading 1645/2134\n",
            "Loading 1646/2134\n",
            "Loading 1647/2134\n",
            "Loading 1648/2134\n",
            "Loading 1649/2134\n",
            "Loading 1650/2134\n",
            "Loading 1651/2134\n",
            "Loading 1652/2134\n",
            "Loading 1653/2134\n",
            "Loading 1654/2134\n",
            "Loading 1655/2134\n",
            "Loading 1656/2134\n",
            "Loading 1657/2134\n",
            "Loading 1658/2134\n",
            "Loading 1659/2134\n",
            "Loading 1660/2134\n",
            "Loading 1661/2134\n",
            "Loading 1662/2134\n",
            "Loading 1663/2134\n",
            "Loading 1664/2134\n",
            "Loading 1665/2134\n",
            "Loading 1666/2134\n",
            "Loading 1667/2134\n",
            "Loading 1668/2134\n",
            "Loading 1669/2134\n",
            "Loading 1670/2134\n",
            "Loading 1671/2134\n",
            "Loading 1672/2134\n",
            "Loading 1673/2134\n",
            "Loading 1674/2134\n",
            "Loading 1675/2134\n",
            "Loading 1676/2134\n",
            "Loading 1677/2134\n",
            "Loading 1678/2134\n",
            "Loading 1679/2134\n",
            "Loading 1680/2134\n",
            "Loading 1681/2134\n",
            "Loading 1682/2134\n",
            "Loading 1683/2134\n",
            "Loading 1684/2134\n",
            "Loading 1685/2134\n",
            "Loading 1686/2134\n",
            "Loading 1687/2134\n",
            "Loading 1688/2134\n",
            "Loading 1689/2134\n",
            "Loading 1690/2134\n",
            "Loading 1691/2134\n",
            "Loading 1692/2134\n",
            "Loading 1693/2134\n",
            "Loading 1694/2134\n",
            "Loading 1695/2134\n",
            "Loading 1696/2134\n",
            "Loading 1697/2134\n",
            "Loading 1698/2134\n",
            "Loading 1699/2134\n",
            "Loading 1700/2134\n",
            "Loading 1701/2134\n",
            "Loading 1702/2134\n",
            "Loading 1703/2134\n",
            "Loading 1704/2134\n",
            "Loading 1705/2134\n",
            "Loading 1706/2134\n",
            "Loading 1707/2134\n",
            "Loading 1708/2134\n",
            "Loading 1709/2134\n",
            "Loading 1710/2134\n",
            "Loading 1711/2134\n",
            "Loading 1712/2134\n",
            "Loading 1713/2134\n",
            "Loading 1714/2134\n",
            "Loading 1715/2134\n",
            "Loading 1716/2134\n",
            "Loading 1717/2134\n",
            "Loading 1718/2134\n",
            "Loading 1719/2134\n",
            "Loading 1720/2134\n",
            "Loading 1721/2134\n",
            "Loading 1722/2134\n",
            "Loading 1723/2134\n",
            "Loading 1724/2134\n",
            "Loading 1725/2134\n",
            "Loading 1726/2134\n",
            "Loading 1727/2134\n",
            "Loading 1728/2134\n",
            "Loading 1729/2134\n",
            "Loading 1730/2134\n",
            "Loading 1731/2134\n",
            "Loading 1732/2134\n",
            "Loading 1733/2134\n",
            "Loading 1734/2134\n",
            "Loading 1735/2134\n",
            "Loading 1736/2134\n",
            "Loading 1737/2134\n",
            "Loading 1738/2134\n",
            "Loading 1739/2134\n",
            "Loading 1740/2134\n",
            "Loading 1741/2134\n",
            "Loading 1742/2134\n",
            "Loading 1743/2134\n",
            "Loading 1744/2134\n",
            "Loading 1745/2134\n",
            "Loading 1746/2134\n",
            "Loading 1747/2134\n",
            "Loading 1748/2134\n",
            "Loading 1749/2134\n",
            "Loading 1750/2134\n",
            "Loading 1751/2134\n",
            "Loading 1752/2134\n",
            "Loading 1753/2134\n",
            "Loading 1754/2134\n",
            "Loading 1755/2134\n",
            "Loading 1756/2134\n",
            "Loading 1757/2134\n",
            "Loading 1758/2134\n",
            "Loading 1759/2134\n",
            "Loading 1760/2134\n",
            "Loading 1761/2134\n",
            "Loading 1762/2134\n",
            "Loading 1763/2134\n",
            "Loading 1764/2134\n",
            "Loading 1765/2134\n",
            "Loading 1766/2134\n",
            "Loading 1767/2134\n",
            "Loading 1768/2134\n",
            "Loading 1769/2134\n",
            "Loading 1770/2134\n",
            "Loading 1771/2134\n",
            "Loading 1772/2134\n",
            "Loading 1773/2134\n",
            "Loading 1774/2134\n",
            "Loading 1775/2134\n",
            "Loading 1776/2134\n",
            "Loading 1777/2134\n",
            "Loading 1778/2134\n",
            "Loading 1779/2134\n",
            "Loading 1780/2134\n",
            "Loading 1781/2134\n",
            "Loading 1782/2134\n",
            "Loading 1783/2134\n",
            "Loading 1784/2134\n",
            "Loading 1785/2134\n",
            "Loading 1786/2134\n",
            "Loading 1787/2134\n",
            "Loading 1788/2134\n",
            "Loading 1789/2134\n",
            "Loading 1790/2134\n",
            "Loading 1791/2134\n",
            "Loading 1792/2134\n",
            "Loading 1793/2134\n",
            "Loading 1794/2134\n",
            "Loading 1795/2134\n",
            "Loading 1796/2134\n",
            "Loading 1797/2134\n",
            "Loading 1798/2134\n",
            "Loading 1799/2134\n",
            "Loading 1800/2134\n",
            "Loading 1801/2134\n",
            "Loading 1802/2134\n",
            "Loading 1803/2134\n",
            "Loading 1804/2134\n",
            "Loading 1805/2134\n",
            "Loading 1806/2134\n",
            "Loading 1807/2134\n",
            "Loading 1808/2134\n",
            "Loading 1809/2134\n",
            "Loading 1810/2134\n",
            "Loading 1811/2134\n",
            "Loading 1812/2134\n",
            "Loading 1813/2134\n",
            "Loading 1814/2134\n",
            "Loading 1815/2134\n",
            "Loading 1816/2134\n",
            "Loading 1817/2134\n",
            "Loading 1818/2134\n",
            "Loading 1819/2134\n",
            "Loading 1820/2134\n",
            "Loading 1821/2134\n",
            "Loading 1822/2134\n",
            "Loading 1823/2134\n",
            "Loading 1824/2134\n",
            "Loading 1825/2134\n",
            "Loading 1826/2134\n",
            "Loading 1827/2134\n",
            "Loading 1828/2134\n",
            "Loading 1829/2134\n",
            "Loading 1830/2134\n",
            "Loading 1831/2134\n",
            "Loading 1832/2134\n",
            "Loading 1833/2134\n",
            "Loading 1834/2134\n",
            "Loading 1835/2134\n",
            "Loading 1836/2134\n",
            "Loading 1837/2134\n",
            "Loading 1838/2134\n",
            "Loading 1839/2134\n",
            "Loading 1840/2134\n",
            "Loading 1841/2134\n",
            "Loading 1842/2134\n",
            "Loading 1843/2134\n",
            "Loading 1844/2134\n",
            "Loading 1845/2134\n",
            "Loading 1846/2134\n",
            "Loading 1847/2134\n",
            "Loading 1848/2134\n",
            "Loading 1849/2134\n",
            "Loading 1850/2134\n",
            "Loading 1851/2134\n",
            "Loading 1852/2134\n",
            "Loading 1853/2134\n",
            "Loading 1854/2134\n",
            "Loading 1855/2134\n",
            "Loading 1856/2134\n",
            "Loading 1857/2134\n",
            "Loading 1858/2134\n",
            "Loading 1859/2134\n",
            "Loading 1860/2134\n",
            "Loading 1861/2134\n",
            "Loading 1862/2134\n",
            "Loading 1863/2134\n",
            "Loading 1864/2134\n",
            "Loading 1865/2134\n",
            "Loading 1866/2134\n",
            "Loading 1867/2134\n",
            "Loading 1868/2134\n",
            "Loading 1869/2134\n",
            "Loading 1870/2134\n",
            "Loading 1871/2134\n",
            "Loading 1872/2134\n",
            "Loading 1873/2134\n",
            "Loading 1874/2134\n",
            "Loading 1875/2134\n",
            "Loading 1876/2134\n",
            "Loading 1877/2134\n",
            "Loading 1878/2134\n",
            "Loading 1879/2134\n",
            "Loading 1880/2134\n",
            "Loading 1881/2134\n",
            "Loading 1882/2134\n",
            "Loading 1883/2134\n",
            "Loading 1884/2134\n",
            "Loading 1885/2134\n",
            "Loading 1886/2134\n",
            "Loading 1887/2134\n",
            "Loading 1888/2134\n",
            "Loading 1889/2134\n",
            "Loading 1890/2134\n",
            "Loading 1891/2134\n",
            "Loading 1892/2134\n",
            "Loading 1893/2134\n",
            "Loading 1894/2134\n",
            "Loading 1895/2134\n",
            "Loading 1896/2134\n",
            "Loading 1897/2134\n",
            "Loading 1898/2134\n",
            "Loading 1899/2134\n",
            "Loading 1900/2134\n",
            "Loading 1901/2134\n",
            "Loading 1902/2134\n",
            "Loading 1903/2134\n",
            "Loading 1904/2134\n",
            "Loading 1905/2134\n",
            "Loading 1906/2134\n",
            "Loading 1907/2134\n",
            "Loading 1908/2134\n",
            "Loading 1909/2134\n",
            "Loading 1910/2134\n",
            "Loading 1911/2134\n",
            "Loading 1912/2134\n",
            "Loading 1913/2134\n",
            "Loading 1914/2134\n",
            "Loading 1915/2134\n",
            "Loading 1916/2134\n",
            "Loading 1917/2134\n",
            "Loading 1918/2134\n",
            "Loading 1919/2134\n",
            "Loading 1920/2134\n",
            "Loading 1921/2134\n",
            "Loading 1922/2134\n",
            "Loading 1923/2134\n",
            "Loading 1924/2134\n",
            "Loading 1925/2134\n",
            "Loading 1926/2134\n",
            "Loading 1927/2134\n",
            "Loading 1928/2134\n",
            "Loading 1929/2134\n",
            "Loading 1930/2134\n",
            "Loading 1931/2134\n",
            "Loading 1932/2134\n",
            "Loading 1933/2134\n",
            "Loading 1934/2134\n",
            "Loading 1935/2134\n",
            "Loading 1936/2134\n",
            "Loading 1937/2134\n",
            "Loading 1938/2134\n",
            "Loading 1939/2134\n",
            "Loading 1940/2134\n",
            "Loading 1941/2134\n",
            "Loading 1942/2134\n",
            "Loading 1943/2134\n",
            "Loading 1944/2134\n",
            "Loading 1945/2134\n",
            "Loading 1946/2134\n",
            "Loading 1947/2134\n",
            "Loading 1948/2134\n",
            "Loading 1949/2134\n",
            "Loading 1950/2134\n",
            "Loading 1951/2134\n",
            "Loading 1952/2134\n",
            "Loading 1953/2134\n",
            "Loading 1954/2134\n",
            "Loading 1955/2134\n",
            "Loading 1956/2134\n",
            "Loading 1957/2134\n",
            "Loading 1958/2134\n",
            "Loading 1959/2134\n",
            "Loading 1960/2134\n",
            "Loading 1961/2134\n",
            "Loading 1962/2134\n",
            "Loading 1963/2134\n",
            "Loading 1964/2134\n",
            "Loading 1965/2134\n",
            "Loading 1966/2134\n",
            "Loading 1967/2134\n",
            "Loading 1968/2134\n",
            "Loading 1969/2134\n",
            "Loading 1970/2134\n",
            "Loading 1971/2134\n",
            "Loading 1972/2134\n",
            "Loading 1973/2134\n",
            "Loading 1974/2134\n",
            "Loading 1975/2134\n",
            "Loading 1976/2134\n",
            "Loading 1977/2134\n",
            "Loading 1978/2134\n",
            "Loading 1979/2134\n",
            "Loading 1980/2134\n",
            "Loading 1981/2134\n",
            "Loading 1982/2134\n",
            "Loading 1983/2134\n",
            "Loading 1984/2134\n",
            "Loading 1985/2134\n",
            "Loading 1986/2134\n",
            "Loading 1987/2134\n",
            "Loading 1988/2134\n",
            "Loading 1989/2134\n",
            "Loading 1990/2134\n",
            "Loading 1991/2134\n",
            "Loading 1992/2134\n",
            "Loading 1993/2134\n",
            "Loading 1994/2134\n",
            "Loading 1995/2134\n",
            "Loading 1996/2134\n",
            "Loading 1997/2134\n",
            "Loading 1998/2134\n",
            "Loading 1999/2134\n",
            "Loading 2000/2134\n",
            "Loading 2001/2134\n",
            "Loading 2002/2134\n",
            "Loading 2003/2134\n",
            "Loading 2004/2134\n",
            "Loading 2005/2134\n",
            "Loading 2006/2134\n",
            "Loading 2007/2134\n",
            "Loading 2008/2134\n",
            "Loading 2009/2134\n",
            "Loading 2010/2134\n",
            "Loading 2011/2134\n",
            "Loading 2012/2134\n",
            "Loading 2013/2134\n",
            "Loading 2014/2134\n",
            "Loading 2015/2134\n",
            "Loading 2016/2134\n",
            "Loading 2017/2134\n",
            "Loading 2018/2134\n",
            "Loading 2019/2134\n",
            "Loading 2020/2134\n",
            "Loading 2021/2134\n",
            "Loading 2022/2134\n",
            "Loading 2023/2134\n",
            "Loading 2024/2134\n",
            "Loading 2025/2134\n",
            "Loading 2026/2134\n",
            "Loading 2027/2134\n",
            "Loading 2028/2134\n",
            "Loading 2029/2134\n",
            "Loading 2030/2134\n",
            "Loading 2031/2134\n",
            "Loading 2032/2134\n",
            "Loading 2033/2134\n",
            "Loading 2034/2134\n",
            "Loading 2035/2134\n",
            "Loading 2036/2134\n",
            "Loading 2037/2134\n",
            "Loading 2038/2134\n",
            "Loading 2039/2134\n",
            "Loading 2040/2134\n",
            "Loading 2041/2134\n",
            "Loading 2042/2134\n",
            "Loading 2043/2134\n",
            "Loading 2044/2134\n",
            "Loading 2045/2134\n",
            "Loading 2046/2134\n",
            "Loading 2047/2134\n",
            "Loading 2048/2134\n",
            "Loading 2049/2134\n",
            "Loading 2050/2134\n",
            "Loading 2051/2134\n",
            "Loading 2052/2134\n",
            "Loading 2053/2134\n",
            "Loading 2054/2134\n",
            "Loading 2055/2134\n",
            "Loading 2056/2134\n",
            "Loading 2057/2134\n",
            "Loading 2058/2134\n",
            "Loading 2059/2134\n",
            "Loading 2060/2134\n",
            "Loading 2061/2134\n",
            "Loading 2062/2134\n",
            "Loading 2063/2134\n",
            "Loading 2064/2134\n",
            "Loading 2065/2134\n",
            "Loading 2066/2134\n",
            "Loading 2067/2134\n",
            "Loading 2068/2134\n",
            "Loading 2069/2134\n",
            "Loading 2070/2134\n",
            "Loading 2071/2134\n",
            "Loading 2072/2134\n",
            "Loading 2073/2134\n",
            "Loading 2074/2134\n",
            "Loading 2075/2134\n",
            "Loading 2076/2134\n",
            "Loading 2077/2134\n",
            "Loading 2078/2134\n",
            "Loading 2079/2134\n",
            "Loading 2080/2134\n",
            "Loading 2081/2134\n",
            "Loading 2082/2134\n",
            "Loading 2083/2134\n",
            "Loading 2084/2134\n",
            "Loading 2085/2134\n",
            "Loading 2086/2134\n",
            "Loading 2087/2134\n",
            "Loading 2088/2134\n",
            "Loading 2089/2134\n",
            "Loading 2090/2134\n",
            "Loading 2091/2134\n",
            "Loading 2092/2134\n",
            "Loading 2093/2134\n",
            "Loading 2094/2134\n",
            "Loading 2095/2134\n",
            "Loading 2096/2134\n",
            "Loading 2097/2134\n",
            "Loading 2098/2134\n",
            "Loading 2099/2134\n",
            "Loading 2100/2134\n",
            "Loading 2101/2134\n",
            "Loading 2102/2134\n",
            "Loading 2103/2134\n",
            "Loading 2104/2134\n",
            "Loading 2105/2134\n",
            "Loading 2106/2134\n",
            "Loading 2107/2134\n",
            "Loading 2108/2134\n",
            "Loading 2109/2134\n",
            "Loading 2110/2134\n",
            "Loading 2111/2134\n",
            "Loading 2112/2134\n",
            "Loading 2113/2134\n",
            "Loading 2114/2134\n",
            "Loading 2115/2134\n",
            "Loading 2116/2134\n",
            "Loading 2117/2134\n",
            "Loading 2118/2134\n",
            "Loading 2119/2134\n",
            "Loading 2120/2134\n",
            "Loading 2121/2134\n",
            "Loading 2122/2134\n",
            "Loading 2123/2134\n",
            "Loading 2124/2134\n",
            "Loading 2125/2134\n",
            "Loading 2126/2134\n",
            "Loading 2127/2134\n",
            "Loading 2128/2134\n",
            "Loading 2129/2134\n",
            "Loading 2130/2134\n",
            "Loading 2131/2134\n",
            "Loading 2132/2134\n",
            "Loading 2133/2134\n",
            "Loading 2134/2134\n",
            "Test image index : [154  47  59  31 419 446 217  63 152 236 289 229 434  67  45 316 352 135\n",
            " 285  77 318  41 142]\n",
            "Ended divided training and test dataset. Training : 38574, Test : 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMTIgLyC38To"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amc_PFY438To",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1f409f9-dcfb-42b3-b8af-d45270faebec"
      },
      "source": [
        "batch_size = 8\n",
        "max_epoch = 300\n",
        "n_mels = 40\n",
        "time_steps = 303\n",
        "num_hg_Depth = 4\n",
        "dim_hg_feat = 256\n",
        "learning_rate = 0.00001\n",
        "dropout_rate = 0.0\n",
        "train_model_number = 1\n",
        "input_channel_type = 'single'\n",
        "run_date = '2020-12-07'\n",
        "encoder_args = {'num_stacks': 3, 'num_channels':[n_mels for i in range(6)], 'kernel_size':3,\n",
        "                'dropout_rate': dropout_rate, 'activation': 'leaky-relu', 'return_type': 'end'}\n",
        "input_shapes = (None, n_mels, time_steps)\n",
        "seed = 1\n",
        "training_state = True\n",
        "restore_flag = 0\n",
        "restore_epoch = 0\n",
        "raise ValueError('Check restore_flag and restore_epoch again!! If confident # this code')\n",
        "\"\"\"\n",
        "1) restore_flag == 0\n",
        "- Restore encoder model weights only\n",
        "- restore_epoch == 0\n",
        "\n",
        "2) restore_flag == 1\n",
        "- Restore total model weights\n",
        "- restore_epoch != 0\n",
        "\"\"\"\n",
        "if restore_flag == 0 and restore_epoch != 0:\n",
        "    raise ValueError('Check restore_flag and restore_epoch')\n",
        "elif restore_flag == 1 and restore_epoch == 0:\n",
        "    raise ValueError('Check restore_flag and restore_epoch')\n",
        "\n",
        "\n",
        "wandb_config = {'batch_size': batch_size,\n",
        "                'max_epoch': max_epoch,\n",
        "                'n_mels': n_mels,\n",
        "                'num_hg_Depth': num_hg_Depth,\n",
        "                'dim_hg_feat': dim_hg_feat,\n",
        "                'learning_rate': learning_rate,\n",
        "                'dropout_rate': dropout_rate,\n",
        "                'train_model_number': train_model_number,\n",
        "                'input_channel_type': input_channel_type,\n",
        "                'seed': seed,\n",
        "                'training_state': training_state,\n",
        "                'num_train': num_train,\n",
        "                'num_test': num_test,\n",
        "                'date': run_date}\n",
        "\n",
        "if restore_flag == 0:\n",
        "    id = wandb.util.generate_id()\n",
        "    print('Wandb id: {}'.format(id))\n",
        "    with open('/content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/wandbID.txt', 'w') as f:\n",
        "        f.write(str(id))\n",
        "wandb_run = wandb.init(project='Speech2Pickup', name='HGN_senEM', id=id, resume=\"allow\", config=wandb_config)\n",
        "\n",
        "train(img_resize = 256, # must be fixed\n",
        "      heatmap_resize = 64, # must be fixed\n",
        "      num_hg_Depth = num_hg_Depth, # good be fixed\n",
        "      dim_hg_feat = dim_hg_feat, # good be fixed\n",
        "      n_mels = n_mels,\n",
        "      time_steps = time_steps,\n",
        "      encoder_model_path = '/content/drive/MyDrive/Speech2Pickup/sentenceEM_model/SOTA/encoder_model/sentenceEM_encoder_model',\n",
        "      encoder_args = encoder_args,\n",
        "      input_shapes = input_shapes,\n",
        "      seed = seed,\n",
        "      training_state = training_state,\n",
        "      batch_size = batch_size, \n",
        "      max_epoch = max_epoch,\n",
        "      num_train = num_train,\n",
        "      save_stride = 1,\n",
        "      learning_rate = learning_rate, # good be fixed\n",
        "      dropout_rate = dropout_rate,\n",
        "      restore_flag = restore_flag,\n",
        "      restore_path = '/content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt',\n",
        "      restore_epoch = restore_epoch,\n",
        "      total_images = total_images,\n",
        "      total_heatmaps = total_heatmaps,\n",
        "      train_speech_inputs = train_speech_inputs,\n",
        "      train_img_idx = train_img_idx,\n",
        "      train_pos_outputs = train_pos_outputs,\n",
        "      model_save_path = '/content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wandb id: 1s3zdqke\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">HGN_senEM</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/awesomericky/Speech2Pickup\" target=\"_blank\">https://wandb.ai/awesomericky/Speech2Pickup</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/awesomericky/Speech2Pickup/runs/1s3zdqke\" target=\"_blank\">https://wandb.ai/awesomericky/Speech2Pickup/runs/1s3zdqke</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201208_093214-1s3zdqke</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:16: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/TCN_and_decoder.py:10: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:119: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:119: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TempConvnet.call of <TCN_and_decoder.TempConvnet object at 0x7ffb72c34470>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb72c34390>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c344a8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72c47ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7241e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723af208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723b6e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723c3c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723d29e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723d2c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723e39b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72371780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72380550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7238d320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7239a0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TemporalBlock.call of <TCN_and_decoder.TemporalBlock object at 0x7ffb723a2e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb723280f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72331e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb72340c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7234d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb7235a7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method ResidualBlock.call of <TCN_and_decoder.ResidualBlock object at 0x7ffb722ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:82: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:83: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:85: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:91: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:52: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:52: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/hourglass_with_senEM.py:58: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:34: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:36: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:38: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:38: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:41: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "Now ready to start the session.\n",
            "WARNING:tensorflow:From /content/code_HGN_senEM_train.py:47: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "batch loss : 0.028552026 -> about 58309.480 second left to finish this epoch\n",
            "batch loss : 0.019467214 -> about 1284.492 second left to finish this epoch\n",
            "batch loss : 0.018839158 -> about 985.965 second left to finish this epoch\n",
            "batch loss : 0.018746775 -> about 875.370 second left to finish this epoch\n",
            "batch loss : 0.019743644 -> about 812.230 second left to finish this epoch\n",
            "batch loss : 0.020073947 -> about 768.255 second left to finish this epoch\n",
            "batch loss : 0.018191397 -> about 733.685 second left to finish this epoch\n",
            "batch loss : 0.0186313 -> about 704.438 second left to finish this epoch\n",
            "batch loss : 0.017922997 -> about 678.620 second left to finish this epoch\n",
            "batch loss : 0.018744577 -> about 655.199 second left to finish this epoch\n",
            "batch loss : 0.019534566 -> about 633.055 second left to finish this epoch\n",
            "batch loss : 0.01925319 -> about 612.207 second left to finish this epoch\n",
            "batch loss : 0.019435436 -> about 592.516 second left to finish this epoch\n",
            "batch loss : 0.017339868 -> about 573.434 second left to finish this epoch\n",
            "batch loss : 0.017579896 -> about 554.800 second left to finish this epoch\n",
            "batch loss : 0.014893438 -> about 536.470 second left to finish this epoch\n",
            "batch loss : 0.017590651 -> about 518.602 second left to finish this epoch\n",
            "batch loss : 0.015966276 -> about 501.262 second left to finish this epoch\n",
            "batch loss : 0.014682034 -> about 484.069 second left to finish this epoch\n",
            "batch loss : 0.013559235 -> about 466.967 second left to finish this epoch\n",
            "batch loss : 0.012123511 -> about 450.306 second left to finish this epoch\n",
            "batch loss : 0.010555852 -> about 433.680 second left to finish this epoch\n",
            "batch loss : 0.012075301 -> about 417.050 second left to finish this epoch\n",
            "batch loss : 0.012847504 -> about 400.505 second left to finish this epoch\n",
            "batch loss : 0.0135996025 -> about 384.075 second left to finish this epoch\n",
            "batch loss : 0.009995403 -> about 367.722 second left to finish this epoch\n",
            "batch loss : 0.015248025 -> about 351.430 second left to finish this epoch\n",
            "batch loss : 0.016114179 -> about 335.255 second left to finish this epoch\n",
            "batch loss : 0.015117505 -> about 319.155 second left to finish this epoch\n",
            "batch loss : 0.014316142 -> about 303.063 second left to finish this epoch\n",
            "batch loss : 0.0146086635 -> about 287.018 second left to finish this epoch\n",
            "batch loss : 0.009321738 -> about 271.001 second left to finish this epoch\n",
            "batch loss : 0.01680803 -> about 255.052 second left to finish this epoch\n",
            "batch loss : 0.014487639 -> about 239.150 second left to finish this epoch\n",
            "batch loss : 0.01621398 -> about 223.265 second left to finish this epoch\n",
            "batch loss : 0.01576394 -> about 207.426 second left to finish this epoch\n",
            "batch loss : 0.014371838 -> about 191.600 second left to finish this epoch\n",
            "batch loss : 0.0114026675 -> about 175.827 second left to finish this epoch\n",
            "batch loss : 0.0102006635 -> about 160.060 second left to finish this epoch\n",
            "batch loss : 0.009311808 -> about 144.303 second left to finish this epoch\n",
            "batch loss : 0.012677129 -> about 128.591 second left to finish this epoch\n",
            "batch loss : 0.014699405 -> about 112.905 second left to finish this epoch\n",
            "batch loss : 0.01053841 -> about 97.192 second left to finish this epoch\n",
            "batch loss : 0.012090004 -> about 81.494 second left to finish this epoch\n",
            "batch loss : 0.014813649 -> about 65.825 second left to finish this epoch\n",
            "batch loss : 0.012106722 -> about 50.168 second left to finish this epoch\n",
            "batch loss : 0.0084373765 -> about 34.525 second left to finish this epoch\n",
            "batch loss : 0.010371233 -> about 18.896 second left to finish this epoch\n",
            "batch loss : 0.008096302 -> about 3.278 second left to finish this epoch\n",
            "current epoch : 1 , current train loss : 0.014577340616890378\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.011257969 -> about 786.665 second left to finish this epoch\n",
            "batch loss : 0.009398699 -> about 725.775 second left to finish this epoch\n",
            "batch loss : 0.012317674 -> about 708.650 second left to finish this epoch\n",
            "batch loss : 0.01045279 -> about 693.394 second left to finish this epoch\n",
            "batch loss : 0.0069695455 -> about 677.831 second left to finish this epoch\n",
            "batch loss : 0.008724261 -> about 662.520 second left to finish this epoch\n",
            "batch loss : 0.009177281 -> about 647.797 second left to finish this epoch\n",
            "batch loss : 0.012797253 -> about 632.369 second left to finish this epoch\n",
            "batch loss : 0.013939137 -> about 616.859 second left to finish this epoch\n",
            "batch loss : 0.0072661093 -> about 602.236 second left to finish this epoch\n",
            "batch loss : 0.014975747 -> about 586.770 second left to finish this epoch\n",
            "batch loss : 0.009578826 -> about 571.602 second left to finish this epoch\n",
            "batch loss : 0.010974796 -> about 556.956 second left to finish this epoch\n",
            "batch loss : 0.005648245 -> about 541.596 second left to finish this epoch\n",
            "batch loss : 0.009156151 -> about 526.052 second left to finish this epoch\n",
            "batch loss : 0.013328655 -> about 510.599 second left to finish this epoch\n",
            "batch loss : 0.010003616 -> about 495.092 second left to finish this epoch\n",
            "batch loss : 0.003952308 -> about 479.749 second left to finish this epoch\n",
            "batch loss : 0.01333208 -> about 464.339 second left to finish this epoch\n",
            "batch loss : 0.008685304 -> about 448.916 second left to finish this epoch\n",
            "batch loss : 0.008957854 -> about 433.445 second left to finish this epoch\n",
            "batch loss : 0.015406664 -> about 418.060 second left to finish this epoch\n",
            "batch loss : 0.008244467 -> about 402.678 second left to finish this epoch\n",
            "batch loss : 0.008614696 -> about 387.304 second left to finish this epoch\n",
            "batch loss : 0.010199899 -> about 371.907 second left to finish this epoch\n",
            "batch loss : 0.012440791 -> about 356.466 second left to finish this epoch\n",
            "batch loss : 0.0054263305 -> about 341.049 second left to finish this epoch\n",
            "batch loss : 0.011259092 -> about 325.636 second left to finish this epoch\n",
            "batch loss : 0.0078148665 -> about 310.275 second left to finish this epoch\n",
            "batch loss : 0.010250367 -> about 294.950 second left to finish this epoch\n",
            "batch loss : 0.0062343804 -> about 279.589 second left to finish this epoch\n",
            "batch loss : 0.0077253277 -> about 264.181 second left to finish this epoch\n",
            "batch loss : 0.011731097 -> about 248.855 second left to finish this epoch\n",
            "batch loss : 0.008785073 -> about 233.567 second left to finish this epoch\n",
            "batch loss : 0.013078318 -> about 218.223 second left to finish this epoch\n",
            "batch loss : 0.009005122 -> about 202.842 second left to finish this epoch\n",
            "batch loss : 0.0071288766 -> about 187.453 second left to finish this epoch\n",
            "batch loss : 0.0061504915 -> about 172.084 second left to finish this epoch\n",
            "batch loss : 0.007513407 -> about 156.723 second left to finish this epoch\n",
            "batch loss : 0.011318037 -> about 141.380 second left to finish this epoch\n",
            "batch loss : 0.0056585213 -> about 126.033 second left to finish this epoch\n",
            "batch loss : 0.009859651 -> about 110.667 second left to finish this epoch\n",
            "batch loss : 0.0073859855 -> about 95.313 second left to finish this epoch\n",
            "batch loss : 0.0078885155 -> about 79.959 second left to finish this epoch\n",
            "batch loss : 0.010220429 -> about 64.600 second left to finish this epoch\n",
            "batch loss : 0.0097467275 -> about 49.250 second left to finish this epoch\n",
            "batch loss : 0.01079571 -> about 33.906 second left to finish this epoch\n",
            "batch loss : 0.0060810805 -> about 18.562 second left to finish this epoch\n",
            "batch loss : 0.009287209 -> about 3.221 second left to finish this epoch\n",
            "current epoch : 2 , current train loss : 0.009224225420342923\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.005058619 -> about 751.016 second left to finish this epoch\n",
            "batch loss : 0.0039575137 -> about 722.428 second left to finish this epoch\n",
            "batch loss : 0.0025727449 -> about 707.059 second left to finish this epoch\n",
            "batch loss : 0.005503393 -> about 692.536 second left to finish this epoch\n",
            "batch loss : 0.0074207475 -> about 678.222 second left to finish this epoch\n",
            "batch loss : 0.0029433814 -> about 664.043 second left to finish this epoch\n",
            "batch loss : 0.0060990476 -> about 648.124 second left to finish this epoch\n",
            "batch loss : 0.007623123 -> about 632.268 second left to finish this epoch\n",
            "batch loss : 0.004931424 -> about 616.895 second left to finish this epoch\n",
            "batch loss : 0.005357844 -> about 601.548 second left to finish this epoch\n",
            "batch loss : 0.009943934 -> about 586.213 second left to finish this epoch\n",
            "batch loss : 0.009192135 -> about 570.648 second left to finish this epoch\n",
            "batch loss : 0.007067399 -> about 555.241 second left to finish this epoch\n",
            "batch loss : 0.005871592 -> about 539.894 second left to finish this epoch\n",
            "batch loss : 0.004084807 -> about 524.462 second left to finish this epoch\n",
            "batch loss : 0.010868682 -> about 508.993 second left to finish this epoch\n",
            "batch loss : 0.0073235584 -> about 493.592 second left to finish this epoch\n",
            "batch loss : 0.008308265 -> about 478.197 second left to finish this epoch\n",
            "batch loss : 0.010135778 -> about 462.899 second left to finish this epoch\n",
            "batch loss : 0.0058977883 -> about 447.450 second left to finish this epoch\n",
            "batch loss : 0.005828236 -> about 432.167 second left to finish this epoch\n",
            "batch loss : 0.0068195174 -> about 416.860 second left to finish this epoch\n",
            "batch loss : 0.0018723903 -> about 401.438 second left to finish this epoch\n",
            "batch loss : 0.0051112985 -> about 386.000 second left to finish this epoch\n",
            "batch loss : 0.0066633457 -> about 370.653 second left to finish this epoch\n",
            "batch loss : 0.0031697517 -> about 355.548 second left to finish this epoch\n",
            "batch loss : 0.008976059 -> about 340.231 second left to finish this epoch\n",
            "batch loss : 0.004761608 -> about 324.892 second left to finish this epoch\n",
            "batch loss : 0.0059579094 -> about 309.512 second left to finish this epoch\n",
            "batch loss : 0.009388842 -> about 294.181 second left to finish this epoch\n",
            "batch loss : 0.010282214 -> about 278.867 second left to finish this epoch\n",
            "batch loss : 0.0033545247 -> about 263.556 second left to finish this epoch\n",
            "batch loss : 0.009243605 -> about 248.163 second left to finish this epoch\n",
            "batch loss : 0.0023994325 -> about 232.839 second left to finish this epoch\n",
            "batch loss : 0.008239884 -> about 217.503 second left to finish this epoch\n",
            "batch loss : 0.008475946 -> about 202.186 second left to finish this epoch\n",
            "batch loss : 0.0080738235 -> about 186.863 second left to finish this epoch\n",
            "batch loss : 0.009842267 -> about 171.560 second left to finish this epoch\n",
            "batch loss : 0.00977226 -> about 156.251 second left to finish this epoch\n",
            "batch loss : 0.0069243293 -> about 140.937 second left to finish this epoch\n",
            "batch loss : 0.0070497617 -> about 125.641 second left to finish this epoch\n",
            "batch loss : 0.00810112 -> about 110.333 second left to finish this epoch\n",
            "batch loss : 0.011793112 -> about 95.027 second left to finish this epoch\n",
            "batch loss : 0.0038226943 -> about 79.727 second left to finish this epoch\n",
            "batch loss : 0.006047281 -> about 64.414 second left to finish this epoch\n",
            "batch loss : 0.005172841 -> about 49.122 second left to finish this epoch\n",
            "batch loss : 0.005717364 -> about 33.820 second left to finish this epoch\n",
            "batch loss : 0.0019833904 -> about 18.517 second left to finish this epoch\n",
            "batch loss : 0.0049344646 -> about 3.213 second left to finish this epoch\n",
            "current epoch : 3 , current train loss : 0.006937262180389392\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.006040012 -> about 749.655 second left to finish this epoch\n",
            "batch loss : 0.005470397 -> about 721.103 second left to finish this epoch\n",
            "batch loss : 0.0070353905 -> about 705.634 second left to finish this epoch\n",
            "batch loss : 0.004906245 -> about 689.143 second left to finish this epoch\n",
            "batch loss : 0.004285476 -> about 673.710 second left to finish this epoch\n",
            "batch loss : 0.008412214 -> about 658.754 second left to finish this epoch\n",
            "batch loss : 0.0065337773 -> about 643.427 second left to finish this epoch\n",
            "batch loss : 0.008330569 -> about 628.388 second left to finish this epoch\n",
            "batch loss : 0.0022876598 -> about 613.087 second left to finish this epoch\n",
            "batch loss : 0.0046420014 -> about 597.847 second left to finish this epoch\n",
            "batch loss : 0.0040973416 -> about 582.379 second left to finish this epoch\n",
            "batch loss : 0.0070600407 -> about 567.300 second left to finish this epoch\n",
            "batch loss : 0.0046980903 -> about 552.433 second left to finish this epoch\n",
            "batch loss : 0.005775678 -> about 537.082 second left to finish this epoch\n",
            "batch loss : 0.005250074 -> about 521.811 second left to finish this epoch\n",
            "batch loss : 0.007740521 -> about 506.534 second left to finish this epoch\n",
            "batch loss : 0.0078026657 -> about 491.327 second left to finish this epoch\n",
            "batch loss : 0.0033682722 -> about 476.470 second left to finish this epoch\n",
            "batch loss : 0.010682803 -> about 461.367 second left to finish this epoch\n",
            "batch loss : 0.0037357272 -> about 446.107 second left to finish this epoch\n",
            "batch loss : 0.0030987074 -> about 430.835 second left to finish this epoch\n",
            "batch loss : 0.007636736 -> about 415.577 second left to finish this epoch\n",
            "batch loss : 0.008721746 -> about 400.352 second left to finish this epoch\n",
            "batch loss : 0.0034332697 -> about 385.060 second left to finish this epoch\n",
            "batch loss : 0.01286854 -> about 369.770 second left to finish this epoch\n",
            "batch loss : 0.0060035726 -> about 354.516 second left to finish this epoch\n",
            "batch loss : 0.0109657645 -> about 339.247 second left to finish this epoch\n",
            "batch loss : 0.0032901033 -> about 323.986 second left to finish this epoch\n",
            "batch loss : 0.006261541 -> about 308.679 second left to finish this epoch\n",
            "batch loss : 0.0073787505 -> about 293.424 second left to finish this epoch\n",
            "batch loss : 0.0015060753 -> about 278.187 second left to finish this epoch\n",
            "batch loss : 0.002925658 -> about 262.921 second left to finish this epoch\n",
            "batch loss : 0.007128834 -> about 247.688 second left to finish this epoch\n",
            "batch loss : 0.0026165294 -> about 232.388 second left to finish this epoch\n",
            "batch loss : 0.0060196705 -> about 217.081 second left to finish this epoch\n",
            "batch loss : 0.0013837869 -> about 201.799 second left to finish this epoch\n",
            "batch loss : 0.0026451356 -> about 186.526 second left to finish this epoch\n",
            "batch loss : 0.0027338942 -> about 171.287 second left to finish this epoch\n",
            "batch loss : 0.0010952309 -> about 156.067 second left to finish this epoch\n",
            "batch loss : 0.0032524625 -> about 140.780 second left to finish this epoch\n",
            "batch loss : 0.004111802 -> about 125.491 second left to finish this epoch\n",
            "batch loss : 0.0047281645 -> about 110.193 second left to finish this epoch\n",
            "batch loss : 0.0036465363 -> about 94.905 second left to finish this epoch\n",
            "batch loss : 0.0060976716 -> about 79.618 second left to finish this epoch\n",
            "batch loss : 0.0021200632 -> about 64.329 second left to finish this epoch\n",
            "batch loss : 0.003591894 -> about 49.050 second left to finish this epoch\n",
            "batch loss : 0.001674145 -> about 33.769 second left to finish this epoch\n",
            "batch loss : 0.0044660014 -> about 18.490 second left to finish this epoch\n",
            "batch loss : 0.006785456 -> about 3.209 second left to finish this epoch\n",
            "current epoch : 4 , current train loss : 0.0054134293831831735\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.0038041358 -> about 761.927 second left to finish this epoch\n",
            "batch loss : 0.0054108687 -> about 715.816 second left to finish this epoch\n",
            "batch loss : 0.0014080256 -> about 700.231 second left to finish this epoch\n",
            "batch loss : 0.005001263 -> about 685.900 second left to finish this epoch\n",
            "batch loss : 0.0037772527 -> about 672.061 second left to finish this epoch\n",
            "batch loss : 0.0027241698 -> about 656.915 second left to finish this epoch\n",
            "batch loss : 0.0038595796 -> about 641.873 second left to finish this epoch\n",
            "batch loss : 0.008196351 -> about 626.896 second left to finish this epoch\n",
            "batch loss : 0.0046054507 -> about 611.474 second left to finish this epoch\n",
            "batch loss : 0.008390381 -> about 596.569 second left to finish this epoch\n",
            "batch loss : 0.0057280688 -> about 582.321 second left to finish this epoch\n",
            "batch loss : 0.006414704 -> about 566.897 second left to finish this epoch\n",
            "batch loss : 0.00848704 -> about 551.733 second left to finish this epoch\n",
            "batch loss : 0.0061694663 -> about 536.367 second left to finish this epoch\n",
            "batch loss : 0.003851714 -> about 520.980 second left to finish this epoch\n",
            "batch loss : 0.0031634453 -> about 505.552 second left to finish this epoch\n",
            "batch loss : 0.0042952313 -> about 490.286 second left to finish this epoch\n",
            "batch loss : 0.002384345 -> about 474.971 second left to finish this epoch\n",
            "batch loss : 0.0026929565 -> about 459.694 second left to finish this epoch\n",
            "batch loss : 0.008926043 -> about 444.437 second left to finish this epoch\n",
            "batch loss : 0.0016314457 -> about 429.235 second left to finish this epoch\n",
            "batch loss : 0.005256447 -> about 414.031 second left to finish this epoch\n",
            "batch loss : 0.004786339 -> about 398.776 second left to finish this epoch\n",
            "batch loss : 0.0029550032 -> about 383.475 second left to finish this epoch\n",
            "batch loss : 0.007603815 -> about 368.398 second left to finish this epoch\n",
            "batch loss : 0.0027318718 -> about 353.202 second left to finish this epoch\n",
            "batch loss : 0.0011062885 -> about 338.013 second left to finish this epoch\n",
            "batch loss : 0.0073549724 -> about 322.772 second left to finish this epoch\n",
            "batch loss : 0.0034513986 -> about 307.497 second left to finish this epoch\n",
            "batch loss : 0.007181331 -> about 292.245 second left to finish this epoch\n",
            "batch loss : 0.0035430582 -> about 277.188 second left to finish this epoch\n",
            "batch loss : 0.0097510945 -> about 261.961 second left to finish this epoch\n",
            "batch loss : 0.0036054729 -> about 246.716 second left to finish this epoch\n",
            "batch loss : 0.003204011 -> about 231.461 second left to finish this epoch\n",
            "batch loss : 0.0046435082 -> about 216.220 second left to finish this epoch\n",
            "batch loss : 0.0040758112 -> about 200.980 second left to finish this epoch\n",
            "batch loss : 0.0043000253 -> about 185.775 second left to finish this epoch\n",
            "batch loss : 0.0058013867 -> about 170.565 second left to finish this epoch\n",
            "batch loss : 0.002802899 -> about 155.358 second left to finish this epoch\n",
            "batch loss : 0.003902745 -> about 140.123 second left to finish this epoch\n",
            "batch loss : 0.0032986412 -> about 124.904 second left to finish this epoch\n",
            "batch loss : 0.005407433 -> about 109.676 second left to finish this epoch\n",
            "batch loss : 0.004988553 -> about 94.458 second left to finish this epoch\n",
            "batch loss : 0.0024504713 -> about 79.237 second left to finish this epoch\n",
            "batch loss : 0.0020738933 -> about 64.042 second left to finish this epoch\n",
            "batch loss : 0.0044850754 -> about 48.828 second left to finish this epoch\n",
            "batch loss : 0.0011591611 -> about 33.618 second left to finish this epoch\n",
            "batch loss : 0.0049035326 -> about 18.405 second left to finish this epoch\n",
            "batch loss : 0.00316996 -> about 3.194 second left to finish this epoch\n",
            "current epoch : 5 , current train loss : 0.004312456212338973\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.003755633 -> about 726.496 second left to finish this epoch\n",
            "batch loss : 0.0014930987 -> about 718.474 second left to finish this epoch\n",
            "batch loss : 0.0030071316 -> about 708.248 second left to finish this epoch\n",
            "batch loss : 0.0015305064 -> about 692.309 second left to finish this epoch\n",
            "batch loss : 0.0040584654 -> about 675.657 second left to finish this epoch\n",
            "batch loss : 0.0025475626 -> about 659.274 second left to finish this epoch\n",
            "batch loss : 0.004747937 -> about 644.231 second left to finish this epoch\n",
            "batch loss : 0.002153351 -> about 628.664 second left to finish this epoch\n",
            "batch loss : 0.0035642576 -> about 613.325 second left to finish this epoch\n",
            "batch loss : 0.004938201 -> about 597.803 second left to finish this epoch\n",
            "batch loss : 0.00318025 -> about 582.339 second left to finish this epoch\n",
            "batch loss : 0.0017781253 -> about 567.143 second left to finish this epoch\n",
            "batch loss : 0.00090549287 -> about 551.810 second left to finish this epoch\n",
            "batch loss : 0.0015985204 -> about 536.430 second left to finish this epoch\n",
            "batch loss : 0.0027857735 -> about 521.011 second left to finish this epoch\n",
            "batch loss : 0.004016536 -> about 505.552 second left to finish this epoch\n",
            "batch loss : 0.0011118285 -> about 490.449 second left to finish this epoch\n",
            "batch loss : 0.0031135392 -> about 475.212 second left to finish this epoch\n",
            "batch loss : 0.007937214 -> about 459.977 second left to finish this epoch\n",
            "batch loss : 0.0035144594 -> about 444.688 second left to finish this epoch\n",
            "batch loss : 0.0019654976 -> about 429.422 second left to finish this epoch\n",
            "batch loss : 0.0009569442 -> about 414.139 second left to finish this epoch\n",
            "batch loss : 0.0033113179 -> about 398.935 second left to finish this epoch\n",
            "batch loss : 0.002776801 -> about 383.954 second left to finish this epoch\n",
            "batch loss : 0.003289589 -> about 368.654 second left to finish this epoch\n",
            "batch loss : 0.0011892866 -> about 353.436 second left to finish this epoch\n",
            "batch loss : 0.0010180713 -> about 338.115 second left to finish this epoch\n",
            "batch loss : 0.0033641541 -> about 322.882 second left to finish this epoch\n",
            "batch loss : 0.001691692 -> about 307.622 second left to finish this epoch\n",
            "batch loss : 0.0039582364 -> about 292.428 second left to finish this epoch\n",
            "batch loss : 0.0020939414 -> about 277.187 second left to finish this epoch\n",
            "batch loss : 0.0020606462 -> about 261.960 second left to finish this epoch\n",
            "batch loss : 0.004104062 -> about 246.728 second left to finish this epoch\n",
            "batch loss : 0.0061585787 -> about 231.476 second left to finish this epoch\n",
            "batch loss : 0.00090420555 -> about 216.256 second left to finish this epoch\n",
            "batch loss : 0.009833608 -> about 201.038 second left to finish this epoch\n",
            "batch loss : 0.0057754996 -> about 185.825 second left to finish this epoch\n",
            "batch loss : 0.0015437017 -> about 170.596 second left to finish this epoch\n",
            "batch loss : 0.0017063478 -> about 155.375 second left to finish this epoch\n",
            "batch loss : 0.0009881235 -> about 140.141 second left to finish this epoch\n",
            "batch loss : 0.0021752757 -> about 124.905 second left to finish this epoch\n",
            "batch loss : 0.0013567191 -> about 109.687 second left to finish this epoch\n",
            "batch loss : 0.004839295 -> about 94.474 second left to finish this epoch\n",
            "batch loss : 0.0043360176 -> about 79.289 second left to finish this epoch\n",
            "batch loss : 0.0028118484 -> about 64.068 second left to finish this epoch\n",
            "batch loss : 0.0010886332 -> about 48.844 second left to finish this epoch\n",
            "batch loss : 0.0019779399 -> about 33.624 second left to finish this epoch\n",
            "batch loss : 0.0022979781 -> about 18.409 second left to finish this epoch\n",
            "batch loss : 0.0029524737 -> about 3.195 second left to finish this epoch\n",
            "current epoch : 6 , current train loss : 0.0034545635870529205\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.0017384664 -> about 785.258 second left to finish this epoch\n",
            "batch loss : 0.0025171877 -> about 721.197 second left to finish this epoch\n",
            "batch loss : 0.0014319548 -> about 703.261 second left to finish this epoch\n",
            "batch loss : 0.0023794374 -> about 687.734 second left to finish this epoch\n",
            "batch loss : 0.0023470605 -> about 672.203 second left to finish this epoch\n",
            "batch loss : 0.0022289439 -> about 656.825 second left to finish this epoch\n",
            "batch loss : 0.0011556282 -> about 641.679 second left to finish this epoch\n",
            "batch loss : 0.0038757506 -> about 626.646 second left to finish this epoch\n",
            "batch loss : 0.0038506216 -> about 611.467 second left to finish this epoch\n",
            "batch loss : 0.0022161447 -> about 596.098 second left to finish this epoch\n",
            "batch loss : 0.0013162412 -> about 580.750 second left to finish this epoch\n",
            "batch loss : 0.0033284894 -> about 565.129 second left to finish this epoch\n",
            "batch loss : 0.0041886372 -> about 549.577 second left to finish this epoch\n",
            "batch loss : 0.0024194126 -> about 534.242 second left to finish this epoch\n",
            "batch loss : 0.0018070121 -> about 518.854 second left to finish this epoch\n",
            "batch loss : 0.004737354 -> about 504.077 second left to finish this epoch\n",
            "batch loss : 0.002721134 -> about 488.852 second left to finish this epoch\n",
            "batch loss : 0.0022796998 -> about 473.543 second left to finish this epoch\n",
            "batch loss : 0.002075952 -> about 458.236 second left to finish this epoch\n",
            "batch loss : 0.00318236 -> about 443.033 second left to finish this epoch\n",
            "batch loss : 0.0037417756 -> about 427.723 second left to finish this epoch\n",
            "batch loss : 0.0019839802 -> about 412.554 second left to finish this epoch\n",
            "batch loss : 0.00087701913 -> about 397.244 second left to finish this epoch\n",
            "batch loss : 0.002501259 -> about 382.112 second left to finish this epoch\n",
            "batch loss : 0.0024285847 -> about 366.869 second left to finish this epoch\n",
            "batch loss : 0.0008655067 -> about 351.666 second left to finish this epoch\n",
            "batch loss : 0.00056325167 -> about 336.467 second left to finish this epoch\n",
            "batch loss : 0.0027830394 -> about 321.340 second left to finish this epoch\n",
            "batch loss : 0.0057645696 -> about 306.231 second left to finish this epoch\n",
            "batch loss : 0.0031281542 -> about 291.053 second left to finish this epoch\n",
            "batch loss : 0.0075910566 -> about 275.854 second left to finish this epoch\n",
            "batch loss : 0.0037986236 -> about 260.690 second left to finish this epoch\n",
            "batch loss : 0.0037211687 -> about 245.525 second left to finish this epoch\n",
            "batch loss : 0.0037895641 -> about 230.367 second left to finish this epoch\n",
            "batch loss : 0.0042955577 -> about 215.184 second left to finish this epoch\n",
            "batch loss : 0.007909188 -> about 200.025 second left to finish this epoch\n",
            "batch loss : 0.0045462893 -> about 184.966 second left to finish this epoch\n",
            "batch loss : 0.0015094767 -> about 169.802 second left to finish this epoch\n",
            "batch loss : 0.0015906494 -> about 154.643 second left to finish this epoch\n",
            "batch loss : 0.0015875844 -> about 139.482 second left to finish this epoch\n",
            "batch loss : 0.002979152 -> about 124.333 second left to finish this epoch\n",
            "batch loss : 0.0039724465 -> about 109.181 second left to finish this epoch\n",
            "batch loss : 0.0036061818 -> about 94.037 second left to finish this epoch\n",
            "batch loss : 0.002634932 -> about 78.898 second left to finish this epoch\n",
            "batch loss : 0.0023869206 -> about 63.750 second left to finish this epoch\n",
            "batch loss : 0.0029847557 -> about 48.607 second left to finish this epoch\n",
            "batch loss : 0.0019161977 -> about 33.462 second left to finish this epoch\n",
            "batch loss : 0.0018322862 -> about 18.319 second left to finish this epoch\n",
            "batch loss : 0.0050119944 -> about 3.180 second left to finish this epoch\n",
            "current epoch : 7 , current train loss : 0.002760172116672222\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.0030895027 -> about 767.471 second left to finish this epoch\n",
            "batch loss : 0.0047972836 -> about 720.357 second left to finish this epoch\n",
            "batch loss : 0.0012614646 -> about 704.954 second left to finish this epoch\n",
            "batch loss : 0.001860494 -> about 689.870 second left to finish this epoch\n",
            "batch loss : 0.0032456892 -> about 674.789 second left to finish this epoch\n",
            "batch loss : 0.0034756486 -> about 659.075 second left to finish this epoch\n",
            "batch loss : 0.0019046154 -> about 643.809 second left to finish this epoch\n",
            "batch loss : 0.0015076936 -> about 628.619 second left to finish this epoch\n",
            "batch loss : 0.0013859089 -> about 614.567 second left to finish this epoch\n",
            "batch loss : 0.0012392179 -> about 599.289 second left to finish this epoch\n",
            "batch loss : 0.0011763978 -> about 583.776 second left to finish this epoch\n",
            "batch loss : 0.0009786158 -> about 568.497 second left to finish this epoch\n",
            "batch loss : 0.001469345 -> about 553.106 second left to finish this epoch\n",
            "batch loss : 0.0036123116 -> about 537.675 second left to finish this epoch\n",
            "batch loss : 0.004426612 -> about 522.565 second left to finish this epoch\n",
            "batch loss : 0.003760856 -> about 507.276 second left to finish this epoch\n",
            "batch loss : 0.004820148 -> about 491.891 second left to finish this epoch\n",
            "batch loss : 0.0017523379 -> about 476.575 second left to finish this epoch\n",
            "batch loss : 0.0015519699 -> about 461.258 second left to finish this epoch\n",
            "batch loss : 0.0046108505 -> about 446.023 second left to finish this epoch\n",
            "batch loss : 0.003099864 -> about 430.961 second left to finish this epoch\n",
            "batch loss : 0.0008974832 -> about 415.718 second left to finish this epoch\n",
            "batch loss : 0.00087617175 -> about 400.343 second left to finish this epoch\n",
            "batch loss : 0.0014813761 -> about 385.021 second left to finish this epoch\n",
            "batch loss : 0.0015842351 -> about 369.781 second left to finish this epoch\n",
            "batch loss : 0.0014291173 -> about 354.539 second left to finish this epoch\n",
            "batch loss : 0.0041830484 -> about 339.241 second left to finish this epoch\n",
            "batch loss : 0.0011160013 -> about 323.937 second left to finish this epoch\n",
            "batch loss : 0.00072476664 -> about 308.759 second left to finish this epoch\n",
            "batch loss : 0.0046752696 -> about 293.537 second left to finish this epoch\n",
            "batch loss : 0.0035654153 -> about 278.247 second left to finish this epoch\n",
            "batch loss : 0.0014327656 -> about 262.924 second left to finish this epoch\n",
            "batch loss : 0.0012853652 -> about 247.643 second left to finish this epoch\n",
            "batch loss : 0.0013271775 -> about 232.387 second left to finish this epoch\n",
            "batch loss : 0.0014038398 -> about 217.105 second left to finish this epoch\n",
            "batch loss : 0.003456964 -> about 201.813 second left to finish this epoch\n",
            "batch loss : 0.0011988715 -> about 186.539 second left to finish this epoch\n",
            "batch loss : 0.0018448127 -> about 171.270 second left to finish this epoch\n",
            "batch loss : 0.0019875148 -> about 155.983 second left to finish this epoch\n",
            "batch loss : 0.004042801 -> about 140.703 second left to finish this epoch\n",
            "batch loss : 0.0015361231 -> about 125.450 second left to finish this epoch\n",
            "batch loss : 0.0011821145 -> about 110.157 second left to finish this epoch\n",
            "batch loss : 0.0012797198 -> about 94.878 second left to finish this epoch\n",
            "batch loss : 0.0009908675 -> about 79.600 second left to finish this epoch\n",
            "batch loss : 0.00274079 -> about 64.318 second left to finish this epoch\n",
            "batch loss : 0.0010417067 -> about 49.037 second left to finish this epoch\n",
            "batch loss : 0.0012293109 -> about 33.763 second left to finish this epoch\n",
            "batch loss : 0.0022870605 -> about 18.485 second left to finish this epoch\n",
            "batch loss : 0.0011510463 -> about 3.208 second left to finish this epoch\n",
            "current epoch : 8 , current train loss : 0.002211248539980519\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.001971012 -> about 754.236 second left to finish this epoch\n",
            "batch loss : 0.0006988128 -> about 724.011 second left to finish this epoch\n",
            "batch loss : 0.0006695855 -> about 705.025 second left to finish this epoch\n",
            "batch loss : 0.002357311 -> about 688.180 second left to finish this epoch\n",
            "batch loss : 0.0011748803 -> about 672.297 second left to finish this epoch\n",
            "batch loss : 0.0019917968 -> about 656.710 second left to finish this epoch\n",
            "batch loss : 0.0019172059 -> about 641.361 second left to finish this epoch\n",
            "batch loss : 0.001436163 -> about 626.212 second left to finish this epoch\n",
            "batch loss : 0.001099488 -> about 610.840 second left to finish this epoch\n",
            "batch loss : 0.0006792738 -> about 595.577 second left to finish this epoch\n",
            "batch loss : 0.001653194 -> about 580.224 second left to finish this epoch\n",
            "batch loss : 0.0031372746 -> about 565.375 second left to finish this epoch\n",
            "batch loss : 0.0036863782 -> about 550.167 second left to finish this epoch\n",
            "batch loss : 0.004104747 -> about 534.993 second left to finish this epoch\n",
            "batch loss : 0.0024502361 -> about 519.874 second left to finish this epoch\n",
            "batch loss : 0.0012488805 -> about 504.663 second left to finish this epoch\n",
            "batch loss : 0.0011335983 -> about 489.436 second left to finish this epoch\n",
            "batch loss : 0.0016078283 -> about 474.204 second left to finish this epoch\n",
            "batch loss : 0.0015054725 -> about 458.946 second left to finish this epoch\n",
            "batch loss : 0.0011096739 -> about 443.628 second left to finish this epoch\n",
            "batch loss : 0.0010057521 -> about 428.471 second left to finish this epoch\n",
            "batch loss : 0.0015079313 -> about 413.594 second left to finish this epoch\n",
            "batch loss : 0.0009663562 -> about 398.450 second left to finish this epoch\n",
            "batch loss : 0.0008335484 -> about 383.239 second left to finish this epoch\n",
            "batch loss : 0.0016779581 -> about 368.010 second left to finish this epoch\n",
            "batch loss : 0.003574278 -> about 352.851 second left to finish this epoch\n",
            "batch loss : 0.0009957419 -> about 337.581 second left to finish this epoch\n",
            "batch loss : 0.0009808413 -> about 322.395 second left to finish this epoch\n",
            "batch loss : 0.00088706415 -> about 307.175 second left to finish this epoch\n",
            "batch loss : 0.002460046 -> about 291.976 second left to finish this epoch\n",
            "batch loss : 0.0007054503 -> about 276.773 second left to finish this epoch\n",
            "batch loss : 0.0015651885 -> about 261.608 second left to finish this epoch\n",
            "batch loss : 0.0017268165 -> about 246.412 second left to finish this epoch\n",
            "batch loss : 0.001020454 -> about 231.213 second left to finish this epoch\n",
            "batch loss : 0.0008176341 -> about 216.014 second left to finish this epoch\n",
            "batch loss : 0.0009407438 -> about 200.799 second left to finish this epoch\n",
            "batch loss : 0.0010558687 -> about 185.592 second left to finish this epoch\n",
            "batch loss : 0.0013068264 -> about 170.391 second left to finish this epoch\n",
            "batch loss : 0.0026071079 -> about 155.199 second left to finish this epoch\n",
            "batch loss : 0.00089234306 -> about 139.996 second left to finish this epoch\n",
            "batch loss : 0.0013523712 -> about 124.792 second left to finish this epoch\n",
            "batch loss : 0.0016528985 -> about 109.622 second left to finish this epoch\n",
            "batch loss : 0.0013369034 -> about 94.422 second left to finish this epoch\n",
            "batch loss : 0.0006744922 -> about 79.213 second left to finish this epoch\n",
            "batch loss : 0.0017245543 -> about 64.002 second left to finish this epoch\n",
            "batch loss : 0.0010934417 -> about 48.798 second left to finish this epoch\n",
            "batch loss : 0.0004884796 -> about 33.594 second left to finish this epoch\n",
            "batch loss : 0.0016590264 -> about 18.393 second left to finish this epoch\n",
            "batch loss : 0.0019557723 -> about 3.192 second left to finish this epoch\n",
            "current epoch : 9 , current train loss : 0.001839335953718829\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.002320615 -> about 763.572 second left to finish this epoch\n",
            "batch loss : 0.0010602789 -> about 720.654 second left to finish this epoch\n",
            "batch loss : 0.0044674138 -> about 703.619 second left to finish this epoch\n",
            "batch loss : 0.0020300574 -> about 689.197 second left to finish this epoch\n",
            "batch loss : 0.0011162024 -> about 673.918 second left to finish this epoch\n",
            "batch loss : 0.0012340854 -> about 658.443 second left to finish this epoch\n",
            "batch loss : 0.0014350284 -> about 643.396 second left to finish this epoch\n",
            "batch loss : 0.0020854878 -> about 627.792 second left to finish this epoch\n",
            "batch loss : 0.0033697002 -> about 612.693 second left to finish this epoch\n",
            "batch loss : 0.0010472869 -> about 597.345 second left to finish this epoch\n",
            "batch loss : 0.0010140805 -> about 581.974 second left to finish this epoch\n",
            "batch loss : 0.0010985059 -> about 566.558 second left to finish this epoch\n",
            "batch loss : 0.00072172034 -> about 551.488 second left to finish this epoch\n",
            "batch loss : 0.0005633455 -> about 536.684 second left to finish this epoch\n",
            "batch loss : 0.0015478376 -> about 521.769 second left to finish this epoch\n",
            "batch loss : 0.0007762782 -> about 506.544 second left to finish this epoch\n",
            "batch loss : 0.0026295683 -> about 491.119 second left to finish this epoch\n",
            "batch loss : 0.0007979021 -> about 475.799 second left to finish this epoch\n",
            "batch loss : 0.0013181127 -> about 460.556 second left to finish this epoch\n",
            "batch loss : 0.0010575016 -> about 445.224 second left to finish this epoch\n",
            "batch loss : 0.0024858827 -> about 429.987 second left to finish this epoch\n",
            "batch loss : 0.00075653405 -> about 414.734 second left to finish this epoch\n",
            "batch loss : 0.00077099755 -> about 399.421 second left to finish this epoch\n",
            "batch loss : 0.004201424 -> about 384.314 second left to finish this epoch\n",
            "batch loss : 0.0008844134 -> about 369.031 second left to finish this epoch\n",
            "batch loss : 0.0017018307 -> about 353.801 second left to finish this epoch\n",
            "batch loss : 0.0015767806 -> about 338.556 second left to finish this epoch\n",
            "batch loss : 0.0019202484 -> about 323.296 second left to finish this epoch\n",
            "batch loss : 0.00045983162 -> about 308.019 second left to finish this epoch\n",
            "batch loss : 0.00092762965 -> about 292.754 second left to finish this epoch\n",
            "batch loss : 0.0006833955 -> about 277.508 second left to finish this epoch\n",
            "batch loss : 0.00061758375 -> about 262.273 second left to finish this epoch\n",
            "batch loss : 0.002885556 -> about 247.020 second left to finish this epoch\n",
            "batch loss : 0.0041350815 -> about 231.789 second left to finish this epoch\n",
            "batch loss : 0.0027578266 -> about 216.661 second left to finish this epoch\n",
            "batch loss : 0.0014984144 -> about 201.367 second left to finish this epoch\n",
            "batch loss : 0.00068441045 -> about 186.106 second left to finish this epoch\n",
            "batch loss : 0.0012407684 -> about 170.868 second left to finish this epoch\n",
            "batch loss : 0.005275092 -> about 155.619 second left to finish this epoch\n",
            "batch loss : 0.0006250508 -> about 140.373 second left to finish this epoch\n",
            "batch loss : 0.00082065386 -> about 125.123 second left to finish this epoch\n",
            "batch loss : 0.0009828971 -> about 109.888 second left to finish this epoch\n",
            "batch loss : 0.001192231 -> about 94.647 second left to finish this epoch\n",
            "batch loss : 0.000646379 -> about 79.419 second left to finish this epoch\n",
            "batch loss : 0.00040003646 -> about 64.169 second left to finish this epoch\n",
            "batch loss : 0.0020475746 -> about 48.926 second left to finish this epoch\n",
            "batch loss : 0.0041925777 -> about 33.685 second left to finish this epoch\n",
            "batch loss : 0.0031743976 -> about 18.442 second left to finish this epoch\n",
            "batch loss : 0.00044136425 -> about 3.201 second left to finish this epoch\n",
            "current epoch : 10 , current train loss : 0.001545792524303688\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.00082362833 -> about 739.109 second left to finish this epoch\n",
            "batch loss : 0.001004339 -> about 719.276 second left to finish this epoch\n",
            "batch loss : 0.0005834087 -> about 702.974 second left to finish this epoch\n",
            "batch loss : 0.00088697963 -> about 689.111 second left to finish this epoch\n",
            "batch loss : 0.00046605236 -> about 673.537 second left to finish this epoch\n",
            "batch loss : 0.00325404 -> about 658.562 second left to finish this epoch\n",
            "batch loss : 0.0031241358 -> about 644.409 second left to finish this epoch\n",
            "batch loss : 0.0012410786 -> about 628.988 second left to finish this epoch\n",
            "batch loss : 0.00065136293 -> about 613.367 second left to finish this epoch\n",
            "batch loss : 0.000735651 -> about 597.983 second left to finish this epoch\n",
            "batch loss : 0.001000036 -> about 582.654 second left to finish this epoch\n",
            "batch loss : 0.0009326628 -> about 567.374 second left to finish this epoch\n",
            "batch loss : 0.0005810129 -> about 551.935 second left to finish this epoch\n",
            "batch loss : 0.0032142974 -> about 536.560 second left to finish this epoch\n",
            "batch loss : 0.00068665453 -> about 521.334 second left to finish this epoch\n",
            "batch loss : 0.0008873347 -> about 506.407 second left to finish this epoch\n",
            "batch loss : 0.003631971 -> about 491.075 second left to finish this epoch\n",
            "batch loss : 0.0047716857 -> about 475.946 second left to finish this epoch\n",
            "batch loss : 0.0009905808 -> about 460.614 second left to finish this epoch\n",
            "batch loss : 0.0012924948 -> about 445.317 second left to finish this epoch\n",
            "batch loss : 0.0015214117 -> about 430.074 second left to finish this epoch\n",
            "batch loss : 0.003949203 -> about 414.863 second left to finish this epoch\n",
            "batch loss : 0.000388498 -> about 399.573 second left to finish this epoch\n",
            "batch loss : 0.00073828944 -> about 384.314 second left to finish this epoch\n",
            "batch loss : 0.0046385447 -> about 368.988 second left to finish this epoch\n",
            "batch loss : 0.0037365463 -> about 353.725 second left to finish this epoch\n",
            "batch loss : 0.00094409974 -> about 338.599 second left to finish this epoch\n",
            "batch loss : 0.00062651664 -> about 323.346 second left to finish this epoch\n",
            "batch loss : 0.0043761353 -> about 308.101 second left to finish this epoch\n",
            "batch loss : 0.0006679381 -> about 292.859 second left to finish this epoch\n",
            "batch loss : 0.0018155139 -> about 277.566 second left to finish this epoch\n",
            "batch loss : 0.0007596065 -> about 262.346 second left to finish this epoch\n",
            "batch loss : 0.000787913 -> about 247.128 second left to finish this epoch\n",
            "batch loss : 0.0038991126 -> about 231.886 second left to finish this epoch\n",
            "batch loss : 0.00054701546 -> about 216.627 second left to finish this epoch\n",
            "batch loss : 0.0005098586 -> about 201.398 second left to finish this epoch\n",
            "batch loss : 0.0007096171 -> about 186.123 second left to finish this epoch\n",
            "batch loss : 0.001213552 -> about 170.885 second left to finish this epoch\n",
            "batch loss : 0.0009060212 -> about 155.632 second left to finish this epoch\n",
            "batch loss : 0.00071901944 -> about 140.379 second left to finish this epoch\n",
            "batch loss : 0.0009382925 -> about 125.130 second left to finish this epoch\n",
            "batch loss : 0.0009067517 -> about 109.877 second left to finish this epoch\n",
            "batch loss : 0.0005767505 -> about 94.635 second left to finish this epoch\n",
            "batch loss : 0.0010917562 -> about 79.401 second left to finish this epoch\n",
            "batch loss : 0.002758465 -> about 64.164 second left to finish this epoch\n",
            "batch loss : 0.00050948816 -> about 48.923 second left to finish this epoch\n",
            "batch loss : 0.001127464 -> about 33.685 second left to finish this epoch\n",
            "batch loss : 0.00075454556 -> about 18.448 second left to finish this epoch\n",
            "batch loss : 0.001845345 -> about 3.201 second left to finish this epoch\n",
            "current epoch : 11 , current train loss : 0.0013187818251480603\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.00039184155 -> about 764.218 second left to finish this epoch\n",
            "batch loss : 0.0011274456 -> about 719.237 second left to finish this epoch\n",
            "batch loss : 0.00042501677 -> about 703.423 second left to finish this epoch\n",
            "batch loss : 0.0033986787 -> about 688.218 second left to finish this epoch\n",
            "batch loss : 0.0025172443 -> about 672.983 second left to finish this epoch\n",
            "batch loss : 0.0008742275 -> about 658.072 second left to finish this epoch\n",
            "batch loss : 0.0005759603 -> about 643.237 second left to finish this epoch\n",
            "batch loss : 0.0009434987 -> about 628.837 second left to finish this epoch\n",
            "batch loss : 0.00032816228 -> about 613.100 second left to finish this epoch\n",
            "batch loss : 0.0016945335 -> about 597.807 second left to finish this epoch\n",
            "batch loss : 0.00026187918 -> about 582.162 second left to finish this epoch\n",
            "batch loss : 0.0007987571 -> about 566.818 second left to finish this epoch\n",
            "batch loss : 0.0021869573 -> about 551.612 second left to finish this epoch\n",
            "batch loss : 0.0014838709 -> about 536.391 second left to finish this epoch\n",
            "batch loss : 0.001010217 -> about 521.204 second left to finish this epoch\n",
            "batch loss : 0.00075869705 -> about 505.988 second left to finish this epoch\n",
            "batch loss : 0.00055479305 -> about 490.708 second left to finish this epoch\n",
            "batch loss : 0.00069434673 -> about 475.545 second left to finish this epoch\n",
            "batch loss : 0.0007419941 -> about 460.374 second left to finish this epoch\n",
            "batch loss : 0.00060900266 -> about 445.418 second left to finish this epoch\n",
            "batch loss : 0.0005778269 -> about 430.092 second left to finish this epoch\n",
            "batch loss : 0.0006307203 -> about 414.781 second left to finish this epoch\n",
            "batch loss : 0.0010317512 -> about 399.541 second left to finish this epoch\n",
            "batch loss : 0.0010173627 -> about 384.224 second left to finish this epoch\n",
            "batch loss : 0.0003151255 -> about 368.967 second left to finish this epoch\n",
            "batch loss : 0.0005404001 -> about 353.708 second left to finish this epoch\n",
            "batch loss : 0.00051643024 -> about 338.456 second left to finish this epoch\n",
            "batch loss : 0.0008894071 -> about 323.314 second left to finish this epoch\n",
            "batch loss : 0.00080065144 -> about 308.047 second left to finish this epoch\n",
            "batch loss : 0.0010771981 -> about 292.786 second left to finish this epoch\n",
            "batch loss : 0.0009317623 -> about 277.539 second left to finish this epoch\n",
            "batch loss : 0.0016235451 -> about 262.285 second left to finish this epoch\n",
            "batch loss : 0.00056019746 -> about 247.068 second left to finish this epoch\n",
            "batch loss : 0.0006150259 -> about 231.779 second left to finish this epoch\n",
            "batch loss : 0.00037454697 -> about 216.528 second left to finish this epoch\n",
            "batch loss : 0.0008923924 -> about 201.283 second left to finish this epoch\n",
            "batch loss : 0.0005371572 -> about 186.014 second left to finish this epoch\n",
            "batch loss : 0.00056945917 -> about 170.792 second left to finish this epoch\n",
            "batch loss : 0.0005804727 -> about 155.549 second left to finish this epoch\n",
            "batch loss : 0.0006402752 -> about 140.381 second left to finish this epoch\n",
            "batch loss : 0.0005169214 -> about 125.138 second left to finish this epoch\n",
            "batch loss : 0.00077760976 -> about 109.895 second left to finish this epoch\n",
            "batch loss : 0.000773363 -> about 94.649 second left to finish this epoch\n",
            "batch loss : 0.0008066753 -> about 79.400 second left to finish this epoch\n",
            "batch loss : 0.00389501 -> about 64.160 second left to finish this epoch\n",
            "batch loss : 0.00040721026 -> about 48.912 second left to finish this epoch\n",
            "batch loss : 0.00060280086 -> about 33.673 second left to finish this epoch\n",
            "batch loss : 0.0008846049 -> about 18.439 second left to finish this epoch\n",
            "batch loss : 0.0007123628 -> about 3.200 second left to finish this epoch\n",
            "current epoch : 12 , current train loss : 0.001154646796615016\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.0007561471 -> about 759.201 second left to finish this epoch\n",
            "batch loss : 0.00057035935 -> about 720.349 second left to finish this epoch\n",
            "batch loss : 0.0009976786 -> about 704.936 second left to finish this epoch\n",
            "batch loss : 0.00087899924 -> about 689.062 second left to finish this epoch\n",
            "batch loss : 0.00089915877 -> about 672.831 second left to finish this epoch\n",
            "batch loss : 0.00046055007 -> about 657.757 second left to finish this epoch\n",
            "batch loss : 0.0017725362 -> about 643.002 second left to finish this epoch\n",
            "batch loss : 0.00174598 -> about 627.941 second left to finish this epoch\n",
            "batch loss : 0.0008844938 -> about 612.550 second left to finish this epoch\n",
            "batch loss : 0.0013531982 -> about 597.364 second left to finish this epoch\n",
            "batch loss : 0.000776135 -> about 581.862 second left to finish this epoch\n",
            "batch loss : 0.0013984529 -> about 567.290 second left to finish this epoch\n",
            "batch loss : 0.0033933346 -> about 551.873 second left to finish this epoch\n",
            "batch loss : 0.0004543399 -> about 536.621 second left to finish this epoch\n",
            "batch loss : 0.0036289769 -> about 521.386 second left to finish this epoch\n",
            "batch loss : 0.0003779052 -> about 506.158 second left to finish this epoch\n",
            "batch loss : 0.0004145269 -> about 490.985 second left to finish this epoch\n",
            "batch loss : 0.0004554467 -> about 475.685 second left to finish this epoch\n",
            "batch loss : 0.0008156951 -> about 460.557 second left to finish this epoch\n",
            "batch loss : 0.0005424032 -> about 445.443 second left to finish this epoch\n",
            "batch loss : 0.000725071 -> about 430.122 second left to finish this epoch\n",
            "batch loss : 0.00043089705 -> about 414.855 second left to finish this epoch\n",
            "batch loss : 0.00069443963 -> about 399.617 second left to finish this epoch\n",
            "batch loss : 0.0006879539 -> about 384.406 second left to finish this epoch\n",
            "batch loss : 0.0034663295 -> about 369.129 second left to finish this epoch\n",
            "batch loss : 0.0008242268 -> about 353.870 second left to finish this epoch\n",
            "batch loss : 0.0005801416 -> about 338.566 second left to finish this epoch\n",
            "batch loss : 0.0015509343 -> about 323.358 second left to finish this epoch\n",
            "batch loss : 0.00030694302 -> about 308.071 second left to finish this epoch\n",
            "batch loss : 0.00078865094 -> about 292.827 second left to finish this epoch\n",
            "batch loss : 0.0008604493 -> about 277.549 second left to finish this epoch\n",
            "batch loss : 0.00045823594 -> about 262.324 second left to finish this epoch\n",
            "batch loss : 0.00094980624 -> about 247.181 second left to finish this epoch\n",
            "batch loss : 0.00056819967 -> about 231.919 second left to finish this epoch\n",
            "batch loss : 0.00072732085 -> about 216.668 second left to finish this epoch\n",
            "batch loss : 0.00068964553 -> about 201.407 second left to finish this epoch\n",
            "batch loss : 0.00043325522 -> about 186.147 second left to finish this epoch\n",
            "batch loss : 0.0036681667 -> about 170.888 second left to finish this epoch\n",
            "batch loss : 0.002685462 -> about 155.647 second left to finish this epoch\n",
            "batch loss : 0.0005651058 -> about 140.409 second left to finish this epoch\n",
            "batch loss : 0.0008564071 -> about 125.154 second left to finish this epoch\n",
            "batch loss : 0.000384652 -> about 109.905 second left to finish this epoch\n",
            "batch loss : 0.0018366361 -> about 94.652 second left to finish this epoch\n",
            "batch loss : 0.0008294592 -> about 79.404 second left to finish this epoch\n",
            "batch loss : 0.00039600398 -> about 64.160 second left to finish this epoch\n",
            "batch loss : 0.0004663763 -> about 48.919 second left to finish this epoch\n",
            "batch loss : 0.0003082663 -> about 33.679 second left to finish this epoch\n",
            "batch loss : 0.00044729543 -> about 18.439 second left to finish this epoch\n",
            "batch loss : 0.0005011097 -> about 3.200 second left to finish this epoch\n",
            "current epoch : 13 , current train loss : 0.0010113210739343835\n",
            "Model saved in file : /content/drive/MyDrive/Speech2Pickup/HGN_senEM_model/model.ckpt\n",
            "batch loss : 0.0005236593 -> about 726.834 second left to finish this epoch\n",
            "batch loss : 0.0012251836 -> about 718.678 second left to finish this epoch\n",
            "batch loss : 0.0007051 -> about 702.992 second left to finish this epoch\n",
            "batch loss : 0.0004394829 -> about 687.934 second left to finish this epoch\n",
            "batch loss : 0.001211197 -> about 675.390 second left to finish this epoch\n",
            "batch loss : 0.0030396092 -> about 658.971 second left to finish this epoch\n",
            "batch loss : 0.0005155491 -> about 643.158 second left to finish this epoch\n",
            "batch loss : 0.00086970103 -> about 627.810 second left to finish this epoch\n",
            "batch loss : 0.00043635315 -> about 612.162 second left to finish this epoch\n",
            "batch loss : 0.0008411539 -> about 596.684 second left to finish this epoch\n",
            "batch loss : 0.0006237248 -> about 581.356 second left to finish this epoch\n",
            "batch loss : 0.0007225994 -> about 566.221 second left to finish this epoch\n",
            "batch loss : 0.0018766992 -> about 550.825 second left to finish this epoch\n",
            "batch loss : 0.00044315564 -> about 535.479 second left to finish this epoch\n",
            "batch loss : 0.00071695296 -> about 520.353 second left to finish this epoch\n",
            "batch loss : 0.0006938267 -> about 505.131 second left to finish this epoch\n",
            "batch loss : 0.001002435 -> about 489.773 second left to finish this epoch\n",
            "batch loss : 0.0004167112 -> about 474.558 second left to finish this epoch\n",
            "batch loss : 0.0019054061 -> about 459.340 second left to finish this epoch\n",
            "batch loss : 0.0010328643 -> about 444.035 second left to finish this epoch\n",
            "batch loss : 0.0028179563 -> about 428.733 second left to finish this epoch\n",
            "batch loss : 0.0010422852 -> about 413.566 second left to finish this epoch\n",
            "batch loss : 0.00044671696 -> about 398.320 second left to finish this epoch\n",
            "batch loss : 0.00077310076 -> about 383.013 second left to finish this epoch\n",
            "batch loss : 0.00054911815 -> about 368.101 second left to finish this epoch\n",
            "batch loss : 0.00039761147 -> about 352.936 second left to finish this epoch\n",
            "batch loss : 0.00076826895 -> about 337.705 second left to finish this epoch\n",
            "batch loss : 0.001431698 -> about 322.496 second left to finish this epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-oZq5P9WQ5"
      },
      "source": [
        "# Reset tensor graph\n",
        "# Finish wandb process\n",
        "\n",
        "tf.reset_default_graph()\n",
        "wandb.finish()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSRSZz3bT67K"
      },
      "source": [
        "# Check variable list (debugging)\n",
        "\n",
        "variables_names = [v.name for v in tf.trainable_variables()]\n",
        "variables_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5lcr7z_AzR1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}